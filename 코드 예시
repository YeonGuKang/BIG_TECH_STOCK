{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Untitled","provenance":[],"collapsed_sections":[],"mount_file_id":"1s6jF597tw88Oihk0dkX9I5L8s-XdJPSg","authorship_tag":"ABX9TyMivg5CqKbp10nk/AmaAtij"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"a9d755ee4c3d4c9c847529dca2f83bb8":{"model_module":"@jupyter-widgets/controls","model_name":"VBoxModel","model_module_version":"1.5.0","state":{"_view_name":"VBoxView","_dom_classes":[],"_model_name":"VBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_9872ead9e7fd44cb8493719496954efe","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_44da5f6a2ef8494c9c8718221a902220","IPY_MODEL_6bf4859c25914c80a698181932c4d345"]}},"9872ead9e7fd44cb8493719496954efe":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"44da5f6a2ef8494c9c8718221a902220":{"model_module":"@jupyter-widgets/controls","model_name":"LabelModel","model_module_version":"1.5.0","state":{"_view_name":"LabelView","style":"IPY_MODEL_04820b5f72f2418ba81fa51baa7e6777","_dom_classes":[],"description":"","_model_name":"LabelModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 0.37MB of 0.37MB uploaded (0.00MB deduped)\r","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_c159504560ed4665a9097839e24e8cb8"}},"6bf4859c25914c80a698181932c4d345":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_2e2ac75731b64f40890e0702b43b4574","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"","max":1,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_e65c1508d761461ba0d5307251381d1d"}},"04820b5f72f2418ba81fa51baa7e6777":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"c159504560ed4665a9097839e24e8cb8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"2e2ac75731b64f40890e0702b43b4574":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"e65c1508d761461ba0d5307251381d1d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"code","metadata":{"id":"AWZxXoy9pczO","colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["a9d755ee4c3d4c9c847529dca2f83bb8","9872ead9e7fd44cb8493719496954efe","44da5f6a2ef8494c9c8718221a902220","6bf4859c25914c80a698181932c4d345","04820b5f72f2418ba81fa51baa7e6777","c159504560ed4665a9097839e24e8cb8","2e2ac75731b64f40890e0702b43b4574","e65c1508d761461ba0d5307251381d1d"]},"outputId":"c6310aa6-771b-4878-ca82-8e1e9f8d5777"},"source":["import tensorflow as tf\n","import numpy as np\n","import pandas as pd\n","import csv\n","import matplotlib.pyplot as plt\n","from sklearn.preprocessing import MinMaxScaler , RobustScaler , StandardScaler\t, MaxAbsScaler\n","from sklearn.model_selection import train_test_split\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense\n","from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n","from tensorflow.keras.layers import LSTM , GRU\n","from tensorflow.keras.models import load_model\n","import wandb\n","import pprint\n","\n","factor = []\n","val_loss_list = []\n","test_loss_list = []\n","\n","\n","\n","            \n","class My_GRU_deep:\n","        # 생성자\n","    def __init__(self,nodes,feature,scaler_method,epochs, batch_size,window_size, train_size, test_size,dropout):\n","        self.nodes = nodes\n","        self.feature = feature\n","        self.scaler_method = scaler_method\n","        self.epochs = epochs\n","        self.batch_size = batch_size\n","        self.window_size = window_size\n","\n","        self.test_loss = 0\n","        self.num = 0\n","\n","        self.val_loss = 0\n","\n","        self.train_size = train_size\n","        self.test_size = test_size\n","\n","        self.dropout = dropout\n","\n","        # df_price = pd.read_csv('./거시+기술지표_kospi200_dropX_뉴스감성_스케일링_lastver_300_COVIDX.csv', encoding='cp949')\n","        # df_price = df_price.drop(['Date'], axis='columns')\n","        # scaler = scaler_method\n","        # scale_cols = df_price.columns\n","\n","        # TEST_SIZE = 200\n","\n","        \n","        # train_df_scaled = scaler.fit_transform(df_price[scale_cols][:-TEST_SIZE])\n","        # test_df_scaled = scaler.fit_transform(df_price[scale_cols][-TEST_SIZE:])\n","\n","\n","        # train_df_scaled = pd.DataFrame(train_df_scaled)\n","        # train_df_scaled.columns = scale_cols\n","\n","        # test_df_scaled = pd.DataFrame(test_df_scaled)\n","        # test_df_scaled.columns = scale_cols\n","\n","        # train = train_df_scaled\n","        # test = test_df_scaled\n","\n","        # feature_cols = self.feature\n","        # label_cols = ['label']\n","\n","        # self.train_feature = train[feature_cols]\n","        # self.train_label = train[label_cols]\n","\n","        # self.test_feature = test[feature_cols]\n","        # self.test_label = test[label_cols]\n","\n","        # self.train_feature, self.train_label = self.make_dataset(self.train_feature, self.train_label, self.window_size)\n","        # self.test_feature, self.test_label = self.make_dataset(self.test_feature, self.test_label, self.window_size)\n","        # self.x_train, self.x_valid, self.y_train, self.y_valid = train_test_split(self.train_feature, self.train_label, test_size=0.2)\n","\n","\n","\n","    def make_dataset(self,data, label, window_size):\n","        feature_list = []\n","        label_list = []\n","        for i in range(len(data) - window_size):\n","            feature_list.append(np.array(data.iloc[i:i+window_size]))\n","            label_list.append(np.array(label.iloc[i+window_size]))\n","\n","        # print(feature_list)\n","        # print(label_list)\n","        return np.array(feature_list), np.array(label_list)\n","            \n","    def train(self):\n","\n","        df_price = pd.read_csv('/content/drive/MyDrive/wantest/거시+기술지표_kospi200_dropX_뉴스감성_스케일링_lastver_300_COVIDX.csv', encoding='cp949')\n","        df_price = df_price.drop(['Date'], axis='columns')\n","        scaler = self.scaler_method\n","        scale_cols = df_price.columns\n","\n","\n","\n","        for i in range(0,len(df_price)):\n","            # train window * 3 days\n","            # test 5 days(week)\n","            TRAIN_SIZE = self.window_size + self.train_size\n","            TEST_SIZE = self.test_size\n","\n","\n","            TRAIN_START = (TRAIN_SIZE + TEST_SIZE) * i\n","            TRAIN_END = TRAIN_START + TRAIN_SIZE\n","\n","            TEST_STRAT = TRAIN_END - self.window_size\n","            TEST_END = TRAIN_END + TEST_SIZE\n","\n","            if(TRAIN_END > len(df_price) or TEST_END > len(df_price)):\n","                break\n","\n","       \n","            \n","\n","            train_df_scaled = scaler.fit_transform(df_price[scale_cols][TRAIN_START:TRAIN_END])\n","            test_df_scaled = scaler.fit_transform(df_price[scale_cols][TEST_STRAT:TEST_END])\n","\n","\n","            train_df_scaled = pd.DataFrame(train_df_scaled)\n","            train_df_scaled.columns = scale_cols\n","\n","            test_df_scaled = pd.DataFrame(test_df_scaled)\n","            test_df_scaled.columns = scale_cols\n","\n","            train = train_df_scaled\n","            test = test_df_scaled\n","\n","            feature_cols = self.feature\n","            label_cols = ['label']\n","\n","            self.train_feature = train[feature_cols]\n","            self.train_label = train[label_cols]\n","\n","            self.test_feature = test[feature_cols]\n","            self.test_label = test[label_cols]\n","\n","            self.train_feature, self.train_label = self.make_dataset(self.train_feature, self.train_label, self.window_size)\n","            self.test_feature, self.test_label = self.make_dataset(self.test_feature, self.test_label, self.window_size)\n","            # self.x_train, self.x_valid, self.y_train, self.y_valid = train_test_split(self.train_feature, self.train_label, test_size=0.2)\n","\n","            regression_GRU = Sequential()\n","\n","            regression_GRU.add(GRU(units=self.nodes,activation=\"relu\",dropout= self.dropout,return_sequences=True, input_shape = (self.train_feature.shape[1], self.train_feature.shape[2])))\n","            \n","            regression_GRU.add(GRU(units=self.nodes, activation=\"relu\", return_sequences=True))\n","\n","            regression_GRU.add(GRU(units=self.nodes, activation=\"relu\",dropout= self.dropout, return_sequences=True))\n","\n","            regression_GRU.add(GRU(units=self.nodes, activation=\"relu\",dropout= self.dropout, return_sequences=True))\n","\n","            regression_GRU.add(GRU(units=self.nodes, activation=\"relu\"))\n","\n","            regression_GRU.add(Dense(units = 1))\n","\n","            regression_GRU.compile(optimizer='adam', loss='mean_squared_error', metrics=['accuracy'])\n","            GRU_history = regression_GRU.fit(self.train_feature, self.train_label, epochs=self.epochs, batch_size=self.batch_size, shuffle=False,validation_data=(self.test_feature, self.test_label))\n","\n","            pred = regression_GRU.predict(self.test_feature)\n","            loss = regression_GRU.evaluate(self.test_feature,self.test_label)\n","            self.test_loss = self.test_loss + loss[1]\n","            self.num = self.num + 1\n","\n","\n","            # self.val_loss = self.val_loss + GRU_history.history['acc'][self.epochs-1]\n","\n","            print(\"loss : \",loss[1])\n","            print(\"total_loss : \",self.test_loss)\n","            print(\"num : \",self.num)\n","\n","\n","        ACCURACY = self.test_loss / self.num\n","        # TRAIN_ACC = self.val_loss / self.num\n","        wandb.log({\"ACCURACY\": ACCURACY})\n","        # wandb.log({\"TRAIN - ACCURACY\": TRAIN_ACC})\n","\n","\n","\n","class BackTesting:\n","    def __init__(self,model,money,feature,window_size,scaler_method):\n","        self.money=money\n","        self.model = model\n","        self.feature = feature\n","        self.window_size = window_size\n","        \n","        self.stock_num = 0\n","        self.left = 0\n","        self.position = \"NONE\"\n","        self.buy_price = 0\n","\n","        column_name = ['name', 'code', 'Date','time', 'Open', 'High', 'Low', 'Close', 'Volume'] # 데이터의 열 지정\n","\n","        self.inverse_data = pd.read_csv('./KODEX 인버스.csv', encoding='cp949')\n","        data = self.inverse_data.values.tolist()\n","        self.inverse_data = pd.DataFrame(data, columns=column_name) # 데이터에 열 지정\n","\n","        self.leverage_data = pd.read_csv('./KODEX 레버리지.csv', encoding='cp949')\n","        data = self.leverage_data.values.tolist()\n","        self.leverage_data = pd.DataFrame(data, columns=column_name) # 데이터에 열 지정\n","\n","        self.test_data = pd.read_csv('./거시경제지표_kospi200_스케일링_Date_inverse2_lever.csv', encoding='cp949')\n","\n","        df_price = pd.read_csv('./거시경제지표_kospi200_스케일링_Date.csv', encoding='cp949')\n","        self.scaler = scaler_method\n","        self.df_price_drop = df_price.drop(['Date'], axis='columns')\n","        self.scale_cols = self.df_price_drop.columns\n","\n","        self.df_scaled = self.scaler.fit_transform(self.df_price_drop[self.scale_cols])\n","\n","        self.df_scaled = pd.DataFrame(self.df_scaled)\n","        self.df_scaled.columns = self.scale_cols\n","\n","        TEST_SIZE = 400\n","    \n","        train = self.df_scaled[:-TEST_SIZE]\n","        test = self.df_scaled[-TEST_SIZE:]\n","\n","\n","        self.inverse_data = self.inverse_data[:420]\n","        self.leverage_data = self.leverage_data[:420]\n","\n","        self.inverse_data = self.inverse_data[::-1]\n","        self.leverage_data = self.leverage_data[::-1]\n","\n","        self.inverse_data = self.inverse_data.reset_index(drop=True)\n","        self.leverage_data = self.leverage_data.reset_index(drop=True)\n","\n","\n","        \n","\n","        feature_cols = self.feature\n","        label_cols = ['Close']\n","\n","        self.test_feature = test[feature_cols]\n","        self.test_label = test[label_cols]\n","        self.test_date = df_price['Date'][-TEST_SIZE:]\n","\n","        self.test_feature, self.test_label, self.test_date = self.make_dataset(self.test_feature, self.test_label, self.test_date,self.window_size)\n","\n","   \n","\n","\n","\n","    def make_dataset(self,data, label, date, window_size):\n","        feature_list = []\n","        label_list = []\n","        date_list = []\n","        for i in range(len(data) - window_size):\n","            feature_list.append(np.array(data.iloc[i:i+window_size]))\n","            label_list.append(np.array(label.iloc[i+window_size]))\n","            date_list.append(np.array(date.iloc[i+window_size]))\n","\n","\n","        # print(feature_list)\n","        # print(label_list)\n","        return np.array(feature_list), np.array(label_list), np.array(date_list)\n","\n","\n","    def test(self):\n","\n","        origin = pd.read_csv('./거시경제지표_kospi200_스케일X.csv', encoding='cp949')\n","\n","        model = load_model('GRU_simple_model.h5')\n","        print(model.summary())\n","      \n","        pred = model.predict(self.test_feature)\n","        \n","        # pred_real = self.scaler.inverse_transform(self.df_scaled)\n","\n","        # print(self.scale_cols)\n","        # print(pred_real[0])\n","\n","\n","        plt.figure(figsize=(12, 9))\n","        plt.plot(self.test_date,self.test_label, label='actual')\n","        plt.plot(pred, label='prediction')\n","        plt.legend()\n","        \n","\n","        for i in range(1,len(pred)):\n","\n","\n","            profit = (pred[i]/pred[i-1])\n","            # 비교를 함에 있어서 실제 주가로 해야할지 아니면 예상주가로 해야할지 불분명함\n","            # profit = (pred[i]/self.test_label[i-1])\n","\n","\n","            # print(self.test_date[i] , self.test_data['Date'][i])\n","      \n","            # print(\"before day : \",self.test_date[i-1],pred[i-1],\"actually :\",self.test_label[i-1])\n","            # print(\"next day : \",self.test_date[i],pred[i],\"actually :\",self.test_label[i])\n","            print(profit)\n","            if(profit >= 1 and (self.position ==\"SHORT\" or self.position == \"NONE\")):\n","                if(self.position == \"NONE\"):\n","                    plt.scatter(self.test_date[i-1], self.test_label[i-1], color=\"r\", marker='^')\n","                    print(\"-\"*10 + \"LONG\" + \"-\"*10)\n","                    print(\"tommorw : \",profit, \"%\")\n","                    print(\"before day : \",self.test_date[i-1],pred[i-1])\n","                    print(\"next day : \",self.test_date[i],pred[i])\n","\n","                    print(\"Date : \",self.test_data['Date'][i-1])\n","                    print(\"Price : \",self.test_data['l_Close'][i-1])\n","                    \n","                    self.stock_num = self.money//(self.test_data['l_Close'][i-1]*1.00015)\n","                    self.buy_price = self.test_data['l_Close'][i-1]*1.00015\n","                    self.left = self.money - self.stock_num * (self.test_data['l_Close'][i-1]*1.00015)\n","                    self.position = \"LONG\"\n","\n","                    print(\"Num : \",self.stock_num)\n","                    print(\"Left : \",self.left)\n","                    print(\"-\"*14)\n","                elif(self.position == \"SHORT\"):\n","                    print(\"-\"*10 + \"SWITCH to LONG\" + \"-\"*10)\n","                    print(\"Date :\",self.test_data['Date'][i-1])\n","                    print(\"num :\",self.stock_num)\n","                    print(\"sell-price :\",self.test_data['i2_Close'][i-1])\n","                    print(\"buy-price :\",self.buy_price)\n","\n","                    sell_price = self.stock_num * self.test_data['i2_Close'][i-1]\n","                    self.money = sell_price * 0.9935 + self.left\n","\n","                    print(\"MONEY : \",self.money)\n","\n","                    print(\"tommorw : \",profit, \"%\")\n","                    print(\"before day : \",self.test_date[i-1],pred[i-1])\n","                    print(\"next day : \",self.test_date[i],pred[i])\n","\n","                    print(\"Date : \",self.test_data['Date'][i-1])\n","                    print(\"Price : \",self.test_data['l_Close'][i-1])\n","                    \n","                    self.stock_num = self.money//(self.test_data['l_Close'][i-1]*1.00015)\n","                    self.buy_price = self.test_data['l_Close'][i-1]*1.00015\n","                    self.left = self.money - self.stock_num * (self.test_data['l_Close'][i-1]*1.00015)\n","                    self.position = \"LONG\"\n","\n","                    print(\"Num : \",self.stock_num)\n","                    print(\"Left : \",self.left)\n","                    plt.scatter(self.test_date[i-1], self.test_label[i-1], color=\"r\", marker='^')\n","\n","                    print(\"-\"*14)\n","\n","                    \n","\n","\n","               \n","                    \n","\n","            elif(profit < 1 and (self.position ==\"LONG\" or self.position == \"NONE\")):\n","                if(self.position == \"NONE\"):\n","                    plt.scatter(self.test_date[i-1], self.test_label[i-1], color=\"b\", marker='v')\n","                    print(\"-\"*10 + \"SHORT\" + \"-\"*10)\n","                    print(profit, \"%\")\n","                    print(\"before day : \",self.test_date[i-1],pred[i-1])\n","                    print(\"next day : \",self.test_date[i],pred[i])\n","\n","                    print(\"Date : \",self.test_data['Date'][i-1])\n","                    print(\"Price : \",self.test_data['i2_Close'][i-1])\n","                    \n","                    self.stock_num = self.money//(self.test_data['i2_Close'][i-1]*1.00015)\n","                    self.buy_price = self.test_data['i2_Close'][i-1]*1.00015\n","                    self.left = self.money - self.stock_num * (self.test_data['i2_Close'][i-1]*1.00015)\n","                    self.position = \"SHORT\"\n","\n","                    print(\"Num : \",self.stock_num)\n","                    print(\"Left : \",self.left)\n","                    print(\"-\"*14)\n","\n","                elif(self.position == \"LONG\"):\n","                    print(\"-\"*10 + \"SWITCH to SHORT\" + \"-\"*10)\n","                    print(\"Date :\",self.test_data['Date'][i-1])\n","                    print(\"num :\",self.stock_num)\n","                    print(\"sell-price :\",self.test_data['l_Close'][i-1])\n","                    print(\"buy-price :\",self.buy_price)\n","\n","                    sell_price = self.stock_num * self.test_data['l_Close'][i-1]\n","                    self.money = sell_price * 0.9935 + self.left\n","\n","                    print(\"MONEY : \",self.money)\n","\n","                    print(\"tommorw : \",profit, \"%\")\n","                    print(\"before day : \",self.test_date[i-1],pred[i-1])\n","                    print(\"next day : \",self.test_date[i],pred[i])\n","\n","                    print(\"Date : \",self.test_data['Date'][i-1])\n","                    print(\"Price : \",self.test_data['i2_Close'][i-1])\n","                    \n","                    self.stock_num = self.money//(self.test_data['i2_Close'][i-1]*1.00015)\n","                    self.buy_price = self.test_data['i2_Close'][i-1]*1.00015\n","                    self.left = self.money - self.stock_num * (self.test_data['i2_Close'][i-1]*1.00015)\n","                    self.position = \"SHORT\"\n","\n","                    print(\"Num : \",self.stock_num)\n","                    print(\"Left : \",self.left)\n","                    plt.scatter(self.test_date[i-1], self.test_label[i-1], color=\"b\", marker='v')\n","\n","                    print(\"-\"*14)\n","\n","\n","           \n","\n","        # plt.savefig(f'GRU_deep_{len(self.feature)+1}.png')\n","        plt.show()\n","\n","\n","class all_train:\n","    def __init__(nodes,feature_list , scaler_method ,epochs , batch_size , window_size, name):\n","        self.nodes = nodes\n","        self.feature_list = feature_list\n","        self.scaler_method = scaler_method\n","        self.epochs = epochs\n","        self.batch_size = batch_size\n","        self.window_size = window_size\n","        self.name = name\n","\n","\n","    def train():\n","        deep_LSTM = My_LSTM_deep(self.feature_list , self.scaler_method ,self.epochs , self.batch_size , self.window_size)\n","        deep_LSTM.train()\n","\n","        simple_LSTM = My_LSTM_simple(self.nodes,self.feature_list , self.scaler_method ,self.epochs , self.batch_size , self.window_size)\n","        simple_LSTM.train()\n","\n","        deep_GRU = My_GRU_deep(self.feature_list , self.scaler_method ,self.epochs , self.batch_size , self.window_size)\n","        deep_GRU.train()\n","\n","        simple_GRU = My_GRU_simple(self.nodes,self.feature_list , self.scaler_method ,self.epochs , self.batch_size , self.window_size)\n","        simple_GRU.train()\n","\n","        result={\"model\": factor, \"val_loss\":val_loss_list, \"test_loss\": test_loss_list}\n","        df = pd.DataFrame(result)\n","        df.to_csv(f'{self.name}.txt', sep = '\\t', index = False)\n","\n","        factor.clear()\n","        val_loss_list.clear()\n","        test_loss_list.clear()\n","\n","def train(config=None):\n","    with wandb.init(config=config):\n","        config=wandb.config\n","        nodes = config.nodes\n","        # 0 == only_index\n","        if(config.feature == 0):\n","            # feature_list = ['Open','High','Low','Volume','Close']\n","            feature_list = ['Open','High','Low','Volume','positive','negative','score','num']\n","        # 1 == index + big\n","        elif(config.feature == 1):\n","            # feature_list = ['Open','High','Low','Volume','Close','Gold','Silver','Crude Oil','WTI Oil','10-Yr Bond','Nikkei 225','USD/EUR','USD/INR','USD/JPY','USD/CNY','USD/CAD']\n","            feature_list = ['Open','High','Low','Volume','macd','macdsignal','macdhist','positive','negative','score','num']\n","        # 2 == index + small\n","        elif(config.feature == 2):\n","            # feature_list = ['Open','High','Low','Volume','Close','macd','macdsignal','macdhist','rsi','MA5','MA20','MA60','cci','OBV','AD','MFI']\n","            feature_list = ['Open','High','Low','Volume','macd','macdsignal','macdhist','rsi','MA5','MA20','MA60','cci','OBV','AD','MFI','positive','negative','score','num']\n","        # 3 == all\n","        elif(config.feature == 3):\n","            # feature_list = ['Open','High','Low','Volume','Close','macd','macdsignal','macdhist','rsi','MA5','MA20','MA60','cci','OBV','AD','MFI','Gold','Silver','Crude Oil','WTI Oil','10-Yr Bond','Nikkei 225','USD/EUR','USD/INR','USD/JPY','USD/CNY','USD/CAD']\n","            feature_list = ['Open','High','Low','Volume','macd','macdsignal','macdhist','rsi','positive','negative','score','num']\n","        elif(config.feature == 4):\n","            # feature_list = ['Open','High','Low','Volume','Close','macd','macdsignal','macdhist','rsi','MA5','MA20','MA60','cci','OBV','AD','MFI','Gold','Silver','Crude Oil','WTI Oil','10-Yr Bond','Nikkei 225','USD/EUR','USD/INR','USD/JPY','USD/CNY','USD/CAD']\n","            feature_list = ['Open','High','Low','Volume','macd','macdsignal','macdhist','rsi','MA5','MA20','MA60','positive','negative','score','num']\n","        elif(config.feature == 5):\n","            # feature_list = ['Open','High','Low','Volume','Close','macd','macdsignal','macdhist','rsi','MA5','MA20','MA60','cci','OBV','AD','MFI','Gold','Silver','Crude Oil','WTI Oil','10-Yr Bond','Nikkei 225','USD/EUR','USD/INR','USD/JPY','USD/CNY','USD/CAD']\n","            feature_list = ['Open','High','Low','Volume','macd','macdsignal','macdhist','rsi','MA5','MA20','MA60','cci','OBV','AD','MFI','positive','negative','score','num']\n","        elif(config.feature == 6):\n","            # feature_list = ['Open','High','Low','Volume','Close','macd','macdsignal','macdhist','rsi','MA5','MA20','MA60','cci','OBV','AD','MFI','Gold','Silver','Crude Oil','WTI Oil','10-Yr Bond','Nikkei 225','USD/EUR','USD/INR','USD/JPY','USD/CNY','USD/CAD']\n","            feature_list = ['Open','High','Low','Volume','Close','Gold','Silver','Crude Oil','10-Yr Bond','Nikkei 225','S&P 500','Dow Jones','Nasdaq','Nikkei 225','USD/KRW','EUR/KRW','GBP/KRW','JPY/KRW','positive','negative','score','num']\n","        elif(config.feature == 7):\n","            # feature_list = ['Open','High','Low','Volume','Close','macd','macdsignal','macdhist','rsi','MA5','MA20','MA60','cci','OBV','AD','MFI','Gold','Silver','Crude Oil','WTI Oil','10-Yr Bond','Nikkei 225','USD/EUR','USD/INR','USD/JPY','USD/CNY','USD/CAD']\n","            feature_list = ['Open','High','Low','Volume','macd','macdsignal','macdhist','rsi','MA5','MA20','MA60','cci','OBV','AD','MFI','Gold','Silver','Crude Oil','10-Yr Bond','Nikkei 225','S&P 500','Dow Jones','Nasdaq','Nikkei 225','USD/KRW','EUR/KRW','GBP/KRW','JPY/KRW','positive','negative','score','num']\n","\n","\n","\n","            \n","        scaler_method = MaxAbsScaler()\n","        epochs = config.epochs\n","        batch_size = config.batch_size\n","        window_size = config.window_size\n","\n","        train_size = config.train_size\n","        test_size = config.test_size\n","\n","        dropout = config.dropout\n","\n","        model = f'GRU_deep_{epochs}_{nodes}_{window_size}_{config.feature}.h5'\n","        model_name = f'GRU_deep_{epochs}_{nodes}_{window_size}_{config.feature}'\n","\n","        deep_gru = My_GRU_deep(nodes, feature_list , scaler_method ,epochs , batch_size , window_size, train_size, test_size, dropout)\n","        deep_gru.train()\n","        \n","        # config=wandb.config\n","        # nodes = config.nodes\n","        # feature_list = ['Open','High','Low','Volume','Close']\n","        # scaler_method = MaxAbsScaler()\n","        # epochs = config.epochs\n","        # batch_size = config.batch_size\n","        # window_size = config.window_size\n","\n","        # # Back = BackTesting(\"GRU_simple\",10000000,['Open','High','Low','Volume','Close'],window_size,scaler_method)\n","        # # Back.test()\n","\n","        # deep_LSTM = My_LSTM_deep(nodes,feature_list , scaler_method ,epochs , batch_size , window_size)\n","        # deep_LSTM.train()\n","\n","        # # simple_LSTM = My_LSTM_simple(nodes,feature_list , scaler_method ,epochs , batch_size , window_size)\n","        # # simple_LSTM.train()\n","\n","        # # deep_GRU = My_GRU_deep(nodes,feature_list , scaler_method ,epochs , batch_size , window_size)\n","        # # deep_GRU.train()\n","\n","        # # simple_GRU = My_GRU_simple(nodes,feature_list , scaler_method ,epochs , batch_size , window_size)\n","        # # simple_GRU.train()\n","\n","        # result={\"model\": factor, \"val_loss\":val_loss_list, \"test_loss\": test_loss_list}\n","        # df = pd.DataFrame(result)\n","        # # df.to_csv('using_all_result+close.txt', sep = '\\t', index = False)\n","\n","        # factor.clear()\n","        # val_loss_list.clear()\n","        # test_loss_list.clear()\n","\n","        # feature_list = ['Open','High','Low','Volume','Close']\n","        # scaler_method = MaxAbsScaler()\n","\n","        # deep_LSTM = My_LSTM_deep(feature_list , scaler_method ,epochs , batch_size , window_size)\n","        # deep_LSTM.train()\n","\n","        # simple_LSTM = My_LSTM_simple(nodes,feature_list , scaler_method ,epochs , batch_size , window_size)\n","        # simple_LSTM.train()\n","\n","        # simple_GRU = My_GRU_simple(nodes,feature_list , scaler_method ,epochs , batch_size , window_size)\n","        # simple_GRU.train()\n","\n","        # deep_GRU = My_GRU_deep(feature_list , scaler_method ,epochs , batch_size , window_size)\n","        # deep_GRU.train()\n","\n","        # result={\"model\": factor, \"val_loss\":val_loss_list, \"test_loss\": test_loss_list}\n","        # df = pd.DataFrame(result)\n","        # # df.to_csv('using_index_result+close.txt', sep = '\\t', index = False)\n","\n","        # factor.clear()\n","        # val_loss_list.clear()\n","        # test_loss_list.clear()\n","\n","        # feature_list = ['Open','High','Low','Volume','Close','macd','macdsignal','macdhist','rsi','MA5','MA20','MA60','MA224','cci']\n","        # scaler_method = MaxAbsScaler()\n","\n","        # deep_LSTM = My_LSTM_deep(feature_list , scaler_method ,epochs , batch_size , window_size)\n","        # deep_LSTM.train()\n","\n","        # simple_LSTM = My_LSTM_simple(nodes,feature_list , scaler_method ,epochs , batch_size , window_size)\n","        # simple_LSTM.train()\n","\n","        # deep_GRU = My_GRU_deep(feature_list , scaler_method ,epochs , batch_size , window_size)\n","        # deep_GRU.train()\n","\n","        # simple_GRU = My_GRU_simple(nodes,feature_list , scaler_method ,epochs , batch_size , window_size)\n","        # simple_GRU.train()\n","\n","        # result={\"model\": factor, \"val_loss\":val_loss_list, \"test_loss\": test_loss_list}\n","        # df = pd.DataFrame(result)\n","        # # df.to_csv('using_index+stockinfo_result+close.txt', sep = '\\t', index = False)\n","\n","        # factor.clear()\n","        # val_loss_list.clear()\n","        # test_loss_list.clear()\n","\n","        # feature_list = ['Crude Oil','10-Yr Bond','S&P 500','Dow Jones','Nasdaq','Nikkei 225','USD/KRW','EUR/KRW','JPY/KRW','Open','High','Low','Volume','Close']\n","        # scaler_method = MaxAbsScaler()\n","\n","        # deep_LSTM = My_LSTM_deep(feature_list , scaler_method ,epochs , batch_size , window_size)\n","        # deep_LSTM.train()\n","\n","        # simple_LSTM = My_LSTM_simple(nodes,feature_list , scaler_method ,epochs , batch_size , window_size)\n","        # simple_LSTM.train()\n","\n","        # deep_GRU = My_GRU_deep(feature_list , scaler_method ,epochs , batch_size , window_size)\n","        # deep_GRU.train()\n","\n","        # simple_GRU = My_GRU_simple(nodes,feature_list , scaler_method ,epochs , batch_size , window_size)\n","        # simple_GRU.train()\n","\n","        # result={\"model\": factor, \"val_loss\":val_loss_list, \"test_loss\": test_loss_list}\n","        # df = pd.DataFrame(result)\n","        # # df.to_csv('using_index+biginfo_result+close.txt', sep = '\\t', index = False)\n","\n","\n","\n","\n","\n","\n","\n","\n","if __name__ == \"__main__\":\n","\n","    sweep_config = {\n","    'method': 'bayes'\n","    }\n","\n","    metric={\n","        'goal': 'maximize',\n","        'name': 'ACCURACY'\n","    }\n","\n","    sweep_config['metric'] = metric\n","\n","    parameters_dict = {\n","    }\n","\n","    sweep_config['parameters'] = parameters_dict\n","\n","    parameters_dict.update({\n","        'nodes': {\n","            'max': 128, \n","            'min': 8\n","        },\n","        'epochs': {\n","            'max': 600, \n","            'min': 100\n","        },\n","        'batch_size': {\n","            'max': 64 ,\n","            'min': 8\n","        },\n","        'window_size': {\n","            'max': 60 , \n","            'min': 3\n","        },\n","        'feature': {\n","            'max': 7, \n","            'min': 0\n","        },\n","        'train_size': {\n","            'max': 100, \n","            'min': 2\n","        },\n","        'test_size': {\n","            'max': 50, \n","            'min': 2\n","        },\n","        'dropout': {\n","            'distribution': 'uniform',\n","            'max': 0.8, \n","            'min': 0\n","        }\n","    })\n","\n","\n","    pprint.pprint(sweep_config)\n","\n","    sweep_id = wandb.sweep(sweep_config, project=f\"index_predict_news_gru_deep_accuracy_dropX_300_COVIDX_sliding_drop_colab\")\n","\n","    wandb.agent(sweep_id, train, count=1000)# 논문과 반대\n","\n","\n"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["{'method': 'bayes',\n"," 'metric': {'goal': 'maximize', 'name': 'ACCURACY'},\n"," 'parameters': {'batch_size': {'max': 64, 'min': 8},\n","                'dropout': {'distribution': 'uniform', 'max': 0.8, 'min': 0},\n","                'epochs': {'max': 600, 'min': 100},\n","                'feature': {'max': 7, 'min': 0},\n","                'nodes': {'max': 128, 'min': 8},\n","                'test_size': {'max': 50, 'min': 2},\n","                'train_size': {'max': 100, 'min': 2},\n","                'window_size': {'max': 60, 'min': 3}}}\n"]},{"output_type":"display_data","data":{"application/javascript":["\n","        window._wandbApiKey = new Promise((resolve, reject) => {\n","            function loadScript(url) {\n","            return new Promise(function(resolve, reject) {\n","                let newScript = document.createElement(\"script\");\n","                newScript.onerror = reject;\n","                newScript.onload = resolve;\n","                document.body.appendChild(newScript);\n","                newScript.src = url;\n","            });\n","            }\n","            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n","            const iframe = document.createElement('iframe')\n","            iframe.style.cssText = \"width:0;height:0;border:none\"\n","            document.body.appendChild(iframe)\n","            const handshake = new Postmate({\n","                container: iframe,\n","                url: 'https://wandb.ai/authorize'\n","            });\n","            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n","            handshake.then(function(child) {\n","                child.on('authorize', data => {\n","                    clearTimeout(timeout)\n","                    resolve(data)\n","                });\n","            });\n","            })\n","        });\n","    "],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n"]},{"name":"stdout","output_type":"stream","text":["wandb: Paste an API key from your profile and hit enter: ··········\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"]},{"output_type":"stream","name":"stdout","text":["Create sweep with ID: oll8rllg\n","Sweep URL: https://wandb.ai/yeongu/index_predict_news_gru_deep_accuracy_dropX_300_COVIDX_sliding_drop_colab/sweeps/oll8rllg\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: kx6gav3k with config:\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 56\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3209695360393731\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 130\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tfeature: 3\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tnodes: 92\n","\u001b[34m\u001b[1mwandb\u001b[0m: \ttest_size: 37\n","\u001b[34m\u001b[1mwandb\u001b[0m: \ttrain_size: 11\n","\u001b[34m\u001b[1mwandb\u001b[0m: \twindow_size: 50\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33myeongu\u001b[0m (use `wandb login --relogin` to force relogin)\n"]},{"output_type":"display_data","data":{"text/html":["\n","                Tracking run with wandb version 0.12.1<br/>\n","                Syncing run <strong style=\"color:#cdcd00\">peachy-sweep-1</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n","                Project page: <a href=\"https://wandb.ai/yeongu/index_predict_news_gru_deep_accuracy_dropX_300_COVIDX_sliding_drop_colab\" target=\"_blank\">https://wandb.ai/yeongu/index_predict_news_gru_deep_accuracy_dropX_300_COVIDX_sliding_drop_colab</a><br/>\n","                Sweep page: <a href=\"https://wandb.ai/yeongu/index_predict_news_gru_deep_accuracy_dropX_300_COVIDX_sliding_drop_colab/sweeps/oll8rllg\" target=\"_blank\">https://wandb.ai/yeongu/index_predict_news_gru_deep_accuracy_dropX_300_COVIDX_sliding_drop_colab/sweeps/oll8rllg</a><br/>\n","Run page: <a href=\"https://wandb.ai/yeongu/index_predict_news_gru_deep_accuracy_dropX_300_COVIDX_sliding_drop_colab/runs/kx6gav3k\" target=\"_blank\">https://wandb.ai/yeongu/index_predict_news_gru_deep_accuracy_dropX_300_COVIDX_sliding_drop_colab/runs/kx6gav3k</a><br/>\n","                Run data is saved locally in <code>/content/wandb/run-20210904_131018-kx6gav3k</code><br/><br/>\n","            "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\u001b[1;30;43m스트리밍 출력 내용이 길어서 마지막 5000줄이 삭제되었습니다.\u001b[0m\n","Epoch 55/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2571 - accuracy: 0.5455 - val_loss: 0.2704 - val_accuracy: 0.4865\n","Epoch 56/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2350 - accuracy: 0.5455 - val_loss: 0.2712 - val_accuracy: 0.4865\n","Epoch 57/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2408 - accuracy: 0.5455 - val_loss: 0.2710 - val_accuracy: 0.4865\n","Epoch 58/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2368 - accuracy: 0.6364 - val_loss: 0.2703 - val_accuracy: 0.5135\n","Epoch 59/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2300 - accuracy: 0.6364 - val_loss: 0.2707 - val_accuracy: 0.4865\n","Epoch 60/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2390 - accuracy: 0.6364 - val_loss: 0.2736 - val_accuracy: 0.4865\n","Epoch 61/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2297 - accuracy: 0.5455 - val_loss: 0.2779 - val_accuracy: 0.4865\n","Epoch 62/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2216 - accuracy: 0.7273 - val_loss: 0.2903 - val_accuracy: 0.5135\n","Epoch 63/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2476 - accuracy: 0.5455 - val_loss: 0.3035 - val_accuracy: 0.5135\n","Epoch 64/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2362 - accuracy: 0.5455 - val_loss: 0.3207 - val_accuracy: 0.5135\n","Epoch 65/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2244 - accuracy: 0.5455 - val_loss: 0.3421 - val_accuracy: 0.4865\n","Epoch 66/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1972 - accuracy: 0.5455 - val_loss: 0.3704 - val_accuracy: 0.4865\n","Epoch 67/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2336 - accuracy: 0.5455 - val_loss: 0.3717 - val_accuracy: 0.5135\n","Epoch 68/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2740 - accuracy: 0.3636 - val_loss: 0.3552 - val_accuracy: 0.4865\n","Epoch 69/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2427 - accuracy: 0.5455 - val_loss: 0.3458 - val_accuracy: 0.4595\n","Epoch 70/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2222 - accuracy: 0.6364 - val_loss: 0.3493 - val_accuracy: 0.4595\n","Epoch 71/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2441 - accuracy: 0.6364 - val_loss: 0.3818 - val_accuracy: 0.4595\n","Epoch 72/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2518 - accuracy: 0.5455 - val_loss: 0.4252 - val_accuracy: 0.4595\n","Epoch 73/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2228 - accuracy: 0.5455 - val_loss: 0.5020 - val_accuracy: 0.4865\n","Epoch 74/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2083 - accuracy: 0.8182 - val_loss: 0.6508 - val_accuracy: 0.5135\n","Epoch 75/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2367 - accuracy: 0.4545 - val_loss: 0.7492 - val_accuracy: 0.4865\n","Epoch 76/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2098 - accuracy: 0.6364 - val_loss: 0.6834 - val_accuracy: 0.5135\n","Epoch 77/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2344 - accuracy: 0.5455 - val_loss: 0.5853 - val_accuracy: 0.4865\n","Epoch 78/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2225 - accuracy: 0.7273 - val_loss: 0.5635 - val_accuracy: 0.4595\n","Epoch 79/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2061 - accuracy: 0.7273 - val_loss: 0.6539 - val_accuracy: 0.4865\n","Epoch 80/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2367 - accuracy: 0.7273 - val_loss: 0.7644 - val_accuracy: 0.5135\n","Epoch 81/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1882 - accuracy: 0.8182 - val_loss: 0.8839 - val_accuracy: 0.5135\n","Epoch 82/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2240 - accuracy: 0.5455 - val_loss: 0.9213 - val_accuracy: 0.5135\n","Epoch 83/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2087 - accuracy: 0.6364 - val_loss: 0.9528 - val_accuracy: 0.5135\n","Epoch 84/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2222 - accuracy: 0.5455 - val_loss: 0.9773 - val_accuracy: 0.5135\n","Epoch 85/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2308 - accuracy: 0.4545 - val_loss: 1.0817 - val_accuracy: 0.5135\n","Epoch 86/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2301 - accuracy: 0.6364 - val_loss: 1.1719 - val_accuracy: 0.5135\n","Epoch 87/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2004 - accuracy: 0.6364 - val_loss: 1.2760 - val_accuracy: 0.4865\n","Epoch 88/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2238 - accuracy: 0.6364 - val_loss: 1.4088 - val_accuracy: 0.4865\n","Epoch 89/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2276 - accuracy: 0.7273 - val_loss: 1.3837 - val_accuracy: 0.4865\n","Epoch 90/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1927 - accuracy: 0.8182 - val_loss: 1.5173 - val_accuracy: 0.4865\n","Epoch 91/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2161 - accuracy: 0.8182 - val_loss: 1.7228 - val_accuracy: 0.4865\n","Epoch 92/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2216 - accuracy: 0.6364 - val_loss: 1.9781 - val_accuracy: 0.4865\n","Epoch 93/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1800 - accuracy: 0.8182 - val_loss: 1.8966 - val_accuracy: 0.4865\n","Epoch 94/130\n","1/1 [==============================] - 1s 961ms/step - loss: 0.2463 - accuracy: 0.6364 - val_loss: 1.5462 - val_accuracy: 0.5135\n","Epoch 95/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2121 - accuracy: 0.7273 - val_loss: 1.7164 - val_accuracy: 0.5135\n","Epoch 96/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2046 - accuracy: 0.7273 - val_loss: 2.0924 - val_accuracy: 0.4865\n","Epoch 97/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1979 - accuracy: 0.7273 - val_loss: 2.7861 - val_accuracy: 0.4865\n","Epoch 98/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2031 - accuracy: 0.7273 - val_loss: 2.4968 - val_accuracy: 0.4865\n","Epoch 99/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2082 - accuracy: 0.7273 - val_loss: 2.1415 - val_accuracy: 0.4865\n","Epoch 100/130\n","1/1 [==============================] - 1s 999ms/step - loss: 0.1918 - accuracy: 0.6364 - val_loss: 2.4658 - val_accuracy: 0.4865\n","Epoch 101/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1788 - accuracy: 0.5455 - val_loss: 3.0116 - val_accuracy: 0.4865\n","Epoch 102/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1471 - accuracy: 0.9091 - val_loss: 3.7443 - val_accuracy: 0.4865\n","Epoch 103/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1980 - accuracy: 0.8182 - val_loss: 4.6509 - val_accuracy: 0.4865\n","Epoch 104/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2640 - accuracy: 0.7273 - val_loss: 3.5818 - val_accuracy: 0.4865\n","Epoch 105/130\n","1/1 [==============================] - 1s 962ms/step - loss: 0.1870 - accuracy: 0.6364 - val_loss: 3.4720 - val_accuracy: 0.4865\n","Epoch 106/130\n","1/1 [==============================] - 1s 987ms/step - loss: 0.1543 - accuracy: 0.8182 - val_loss: 4.0774 - val_accuracy: 0.4865\n","Epoch 107/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1639 - accuracy: 0.7273 - val_loss: 4.0059 - val_accuracy: 0.4865\n","Epoch 108/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2591 - accuracy: 0.7273 - val_loss: 2.7100 - val_accuracy: 0.4865\n","Epoch 109/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1941 - accuracy: 0.5455 - val_loss: 2.3496 - val_accuracy: 0.5135\n","Epoch 110/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2491 - accuracy: 0.5455 - val_loss: 2.1817 - val_accuracy: 0.5135\n","Epoch 111/130\n","1/1 [==============================] - 1s 992ms/step - loss: 0.2124 - accuracy: 0.5455 - val_loss: 2.5526 - val_accuracy: 0.4865\n","Epoch 112/130\n","1/1 [==============================] - 1s 994ms/step - loss: 0.2340 - accuracy: 0.5455 - val_loss: 3.6761 - val_accuracy: 0.4865\n","Epoch 113/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1433 - accuracy: 0.8182 - val_loss: 5.2612 - val_accuracy: 0.4865\n","Epoch 114/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1926 - accuracy: 0.8182 - val_loss: 4.0255 - val_accuracy: 0.4865\n","Epoch 115/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1600 - accuracy: 0.7273 - val_loss: 2.6269 - val_accuracy: 0.4865\n","Epoch 116/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1971 - accuracy: 0.6364 - val_loss: 1.9333 - val_accuracy: 0.5135\n","Epoch 117/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2468 - accuracy: 0.6364 - val_loss: 1.7852 - val_accuracy: 0.5135\n","Epoch 118/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2507 - accuracy: 0.5455 - val_loss: 1.9247 - val_accuracy: 0.4865\n","Epoch 119/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1672 - accuracy: 0.7273 - val_loss: 2.4838 - val_accuracy: 0.4865\n","Epoch 120/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2120 - accuracy: 0.5455 - val_loss: 3.1630 - val_accuracy: 0.4865\n","Epoch 121/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2338 - accuracy: 0.5455 - val_loss: 3.4428 - val_accuracy: 0.4865\n","Epoch 122/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1809 - accuracy: 0.8182 - val_loss: 3.2475 - val_accuracy: 0.4865\n","Epoch 123/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2507 - accuracy: 0.6364 - val_loss: 2.6596 - val_accuracy: 0.4865\n","Epoch 124/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2073 - accuracy: 0.8182 - val_loss: 2.1227 - val_accuracy: 0.4865\n","Epoch 125/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1877 - accuracy: 0.7273 - val_loss: 1.9194 - val_accuracy: 0.4865\n","Epoch 126/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2083 - accuracy: 0.8182 - val_loss: 1.7644 - val_accuracy: 0.4865\n","Epoch 127/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2095 - accuracy: 0.5455 - val_loss: 1.7968 - val_accuracy: 0.4865\n","Epoch 128/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1988 - accuracy: 0.6364 - val_loss: 2.0128 - val_accuracy: 0.4865\n","Epoch 129/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1915 - accuracy: 0.5455 - val_loss: 2.3424 - val_accuracy: 0.4865\n","Epoch 130/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1504 - accuracy: 0.8182 - val_loss: 2.6312 - val_accuracy: 0.4865\n","2/2 [==============================] - 0s 84ms/step - loss: 2.6312 - accuracy: 0.4865\n","loss :  0.4864864945411682\n","total_loss :  1.054054081439972\n","num :  2\n","WARNING:tensorflow:Layer gru_10 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","WARNING:tensorflow:Layer gru_11 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","WARNING:tensorflow:Layer gru_12 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","WARNING:tensorflow:Layer gru_13 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","WARNING:tensorflow:Layer gru_14 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","Epoch 1/130\n","1/1 [==============================] - 12s 12s/step - loss: 0.5614 - accuracy: 0.4545 - val_loss: 0.5357 - val_accuracy: 0.4324\n","Epoch 2/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.5147 - accuracy: 0.4545 - val_loss: 0.5040 - val_accuracy: 0.4324\n","Epoch 3/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.4760 - accuracy: 0.4545 - val_loss: 0.4683 - val_accuracy: 0.4324\n","Epoch 4/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.4385 - accuracy: 0.4545 - val_loss: 0.4239 - val_accuracy: 0.4324\n","Epoch 5/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.4006 - accuracy: 0.4545 - val_loss: 0.3722 - val_accuracy: 0.4324\n","Epoch 6/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.3262 - accuracy: 0.4545 - val_loss: 0.3173 - val_accuracy: 0.4324\n","Epoch 7/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2855 - accuracy: 0.4545 - val_loss: 0.2685 - val_accuracy: 0.4324\n","Epoch 8/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2477 - accuracy: 0.6364 - val_loss: 0.2472 - val_accuracy: 0.5676\n","Epoch 9/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2737 - accuracy: 0.5455 - val_loss: 0.2535 - val_accuracy: 0.5676\n","Epoch 10/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.3169 - accuracy: 0.5455 - val_loss: 0.2497 - val_accuracy: 0.5676\n","Epoch 11/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.3046 - accuracy: 0.5455 - val_loss: 0.2464 - val_accuracy: 0.5676\n","Epoch 12/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.3030 - accuracy: 0.5455 - val_loss: 0.2520 - val_accuracy: 0.4324\n","Epoch 13/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2418 - accuracy: 0.5455 - val_loss: 0.2632 - val_accuracy: 0.4324\n","Epoch 14/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2431 - accuracy: 0.6364 - val_loss: 0.2749 - val_accuracy: 0.4324\n","Epoch 15/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2512 - accuracy: 0.6364 - val_loss: 0.2844 - val_accuracy: 0.4324\n","Epoch 16/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2411 - accuracy: 0.4545 - val_loss: 0.2897 - val_accuracy: 0.4324\n","Epoch 17/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2719 - accuracy: 0.4545 - val_loss: 0.2917 - val_accuracy: 0.4324\n","Epoch 18/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2614 - accuracy: 0.4545 - val_loss: 0.2902 - val_accuracy: 0.4324\n","Epoch 19/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2732 - accuracy: 0.4545 - val_loss: 0.2860 - val_accuracy: 0.4324\n","Epoch 20/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2576 - accuracy: 0.4545 - val_loss: 0.2797 - val_accuracy: 0.4324\n","Epoch 21/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2622 - accuracy: 0.4545 - val_loss: 0.2722 - val_accuracy: 0.4324\n","Epoch 22/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2609 - accuracy: 0.3636 - val_loss: 0.2647 - val_accuracy: 0.4324\n","Epoch 23/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2493 - accuracy: 0.5455 - val_loss: 0.2576 - val_accuracy: 0.4324\n","Epoch 24/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2404 - accuracy: 0.6364 - val_loss: 0.2517 - val_accuracy: 0.4324\n","Epoch 25/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2418 - accuracy: 0.4545 - val_loss: 0.2480 - val_accuracy: 0.6216\n","Epoch 26/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2239 - accuracy: 0.6364 - val_loss: 0.2458 - val_accuracy: 0.5676\n","Epoch 27/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2546 - accuracy: 0.5455 - val_loss: 0.2450 - val_accuracy: 0.5676\n","Epoch 28/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2371 - accuracy: 0.5455 - val_loss: 0.2448 - val_accuracy: 0.5676\n","Epoch 29/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2329 - accuracy: 0.5455 - val_loss: 0.2449 - val_accuracy: 0.5676\n","Epoch 30/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2463 - accuracy: 0.5455 - val_loss: 0.2454 - val_accuracy: 0.5676\n","Epoch 31/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2681 - accuracy: 0.5455 - val_loss: 0.2469 - val_accuracy: 0.5946\n","Epoch 32/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2426 - accuracy: 0.4545 - val_loss: 0.2491 - val_accuracy: 0.5405\n","Epoch 33/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2532 - accuracy: 0.4545 - val_loss: 0.2522 - val_accuracy: 0.4595\n","Epoch 34/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2434 - accuracy: 0.6364 - val_loss: 0.2549 - val_accuracy: 0.4054\n","Epoch 35/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2365 - accuracy: 0.5455 - val_loss: 0.2568 - val_accuracy: 0.4324\n","Epoch 36/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2469 - accuracy: 0.5455 - val_loss: 0.2578 - val_accuracy: 0.4324\n","Epoch 37/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2422 - accuracy: 0.6364 - val_loss: 0.2578 - val_accuracy: 0.4324\n","Epoch 38/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2446 - accuracy: 0.5455 - val_loss: 0.2571 - val_accuracy: 0.4324\n","Epoch 39/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2375 - accuracy: 0.5455 - val_loss: 0.2556 - val_accuracy: 0.4054\n","Epoch 40/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2417 - accuracy: 0.4545 - val_loss: 0.2536 - val_accuracy: 0.4324\n","Epoch 41/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2416 - accuracy: 0.6364 - val_loss: 0.2511 - val_accuracy: 0.5135\n","Epoch 42/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2476 - accuracy: 0.5455 - val_loss: 0.2485 - val_accuracy: 0.5946\n","Epoch 43/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2443 - accuracy: 0.6364 - val_loss: 0.2465 - val_accuracy: 0.5676\n","Epoch 44/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2474 - accuracy: 0.5455 - val_loss: 0.2452 - val_accuracy: 0.5676\n","Epoch 45/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2391 - accuracy: 0.6364 - val_loss: 0.2447 - val_accuracy: 0.5676\n","Epoch 46/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2397 - accuracy: 0.5455 - val_loss: 0.2445 - val_accuracy: 0.5676\n","Epoch 47/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2389 - accuracy: 0.5455 - val_loss: 0.2446 - val_accuracy: 0.5676\n","Epoch 48/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2486 - accuracy: 0.5455 - val_loss: 0.2447 - val_accuracy: 0.5676\n","Epoch 49/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2165 - accuracy: 0.5455 - val_loss: 0.2449 - val_accuracy: 0.5676\n","Epoch 50/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2257 - accuracy: 0.5455 - val_loss: 0.2453 - val_accuracy: 0.5676\n","Epoch 51/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2451 - accuracy: 0.5455 - val_loss: 0.2460 - val_accuracy: 0.5405\n","Epoch 52/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2277 - accuracy: 0.5455 - val_loss: 0.2466 - val_accuracy: 0.5405\n","Epoch 53/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2175 - accuracy: 0.7273 - val_loss: 0.2472 - val_accuracy: 0.5676\n","Epoch 54/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2472 - accuracy: 0.5455 - val_loss: 0.2479 - val_accuracy: 0.5676\n","Epoch 55/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2213 - accuracy: 0.4545 - val_loss: 0.2483 - val_accuracy: 0.5676\n","Epoch 56/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2259 - accuracy: 0.6364 - val_loss: 0.2483 - val_accuracy: 0.5676\n","Epoch 57/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2371 - accuracy: 0.7273 - val_loss: 0.2479 - val_accuracy: 0.5405\n","Epoch 58/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2314 - accuracy: 0.7273 - val_loss: 0.2474 - val_accuracy: 0.5676\n","Epoch 59/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2163 - accuracy: 0.6364 - val_loss: 0.2473 - val_accuracy: 0.5676\n","Epoch 60/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2092 - accuracy: 0.8182 - val_loss: 0.2487 - val_accuracy: 0.5676\n","Epoch 61/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2159 - accuracy: 0.5455 - val_loss: 0.2519 - val_accuracy: 0.5676\n","Epoch 62/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2253 - accuracy: 0.5455 - val_loss: 0.2542 - val_accuracy: 0.5676\n","Epoch 63/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2216 - accuracy: 0.5455 - val_loss: 0.2562 - val_accuracy: 0.5676\n","Epoch 64/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2195 - accuracy: 0.5455 - val_loss: 0.2561 - val_accuracy: 0.5676\n","Epoch 65/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2376 - accuracy: 0.5455 - val_loss: 0.2556 - val_accuracy: 0.5676\n","Epoch 66/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2155 - accuracy: 0.6364 - val_loss: 0.2558 - val_accuracy: 0.5676\n","Epoch 67/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2254 - accuracy: 0.6364 - val_loss: 0.2552 - val_accuracy: 0.5676\n","Epoch 68/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2235 - accuracy: 0.6364 - val_loss: 0.2558 - val_accuracy: 0.5676\n","Epoch 69/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1961 - accuracy: 0.6364 - val_loss: 0.2585 - val_accuracy: 0.5676\n","Epoch 70/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2033 - accuracy: 0.8182 - val_loss: 0.2644 - val_accuracy: 0.5676\n","Epoch 71/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2134 - accuracy: 0.7273 - val_loss: 0.2749 - val_accuracy: 0.5676\n","Epoch 72/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2304 - accuracy: 0.7273 - val_loss: 0.2735 - val_accuracy: 0.5676\n","Epoch 73/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1990 - accuracy: 0.7273 - val_loss: 0.2726 - val_accuracy: 0.5676\n","Epoch 74/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1945 - accuracy: 0.7273 - val_loss: 0.2736 - val_accuracy: 0.5676\n","Epoch 75/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2068 - accuracy: 0.6364 - val_loss: 0.2760 - val_accuracy: 0.5676\n","Epoch 76/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1783 - accuracy: 0.8182 - val_loss: 0.2827 - val_accuracy: 0.5676\n","Epoch 77/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1893 - accuracy: 0.7273 - val_loss: 0.2987 - val_accuracy: 0.5676\n","Epoch 78/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1786 - accuracy: 0.8182 - val_loss: 0.3234 - val_accuracy: 0.5676\n","Epoch 79/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1778 - accuracy: 0.8182 - val_loss: 0.3418 - val_accuracy: 0.5676\n","Epoch 80/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1859 - accuracy: 0.6364 - val_loss: 0.3621 - val_accuracy: 0.5676\n","Epoch 81/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1934 - accuracy: 0.7273 - val_loss: 0.3870 - val_accuracy: 0.5676\n","Epoch 82/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1539 - accuracy: 0.8182 - val_loss: 0.4332 - val_accuracy: 0.5676\n","Epoch 83/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1742 - accuracy: 0.6364 - val_loss: 0.4942 - val_accuracy: 0.5676\n","Epoch 84/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1814 - accuracy: 0.7273 - val_loss: 0.5877 - val_accuracy: 0.5676\n","Epoch 85/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1960 - accuracy: 0.8182 - val_loss: 0.8313 - val_accuracy: 0.5676\n","Epoch 86/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1131 - accuracy: 0.9091 - val_loss: 1.1413 - val_accuracy: 0.5676\n","Epoch 87/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2491 - accuracy: 0.6364 - val_loss: 0.6992 - val_accuracy: 0.5676\n","Epoch 88/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1525 - accuracy: 0.9091 - val_loss: 0.5221 - val_accuracy: 0.5676\n","Epoch 89/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1390 - accuracy: 0.8182 - val_loss: 0.4267 - val_accuracy: 0.5405\n","Epoch 90/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2019 - accuracy: 0.6364 - val_loss: 0.4076 - val_accuracy: 0.5676\n","Epoch 91/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1926 - accuracy: 0.7273 - val_loss: 0.4093 - val_accuracy: 0.5676\n","Epoch 92/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1278 - accuracy: 0.9091 - val_loss: 0.4496 - val_accuracy: 0.5676\n","Epoch 93/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1119 - accuracy: 1.0000 - val_loss: 0.5212 - val_accuracy: 0.5405\n","Epoch 94/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1543 - accuracy: 0.8182 - val_loss: 0.6097 - val_accuracy: 0.5676\n","Epoch 95/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1068 - accuracy: 0.9091 - val_loss: 0.6673 - val_accuracy: 0.5676\n","Epoch 96/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2253 - accuracy: 0.7273 - val_loss: 0.4955 - val_accuracy: 0.5405\n","Epoch 97/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1080 - accuracy: 0.9091 - val_loss: 0.4155 - val_accuracy: 0.5405\n","Epoch 98/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1648 - accuracy: 0.8182 - val_loss: 0.3923 - val_accuracy: 0.5405\n","Epoch 99/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1565 - accuracy: 0.7273 - val_loss: 0.4074 - val_accuracy: 0.5676\n","Epoch 100/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1709 - accuracy: 0.8182 - val_loss: 0.4714 - val_accuracy: 0.5676\n","Epoch 101/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1815 - accuracy: 0.7273 - val_loss: 0.6287 - val_accuracy: 0.5676\n","Epoch 102/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1480 - accuracy: 0.8182 - val_loss: 0.7018 - val_accuracy: 0.5676\n","Epoch 103/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1659 - accuracy: 0.8182 - val_loss: 0.6726 - val_accuracy: 0.5676\n","Epoch 104/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1374 - accuracy: 0.8182 - val_loss: 0.5801 - val_accuracy: 0.5676\n","Epoch 105/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1526 - accuracy: 0.8182 - val_loss: 0.4694 - val_accuracy: 0.5676\n","Epoch 106/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1625 - accuracy: 0.7273 - val_loss: 0.4343 - val_accuracy: 0.5676\n","Epoch 107/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1389 - accuracy: 0.8182 - val_loss: 0.4078 - val_accuracy: 0.5405\n","Epoch 108/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1274 - accuracy: 0.9091 - val_loss: 0.3965 - val_accuracy: 0.5405\n","Epoch 109/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1105 - accuracy: 0.8182 - val_loss: 0.4058 - val_accuracy: 0.5405\n","Epoch 110/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1362 - accuracy: 0.7273 - val_loss: 0.4399 - val_accuracy: 0.5676\n","Epoch 111/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2139 - accuracy: 0.4545 - val_loss: 0.4919 - val_accuracy: 0.5676\n","Epoch 112/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1311 - accuracy: 0.8182 - val_loss: 0.5344 - val_accuracy: 0.5676\n","Epoch 113/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1077 - accuracy: 0.8182 - val_loss: 0.5833 - val_accuracy: 0.5676\n","Epoch 114/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1173 - accuracy: 1.0000 - val_loss: 0.5566 - val_accuracy: 0.5676\n","Epoch 115/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1328 - accuracy: 0.7273 - val_loss: 0.5430 - val_accuracy: 0.5676\n","Epoch 116/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1384 - accuracy: 0.8182 - val_loss: 0.5293 - val_accuracy: 0.5676\n","Epoch 117/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1138 - accuracy: 0.8182 - val_loss: 0.5448 - val_accuracy: 0.5676\n","Epoch 118/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1109 - accuracy: 0.8182 - val_loss: 0.6143 - val_accuracy: 0.5676\n","Epoch 119/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.0982 - accuracy: 0.9091 - val_loss: 0.7481 - val_accuracy: 0.5676\n","Epoch 120/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1089 - accuracy: 0.9091 - val_loss: 0.8319 - val_accuracy: 0.5676\n","Epoch 121/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1222 - accuracy: 0.9091 - val_loss: 0.8259 - val_accuracy: 0.5676\n","Epoch 122/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1802 - accuracy: 0.8182 - val_loss: 0.6344 - val_accuracy: 0.5676\n","Epoch 123/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1318 - accuracy: 0.8182 - val_loss: 0.5304 - val_accuracy: 0.5676\n","Epoch 124/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.0994 - accuracy: 0.9091 - val_loss: 0.5050 - val_accuracy: 0.5676\n","Epoch 125/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1209 - accuracy: 0.9091 - val_loss: 0.5179 - val_accuracy: 0.5676\n","Epoch 126/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1498 - accuracy: 0.8182 - val_loss: 0.5182 - val_accuracy: 0.5676\n","Epoch 127/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1218 - accuracy: 0.7273 - val_loss: 0.5385 - val_accuracy: 0.5676\n","Epoch 128/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1345 - accuracy: 0.8182 - val_loss: 0.5757 - val_accuracy: 0.5676\n","Epoch 129/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1126 - accuracy: 0.9091 - val_loss: 0.6400 - val_accuracy: 0.5676\n","Epoch 130/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1266 - accuracy: 0.9091 - val_loss: 0.7816 - val_accuracy: 0.5676\n","2/2 [==============================] - 0s 93ms/step - loss: 0.7816 - accuracy: 0.5676\n","loss :  0.5675675868988037\n","total_loss :  1.6216216683387756\n","num :  3\n","WARNING:tensorflow:Layer gru_15 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","WARNING:tensorflow:Layer gru_16 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","WARNING:tensorflow:Layer gru_17 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","WARNING:tensorflow:Layer gru_18 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","WARNING:tensorflow:Layer gru_19 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","Epoch 1/130\n","1/1 [==============================] - 11s 11s/step - loss: 0.4085 - accuracy: 0.6364 - val_loss: 0.5077 - val_accuracy: 0.4865\n","Epoch 2/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.3649 - accuracy: 0.6364 - val_loss: 0.4830 - val_accuracy: 0.4865\n","Epoch 3/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.3404 - accuracy: 0.6364 - val_loss: 0.4626 - val_accuracy: 0.4865\n","Epoch 4/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.3251 - accuracy: 0.6364 - val_loss: 0.4412 - val_accuracy: 0.4865\n","Epoch 5/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.3062 - accuracy: 0.6364 - val_loss: 0.4148 - val_accuracy: 0.4865\n","Epoch 6/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2902 - accuracy: 0.6364 - val_loss: 0.3825 - val_accuracy: 0.4865\n","Epoch 7/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2707 - accuracy: 0.6364 - val_loss: 0.3477 - val_accuracy: 0.4865\n","Epoch 8/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2451 - accuracy: 0.6364 - val_loss: 0.3122 - val_accuracy: 0.4865\n","Epoch 9/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2346 - accuracy: 0.6364 - val_loss: 0.2809 - val_accuracy: 0.4865\n","Epoch 10/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2335 - accuracy: 0.6364 - val_loss: 0.2634 - val_accuracy: 0.4865\n","Epoch 11/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2501 - accuracy: 0.4545 - val_loss: 0.2590 - val_accuracy: 0.4865\n","Epoch 12/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2651 - accuracy: 0.4545 - val_loss: 0.2609 - val_accuracy: 0.4865\n","Epoch 13/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2579 - accuracy: 0.2727 - val_loss: 0.2672 - val_accuracy: 0.4865\n","Epoch 14/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2690 - accuracy: 0.3636 - val_loss: 0.2778 - val_accuracy: 0.4865\n","Epoch 15/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2231 - accuracy: 0.6364 - val_loss: 0.2893 - val_accuracy: 0.4865\n","Epoch 16/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2304 - accuracy: 0.6364 - val_loss: 0.2995 - val_accuracy: 0.4865\n","Epoch 17/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2333 - accuracy: 0.6364 - val_loss: 0.3079 - val_accuracy: 0.4865\n","Epoch 18/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2458 - accuracy: 0.6364 - val_loss: 0.3147 - val_accuracy: 0.4865\n","Epoch 19/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2384 - accuracy: 0.6364 - val_loss: 0.3189 - val_accuracy: 0.4865\n","Epoch 20/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2378 - accuracy: 0.6364 - val_loss: 0.3205 - val_accuracy: 0.4865\n","Epoch 21/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2271 - accuracy: 0.6364 - val_loss: 0.3198 - val_accuracy: 0.4865\n","Epoch 22/130\n","1/1 [==============================] - 2s 2s/step - loss: 0.2376 - accuracy: 0.6364 - val_loss: 0.3171 - val_accuracy: 0.4865\n","Epoch 23/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2266 - accuracy: 0.6364 - val_loss: 0.3127 - val_accuracy: 0.4865\n","Epoch 24/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2303 - accuracy: 0.6364 - val_loss: 0.3071 - val_accuracy: 0.4865\n","Epoch 25/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2206 - accuracy: 0.6364 - val_loss: 0.3005 - val_accuracy: 0.4865\n","Epoch 26/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2201 - accuracy: 0.6364 - val_loss: 0.2938 - val_accuracy: 0.4865\n","Epoch 27/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2237 - accuracy: 0.6364 - val_loss: 0.2875 - val_accuracy: 0.4865\n","Epoch 28/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2331 - accuracy: 0.6364 - val_loss: 0.2825 - val_accuracy: 0.4865\n","Epoch 29/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2343 - accuracy: 0.6364 - val_loss: 0.2790 - val_accuracy: 0.4865\n","Epoch 30/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2426 - accuracy: 0.6364 - val_loss: 0.2775 - val_accuracy: 0.4865\n","Epoch 31/130\n","1/1 [==============================] - 2s 2s/step - loss: 0.2232 - accuracy: 0.6364 - val_loss: 0.2770 - val_accuracy: 0.4865\n","Epoch 32/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2396 - accuracy: 0.5455 - val_loss: 0.2783 - val_accuracy: 0.4865\n","Epoch 33/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2223 - accuracy: 0.6364 - val_loss: 0.2804 - val_accuracy: 0.4865\n","Epoch 34/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2261 - accuracy: 0.6364 - val_loss: 0.2832 - val_accuracy: 0.4865\n","Epoch 35/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2408 - accuracy: 0.6364 - val_loss: 0.2870 - val_accuracy: 0.4865\n","Epoch 36/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2344 - accuracy: 0.6364 - val_loss: 0.2905 - val_accuracy: 0.4865\n","Epoch 37/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2288 - accuracy: 0.6364 - val_loss: 0.2934 - val_accuracy: 0.4865\n","Epoch 38/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2314 - accuracy: 0.6364 - val_loss: 0.2961 - val_accuracy: 0.4865\n","Epoch 39/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2259 - accuracy: 0.6364 - val_loss: 0.2976 - val_accuracy: 0.4865\n","Epoch 40/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2220 - accuracy: 0.6364 - val_loss: 0.2975 - val_accuracy: 0.4865\n","Epoch 41/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2341 - accuracy: 0.6364 - val_loss: 0.2970 - val_accuracy: 0.4865\n","Epoch 42/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2419 - accuracy: 0.6364 - val_loss: 0.2963 - val_accuracy: 0.4865\n","Epoch 43/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2344 - accuracy: 0.6364 - val_loss: 0.2952 - val_accuracy: 0.4865\n","Epoch 44/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2356 - accuracy: 0.6364 - val_loss: 0.2936 - val_accuracy: 0.4865\n","Epoch 45/130\n","1/1 [==============================] - 2s 2s/step - loss: 0.2408 - accuracy: 0.6364 - val_loss: 0.2922 - val_accuracy: 0.4865\n","Epoch 46/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2386 - accuracy: 0.6364 - val_loss: 0.2908 - val_accuracy: 0.4865\n","Epoch 47/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2571 - accuracy: 0.6364 - val_loss: 0.2911 - val_accuracy: 0.4865\n","Epoch 48/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2371 - accuracy: 0.6364 - val_loss: 0.2916 - val_accuracy: 0.4865\n","Epoch 49/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2293 - accuracy: 0.6364 - val_loss: 0.2912 - val_accuracy: 0.4865\n","Epoch 50/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2203 - accuracy: 0.6364 - val_loss: 0.2898 - val_accuracy: 0.4865\n","Epoch 51/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2397 - accuracy: 0.6364 - val_loss: 0.2886 - val_accuracy: 0.4865\n","Epoch 52/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2339 - accuracy: 0.6364 - val_loss: 0.2878 - val_accuracy: 0.4865\n","Epoch 53/130\n","1/1 [==============================] - 2s 2s/step - loss: 0.2260 - accuracy: 0.6364 - val_loss: 0.2865 - val_accuracy: 0.4865\n","Epoch 54/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2384 - accuracy: 0.6364 - val_loss: 0.2859 - val_accuracy: 0.4865\n","Epoch 55/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2367 - accuracy: 0.6364 - val_loss: 0.2855 - val_accuracy: 0.4865\n","Epoch 56/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2439 - accuracy: 0.6364 - val_loss: 0.2861 - val_accuracy: 0.4865\n","Epoch 57/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2287 - accuracy: 0.6364 - val_loss: 0.2866 - val_accuracy: 0.4865\n","Epoch 58/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2334 - accuracy: 0.6364 - val_loss: 0.2871 - val_accuracy: 0.4865\n","Epoch 59/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2276 - accuracy: 0.6364 - val_loss: 0.2871 - val_accuracy: 0.4865\n","Epoch 60/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2293 - accuracy: 0.6364 - val_loss: 0.2870 - val_accuracy: 0.4865\n","Epoch 61/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2217 - accuracy: 0.6364 - val_loss: 0.2863 - val_accuracy: 0.4865\n","Epoch 62/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2211 - accuracy: 0.6364 - val_loss: 0.2855 - val_accuracy: 0.4865\n","Epoch 63/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2379 - accuracy: 0.6364 - val_loss: 0.2858 - val_accuracy: 0.4865\n","Epoch 64/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2236 - accuracy: 0.6364 - val_loss: 0.2858 - val_accuracy: 0.4865\n","Epoch 65/130\n","1/1 [==============================] - 2s 2s/step - loss: 0.2377 - accuracy: 0.6364 - val_loss: 0.2862 - val_accuracy: 0.4865\n","Epoch 66/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2445 - accuracy: 0.6364 - val_loss: 0.2872 - val_accuracy: 0.4865\n","Epoch 67/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2227 - accuracy: 0.6364 - val_loss: 0.2877 - val_accuracy: 0.4865\n","Epoch 68/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2343 - accuracy: 0.6364 - val_loss: 0.2887 - val_accuracy: 0.4865\n","Epoch 69/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2218 - accuracy: 0.6364 - val_loss: 0.2887 - val_accuracy: 0.4865\n","Epoch 70/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2240 - accuracy: 0.6364 - val_loss: 0.2881 - val_accuracy: 0.4865\n","Epoch 71/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2327 - accuracy: 0.6364 - val_loss: 0.2873 - val_accuracy: 0.4865\n","Epoch 72/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2384 - accuracy: 0.6364 - val_loss: 0.2863 - val_accuracy: 0.4865\n","Epoch 73/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2340 - accuracy: 0.6364 - val_loss: 0.2859 - val_accuracy: 0.4865\n","Epoch 74/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2245 - accuracy: 0.6364 - val_loss: 0.2855 - val_accuracy: 0.4865\n","Epoch 75/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2266 - accuracy: 0.6364 - val_loss: 0.2850 - val_accuracy: 0.4865\n","Epoch 76/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2222 - accuracy: 0.6364 - val_loss: 0.2840 - val_accuracy: 0.4865\n","Epoch 77/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2444 - accuracy: 0.6364 - val_loss: 0.2835 - val_accuracy: 0.4865\n","Epoch 78/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2175 - accuracy: 0.6364 - val_loss: 0.2826 - val_accuracy: 0.4865\n","Epoch 79/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2379 - accuracy: 0.6364 - val_loss: 0.2826 - val_accuracy: 0.4865\n","Epoch 80/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2309 - accuracy: 0.6364 - val_loss: 0.2823 - val_accuracy: 0.4865\n","Epoch 81/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2278 - accuracy: 0.6364 - val_loss: 0.2817 - val_accuracy: 0.4865\n","Epoch 82/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2307 - accuracy: 0.6364 - val_loss: 0.2807 - val_accuracy: 0.4865\n","Epoch 83/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2198 - accuracy: 0.6364 - val_loss: 0.2804 - val_accuracy: 0.4865\n","Epoch 84/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2276 - accuracy: 0.6364 - val_loss: 0.2808 - val_accuracy: 0.4865\n","Epoch 85/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2338 - accuracy: 0.6364 - val_loss: 0.2816 - val_accuracy: 0.4865\n","Epoch 86/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2292 - accuracy: 0.6364 - val_loss: 0.2826 - val_accuracy: 0.4865\n","Epoch 87/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2257 - accuracy: 0.6364 - val_loss: 0.2832 - val_accuracy: 0.4865\n","Epoch 88/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2302 - accuracy: 0.6364 - val_loss: 0.2843 - val_accuracy: 0.4865\n","Epoch 89/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2330 - accuracy: 0.6364 - val_loss: 0.2854 - val_accuracy: 0.4865\n","Epoch 90/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2358 - accuracy: 0.6364 - val_loss: 0.2865 - val_accuracy: 0.4865\n","Epoch 91/130\n","1/1 [==============================] - 2s 2s/step - loss: 0.2419 - accuracy: 0.6364 - val_loss: 0.2877 - val_accuracy: 0.4865\n","Epoch 92/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2221 - accuracy: 0.6364 - val_loss: 0.2878 - val_accuracy: 0.4865\n","Epoch 93/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2216 - accuracy: 0.6364 - val_loss: 0.2862 - val_accuracy: 0.4865\n","Epoch 94/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2373 - accuracy: 0.6364 - val_loss: 0.2850 - val_accuracy: 0.4865\n","Epoch 95/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2316 - accuracy: 0.6364 - val_loss: 0.2840 - val_accuracy: 0.4865\n","Epoch 96/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2329 - accuracy: 0.6364 - val_loss: 0.2830 - val_accuracy: 0.4865\n","Epoch 97/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2187 - accuracy: 0.6364 - val_loss: 0.2811 - val_accuracy: 0.4865\n","Epoch 98/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2243 - accuracy: 0.6364 - val_loss: 0.2797 - val_accuracy: 0.4865\n","Epoch 99/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2494 - accuracy: 0.6364 - val_loss: 0.2805 - val_accuracy: 0.4865\n","Epoch 100/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2227 - accuracy: 0.6364 - val_loss: 0.2805 - val_accuracy: 0.4865\n","Epoch 101/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2476 - accuracy: 0.6364 - val_loss: 0.2819 - val_accuracy: 0.4865\n","Epoch 102/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2282 - accuracy: 0.6364 - val_loss: 0.2829 - val_accuracy: 0.4865\n","Epoch 103/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2279 - accuracy: 0.6364 - val_loss: 0.2830 - val_accuracy: 0.4865\n","Epoch 104/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2244 - accuracy: 0.6364 - val_loss: 0.2830 - val_accuracy: 0.4865\n","Epoch 105/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2153 - accuracy: 0.6364 - val_loss: 0.2821 - val_accuracy: 0.4865\n","Epoch 106/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2312 - accuracy: 0.6364 - val_loss: 0.2810 - val_accuracy: 0.4865\n","Epoch 107/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2253 - accuracy: 0.6364 - val_loss: 0.2802 - val_accuracy: 0.4865\n","Epoch 108/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2234 - accuracy: 0.6364 - val_loss: 0.2794 - val_accuracy: 0.4865\n","Epoch 109/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2273 - accuracy: 0.6364 - val_loss: 0.2786 - val_accuracy: 0.4865\n","Epoch 110/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2337 - accuracy: 0.6364 - val_loss: 0.2781 - val_accuracy: 0.4865\n","Epoch 111/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2418 - accuracy: 0.6364 - val_loss: 0.2789 - val_accuracy: 0.4865\n","Epoch 112/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2354 - accuracy: 0.6364 - val_loss: 0.2799 - val_accuracy: 0.4865\n","Epoch 113/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2357 - accuracy: 0.6364 - val_loss: 0.2806 - val_accuracy: 0.4865\n","Epoch 114/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2132 - accuracy: 0.6364 - val_loss: 0.2794 - val_accuracy: 0.4865\n","Epoch 115/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2299 - accuracy: 0.6364 - val_loss: 0.2781 - val_accuracy: 0.4865\n","Epoch 116/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2148 - accuracy: 0.6364 - val_loss: 0.2764 - val_accuracy: 0.4865\n","Epoch 117/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2212 - accuracy: 0.6364 - val_loss: 0.2742 - val_accuracy: 0.4865\n","Epoch 118/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2259 - accuracy: 0.6364 - val_loss: 0.2732 - val_accuracy: 0.4865\n","Epoch 119/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2133 - accuracy: 0.6364 - val_loss: 0.2722 - val_accuracy: 0.4865\n","Epoch 120/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2223 - accuracy: 0.6364 - val_loss: 0.2727 - val_accuracy: 0.4865\n","Epoch 121/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2287 - accuracy: 0.6364 - val_loss: 0.2734 - val_accuracy: 0.4865\n","Epoch 122/130\n","1/1 [==============================] - 2s 2s/step - loss: 0.2216 - accuracy: 0.6364 - val_loss: 0.2748 - val_accuracy: 0.4865\n","Epoch 123/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2295 - accuracy: 0.6364 - val_loss: 0.2781 - val_accuracy: 0.4865\n","Epoch 124/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2402 - accuracy: 0.6364 - val_loss: 0.2819 - val_accuracy: 0.4865\n","Epoch 125/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2376 - accuracy: 0.6364 - val_loss: 0.2852 - val_accuracy: 0.4865\n","Epoch 126/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2202 - accuracy: 0.6364 - val_loss: 0.2849 - val_accuracy: 0.4865\n","Epoch 127/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2390 - accuracy: 0.6364 - val_loss: 0.2833 - val_accuracy: 0.4865\n","Epoch 128/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2491 - accuracy: 0.6364 - val_loss: 0.2812 - val_accuracy: 0.4865\n","Epoch 129/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2215 - accuracy: 0.6364 - val_loss: 0.2782 - val_accuracy: 0.4865\n","Epoch 130/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2139 - accuracy: 0.6364 - val_loss: 0.2746 - val_accuracy: 0.4865\n","2/2 [==============================] - 0s 99ms/step - loss: 0.2746 - accuracy: 0.4865\n","loss :  0.4864864945411682\n","total_loss :  2.108108162879944\n","num :  4\n","WARNING:tensorflow:Layer gru_20 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","WARNING:tensorflow:Layer gru_21 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","WARNING:tensorflow:Layer gru_22 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","WARNING:tensorflow:Layer gru_23 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","WARNING:tensorflow:Layer gru_24 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","Epoch 1/130\n","1/1 [==============================] - 13s 13s/step - loss: 0.5671 - accuracy: 0.4545 - val_loss: 0.5382 - val_accuracy: 0.4324\n","Epoch 2/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.5196 - accuracy: 0.4545 - val_loss: 0.4993 - val_accuracy: 0.4324\n","Epoch 3/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.4754 - accuracy: 0.4545 - val_loss: 0.4579 - val_accuracy: 0.4324\n","Epoch 4/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.4272 - accuracy: 0.4545 - val_loss: 0.4079 - val_accuracy: 0.4324\n","Epoch 5/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.3773 - accuracy: 0.4545 - val_loss: 0.3478 - val_accuracy: 0.4324\n","Epoch 6/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.3078 - accuracy: 0.4545 - val_loss: 0.2858 - val_accuracy: 0.4324\n","Epoch 7/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2567 - accuracy: 0.4545 - val_loss: 0.2474 - val_accuracy: 0.5676\n","Epoch 8/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2354 - accuracy: 0.5455 - val_loss: 0.2594 - val_accuracy: 0.5676\n","Epoch 9/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.3367 - accuracy: 0.5455 - val_loss: 0.2554 - val_accuracy: 0.5676\n","Epoch 10/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.3158 - accuracy: 0.5455 - val_loss: 0.2466 - val_accuracy: 0.5676\n","Epoch 11/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2549 - accuracy: 0.5455 - val_loss: 0.2488 - val_accuracy: 0.4865\n","Epoch 12/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2545 - accuracy: 0.5455 - val_loss: 0.2596 - val_accuracy: 0.4324\n","Epoch 13/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2712 - accuracy: 0.1818 - val_loss: 0.2737 - val_accuracy: 0.4324\n","Epoch 14/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2427 - accuracy: 0.7273 - val_loss: 0.2851 - val_accuracy: 0.4324\n","Epoch 15/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2748 - accuracy: 0.4545 - val_loss: 0.2924 - val_accuracy: 0.4324\n","Epoch 16/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2647 - accuracy: 0.4545 - val_loss: 0.2948 - val_accuracy: 0.4324\n","Epoch 17/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2671 - accuracy: 0.4545 - val_loss: 0.2929 - val_accuracy: 0.4324\n","Epoch 18/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2486 - accuracy: 0.4545 - val_loss: 0.2874 - val_accuracy: 0.4324\n","Epoch 19/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2756 - accuracy: 0.4545 - val_loss: 0.2800 - val_accuracy: 0.4324\n","Epoch 20/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2601 - accuracy: 0.4545 - val_loss: 0.2716 - val_accuracy: 0.4324\n","Epoch 21/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2417 - accuracy: 0.5455 - val_loss: 0.2625 - val_accuracy: 0.4324\n","Epoch 22/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2520 - accuracy: 0.4545 - val_loss: 0.2547 - val_accuracy: 0.5135\n","Epoch 23/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2304 - accuracy: 0.6364 - val_loss: 0.2489 - val_accuracy: 0.4865\n","Epoch 24/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2443 - accuracy: 0.5455 - val_loss: 0.2461 - val_accuracy: 0.5676\n","Epoch 25/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2605 - accuracy: 0.5455 - val_loss: 0.2454 - val_accuracy: 0.5676\n","Epoch 26/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2406 - accuracy: 0.5455 - val_loss: 0.2453 - val_accuracy: 0.5676\n","Epoch 27/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2551 - accuracy: 0.5455 - val_loss: 0.2454 - val_accuracy: 0.5676\n","Epoch 28/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2694 - accuracy: 0.5455 - val_loss: 0.2463 - val_accuracy: 0.5676\n","Epoch 29/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2592 - accuracy: 0.5455 - val_loss: 0.2483 - val_accuracy: 0.4865\n","Epoch 30/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2549 - accuracy: 0.5455 - val_loss: 0.2516 - val_accuracy: 0.5135\n","Epoch 31/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2525 - accuracy: 0.5455 - val_loss: 0.2556 - val_accuracy: 0.4865\n","Epoch 32/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2326 - accuracy: 0.7273 - val_loss: 0.2590 - val_accuracy: 0.4324\n","Epoch 33/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2375 - accuracy: 0.9091 - val_loss: 0.2612 - val_accuracy: 0.4324\n","Epoch 34/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2539 - accuracy: 0.4545 - val_loss: 0.2622 - val_accuracy: 0.4324\n","Epoch 35/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2490 - accuracy: 0.3636 - val_loss: 0.2618 - val_accuracy: 0.4324\n","Epoch 36/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2486 - accuracy: 0.4545 - val_loss: 0.2602 - val_accuracy: 0.4324\n","Epoch 37/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2543 - accuracy: 0.4545 - val_loss: 0.2576 - val_accuracy: 0.4324\n","Epoch 38/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2432 - accuracy: 0.6364 - val_loss: 0.2547 - val_accuracy: 0.4865\n","Epoch 39/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2537 - accuracy: 0.4545 - val_loss: 0.2518 - val_accuracy: 0.5135\n","Epoch 40/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2492 - accuracy: 0.6364 - val_loss: 0.2491 - val_accuracy: 0.4865\n","Epoch 41/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2708 - accuracy: 0.3636 - val_loss: 0.2476 - val_accuracy: 0.4324\n","Epoch 42/130\n","1/1 [==============================] - 2s 2s/step - loss: 0.2438 - accuracy: 0.5455 - val_loss: 0.2467 - val_accuracy: 0.5676\n","Epoch 43/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2387 - accuracy: 0.5455 - val_loss: 0.2460 - val_accuracy: 0.5676\n","Epoch 44/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2491 - accuracy: 0.5455 - val_loss: 0.2460 - val_accuracy: 0.5676\n","Epoch 45/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2290 - accuracy: 0.5455 - val_loss: 0.2461 - val_accuracy: 0.5676\n","Epoch 46/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2559 - accuracy: 0.5455 - val_loss: 0.2466 - val_accuracy: 0.5676\n","Epoch 47/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2479 - accuracy: 0.5455 - val_loss: 0.2475 - val_accuracy: 0.4324\n","Epoch 48/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2475 - accuracy: 0.4545 - val_loss: 0.2484 - val_accuracy: 0.4865\n","Epoch 49/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2548 - accuracy: 0.6364 - val_loss: 0.2491 - val_accuracy: 0.4865\n","Epoch 50/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2454 - accuracy: 0.5455 - val_loss: 0.2499 - val_accuracy: 0.5135\n","Epoch 51/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2555 - accuracy: 0.4545 - val_loss: 0.2506 - val_accuracy: 0.4865\n","Epoch 52/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2360 - accuracy: 0.5455 - val_loss: 0.2508 - val_accuracy: 0.4865\n","Epoch 53/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2527 - accuracy: 0.5455 - val_loss: 0.2505 - val_accuracy: 0.4865\n","Epoch 54/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2387 - accuracy: 0.6364 - val_loss: 0.2498 - val_accuracy: 0.4865\n","Epoch 55/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2494 - accuracy: 0.5455 - val_loss: 0.2493 - val_accuracy: 0.5135\n","Epoch 56/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2570 - accuracy: 0.7273 - val_loss: 0.2489 - val_accuracy: 0.5135\n","Epoch 57/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2555 - accuracy: 0.4545 - val_loss: 0.2487 - val_accuracy: 0.4865\n","Epoch 58/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2349 - accuracy: 0.5455 - val_loss: 0.2485 - val_accuracy: 0.4865\n","Epoch 59/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2641 - accuracy: 0.2727 - val_loss: 0.2484 - val_accuracy: 0.4865\n","Epoch 60/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2591 - accuracy: 0.4545 - val_loss: 0.2484 - val_accuracy: 0.4865\n","Epoch 61/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2539 - accuracy: 0.5455 - val_loss: 0.2486 - val_accuracy: 0.4865\n","Epoch 62/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2425 - accuracy: 0.5455 - val_loss: 0.2486 - val_accuracy: 0.5135\n","Epoch 63/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2627 - accuracy: 0.4545 - val_loss: 0.2486 - val_accuracy: 0.5135\n","Epoch 64/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2466 - accuracy: 0.6364 - val_loss: 0.2483 - val_accuracy: 0.4865\n","Epoch 65/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2369 - accuracy: 0.6364 - val_loss: 0.2479 - val_accuracy: 0.5405\n","Epoch 66/130\n","1/1 [==============================] - 2s 2s/step - loss: 0.2465 - accuracy: 0.5455 - val_loss: 0.2475 - val_accuracy: 0.4595\n","Epoch 67/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2349 - accuracy: 0.6364 - val_loss: 0.2471 - val_accuracy: 0.4595\n","Epoch 68/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2460 - accuracy: 0.5455 - val_loss: 0.2470 - val_accuracy: 0.4595\n","Epoch 69/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2548 - accuracy: 0.4545 - val_loss: 0.2472 - val_accuracy: 0.4595\n","Epoch 70/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2504 - accuracy: 0.5455 - val_loss: 0.2474 - val_accuracy: 0.4324\n","Epoch 71/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2555 - accuracy: 0.5455 - val_loss: 0.2479 - val_accuracy: 0.4865\n","Epoch 72/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2407 - accuracy: 0.5455 - val_loss: 0.2483 - val_accuracy: 0.5135\n","Epoch 73/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2516 - accuracy: 0.5455 - val_loss: 0.2489 - val_accuracy: 0.4865\n","Epoch 74/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2501 - accuracy: 0.4545 - val_loss: 0.2495 - val_accuracy: 0.4865\n","Epoch 75/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2458 - accuracy: 0.5455 - val_loss: 0.2496 - val_accuracy: 0.4865\n","Epoch 76/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2492 - accuracy: 0.5455 - val_loss: 0.2495 - val_accuracy: 0.4865\n","Epoch 77/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2442 - accuracy: 0.5455 - val_loss: 0.2491 - val_accuracy: 0.4865\n","Epoch 78/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2494 - accuracy: 0.5455 - val_loss: 0.2486 - val_accuracy: 0.5135\n","Epoch 79/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2366 - accuracy: 0.5455 - val_loss: 0.2479 - val_accuracy: 0.5135\n","Epoch 80/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2522 - accuracy: 0.5455 - val_loss: 0.2479 - val_accuracy: 0.5135\n","Epoch 81/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2397 - accuracy: 0.4545 - val_loss: 0.2476 - val_accuracy: 0.5405\n","Epoch 82/130\n","1/1 [==============================] - 2s 2s/step - loss: 0.2352 - accuracy: 0.4545 - val_loss: 0.2475 - val_accuracy: 0.5135\n","Epoch 83/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2403 - accuracy: 0.5455 - val_loss: 0.2479 - val_accuracy: 0.5405\n","Epoch 84/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2548 - accuracy: 0.3636 - val_loss: 0.2485 - val_accuracy: 0.4865\n","Epoch 85/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2479 - accuracy: 0.6364 - val_loss: 0.2485 - val_accuracy: 0.4865\n","Epoch 86/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2427 - accuracy: 0.5455 - val_loss: 0.2485 - val_accuracy: 0.4865\n","Epoch 87/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2500 - accuracy: 0.4545 - val_loss: 0.2481 - val_accuracy: 0.5405\n","Epoch 88/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2516 - accuracy: 0.4545 - val_loss: 0.2478 - val_accuracy: 0.4595\n","Epoch 89/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2636 - accuracy: 0.4545 - val_loss: 0.2490 - val_accuracy: 0.5405\n","Epoch 90/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2481 - accuracy: 0.4545 - val_loss: 0.2499 - val_accuracy: 0.5405\n","Epoch 91/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2207 - accuracy: 0.5455 - val_loss: 0.2497 - val_accuracy: 0.5405\n","Epoch 92/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2571 - accuracy: 0.4545 - val_loss: 0.2492 - val_accuracy: 0.5405\n","Epoch 93/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2419 - accuracy: 0.5455 - val_loss: 0.2484 - val_accuracy: 0.5405\n","Epoch 94/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2591 - accuracy: 0.3636 - val_loss: 0.2476 - val_accuracy: 0.5135\n","Epoch 95/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2361 - accuracy: 0.6364 - val_loss: 0.2465 - val_accuracy: 0.5405\n","Epoch 96/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2568 - accuracy: 0.5455 - val_loss: 0.2463 - val_accuracy: 0.5135\n","Epoch 97/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2480 - accuracy: 0.5455 - val_loss: 0.2462 - val_accuracy: 0.5135\n","Epoch 98/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2643 - accuracy: 0.5455 - val_loss: 0.2466 - val_accuracy: 0.5676\n","Epoch 99/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2670 - accuracy: 0.4545 - val_loss: 0.2477 - val_accuracy: 0.5946\n","Epoch 100/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2609 - accuracy: 0.4545 - val_loss: 0.2487 - val_accuracy: 0.5135\n","Epoch 101/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2404 - accuracy: 0.5455 - val_loss: 0.2490 - val_accuracy: 0.4865\n","Epoch 102/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2579 - accuracy: 0.3636 - val_loss: 0.2493 - val_accuracy: 0.5135\n","Epoch 103/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2602 - accuracy: 0.4545 - val_loss: 0.2484 - val_accuracy: 0.4865\n","Epoch 104/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2352 - accuracy: 0.7273 - val_loss: 0.2458 - val_accuracy: 0.6216\n","Epoch 105/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2384 - accuracy: 0.4545 - val_loss: 0.2438 - val_accuracy: 0.6216\n","Epoch 106/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2478 - accuracy: 0.4545 - val_loss: 0.2427 - val_accuracy: 0.5405\n","Epoch 107/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2376 - accuracy: 0.5455 - val_loss: 0.2416 - val_accuracy: 0.5676\n","Epoch 108/130\n","1/1 [==============================] - 2s 2s/step - loss: 0.2229 - accuracy: 0.5455 - val_loss: 0.2408 - val_accuracy: 0.5676\n","Epoch 109/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2592 - accuracy: 0.5455 - val_loss: 0.2407 - val_accuracy: 0.5676\n","Epoch 110/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2559 - accuracy: 0.5455 - val_loss: 0.2411 - val_accuracy: 0.5405\n","Epoch 111/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2428 - accuracy: 0.5455 - val_loss: 0.2417 - val_accuracy: 0.5946\n","Epoch 112/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2331 - accuracy: 0.6364 - val_loss: 0.2417 - val_accuracy: 0.5946\n","Epoch 113/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2438 - accuracy: 0.7273 - val_loss: 0.2405 - val_accuracy: 0.5676\n","Epoch 114/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2633 - accuracy: 0.2727 - val_loss: 0.2396 - val_accuracy: 0.5405\n","Epoch 115/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2460 - accuracy: 0.4545 - val_loss: 0.2390 - val_accuracy: 0.5676\n","Epoch 116/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2453 - accuracy: 0.6364 - val_loss: 0.2392 - val_accuracy: 0.5676\n","Epoch 117/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2304 - accuracy: 0.6364 - val_loss: 0.2413 - val_accuracy: 0.5676\n","Epoch 118/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2466 - accuracy: 0.5455 - val_loss: 0.2433 - val_accuracy: 0.5676\n","Epoch 119/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2508 - accuracy: 0.6364 - val_loss: 0.2443 - val_accuracy: 0.5676\n","Epoch 120/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2299 - accuracy: 0.6364 - val_loss: 0.2421 - val_accuracy: 0.5676\n","Epoch 121/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2488 - accuracy: 0.5455 - val_loss: 0.2440 - val_accuracy: 0.5676\n","Epoch 122/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2391 - accuracy: 0.3636 - val_loss: 0.2494 - val_accuracy: 0.5676\n","Epoch 123/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2446 - accuracy: 0.5455 - val_loss: 0.2495 - val_accuracy: 0.5676\n","Epoch 124/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2440 - accuracy: 0.4545 - val_loss: 0.2489 - val_accuracy: 0.5676\n","Epoch 125/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2536 - accuracy: 0.4545 - val_loss: 0.2473 - val_accuracy: 0.5676\n","Epoch 126/130\n","1/1 [==============================] - 2s 2s/step - loss: 0.2312 - accuracy: 0.6364 - val_loss: 0.2540 - val_accuracy: 0.5676\n","Epoch 127/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2609 - accuracy: 0.2727 - val_loss: 0.2596 - val_accuracy: 0.5676\n","Epoch 128/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2236 - accuracy: 0.6364 - val_loss: 0.2661 - val_accuracy: 0.5676\n","Epoch 129/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2282 - accuracy: 0.5455 - val_loss: 0.3037 - val_accuracy: 0.5676\n","Epoch 130/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2455 - accuracy: 0.5455 - val_loss: 0.3845 - val_accuracy: 0.5676\n","WARNING:tensorflow:5 out of the last 9 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f76b8ad4b90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n","2/2 [==============================] - 0s 90ms/step - loss: 0.3845 - accuracy: 0.5676\n","loss :  0.5675675868988037\n","total_loss :  2.6756757497787476\n","num :  5\n","WARNING:tensorflow:Layer gru_25 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","WARNING:tensorflow:Layer gru_26 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","WARNING:tensorflow:Layer gru_27 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","WARNING:tensorflow:Layer gru_28 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","WARNING:tensorflow:Layer gru_29 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","Epoch 1/130\n","1/1 [==============================] - 12s 12s/step - loss: 0.5495 - accuracy: 0.4545 - val_loss: 0.5593 - val_accuracy: 0.4054\n","Epoch 2/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.5058 - accuracy: 0.4545 - val_loss: 0.5149 - val_accuracy: 0.4054\n","Epoch 3/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.4657 - accuracy: 0.4545 - val_loss: 0.4666 - val_accuracy: 0.4054\n","Epoch 4/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.4218 - accuracy: 0.4545 - val_loss: 0.4095 - val_accuracy: 0.4054\n","Epoch 5/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.3594 - accuracy: 0.4545 - val_loss: 0.3434 - val_accuracy: 0.4054\n","Epoch 6/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.3032 - accuracy: 0.4545 - val_loss: 0.2781 - val_accuracy: 0.4054\n","Epoch 7/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2703 - accuracy: 0.3636 - val_loss: 0.2413 - val_accuracy: 0.5946\n","Epoch 8/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2464 - accuracy: 0.5455 - val_loss: 0.2523 - val_accuracy: 0.5946\n","Epoch 9/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2812 - accuracy: 0.5455 - val_loss: 0.2505 - val_accuracy: 0.5946\n","Epoch 10/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2657 - accuracy: 0.5455 - val_loss: 0.2416 - val_accuracy: 0.5946\n","Epoch 11/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2824 - accuracy: 0.5455 - val_loss: 0.2438 - val_accuracy: 0.5946\n","Epoch 12/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2336 - accuracy: 0.5455 - val_loss: 0.2574 - val_accuracy: 0.4054\n","Epoch 13/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2427 - accuracy: 0.5455 - val_loss: 0.2744 - val_accuracy: 0.4054\n","Epoch 14/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2438 - accuracy: 0.6364 - val_loss: 0.2883 - val_accuracy: 0.4054\n","Epoch 15/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2560 - accuracy: 0.4545 - val_loss: 0.2969 - val_accuracy: 0.4054\n","Epoch 16/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2581 - accuracy: 0.4545 - val_loss: 0.2997 - val_accuracy: 0.4054\n","Epoch 17/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2648 - accuracy: 0.4545 - val_loss: 0.2978 - val_accuracy: 0.4054\n","Epoch 18/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2723 - accuracy: 0.4545 - val_loss: 0.2923 - val_accuracy: 0.4054\n","Epoch 19/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2607 - accuracy: 0.4545 - val_loss: 0.2840 - val_accuracy: 0.4054\n","Epoch 20/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2660 - accuracy: 0.4545 - val_loss: 0.2744 - val_accuracy: 0.4054\n","Epoch 21/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2701 - accuracy: 0.3636 - val_loss: 0.2647 - val_accuracy: 0.4054\n","Epoch 22/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2447 - accuracy: 0.4545 - val_loss: 0.2561 - val_accuracy: 0.4054\n","Epoch 23/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2542 - accuracy: 0.6364 - val_loss: 0.2498 - val_accuracy: 0.5405\n","Epoch 24/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2484 - accuracy: 0.5455 - val_loss: 0.2458 - val_accuracy: 0.5135\n","Epoch 25/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2468 - accuracy: 0.6364 - val_loss: 0.2438 - val_accuracy: 0.5946\n","Epoch 26/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2343 - accuracy: 0.5455 - val_loss: 0.2428 - val_accuracy: 0.5946\n","Epoch 27/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2502 - accuracy: 0.5455 - val_loss: 0.2431 - val_accuracy: 0.6486\n","Epoch 28/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2593 - accuracy: 0.5455 - val_loss: 0.2447 - val_accuracy: 0.5405\n","Epoch 29/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2386 - accuracy: 0.5455 - val_loss: 0.2476 - val_accuracy: 0.5135\n","Epoch 30/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2487 - accuracy: 0.5455 - val_loss: 0.2519 - val_accuracy: 0.5135\n","Epoch 31/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2292 - accuracy: 0.6364 - val_loss: 0.2571 - val_accuracy: 0.4054\n","Epoch 32/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2503 - accuracy: 0.5455 - val_loss: 0.2636 - val_accuracy: 0.4054\n","Epoch 33/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2422 - accuracy: 0.5455 - val_loss: 0.2687 - val_accuracy: 0.4054\n","Epoch 34/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2446 - accuracy: 0.3636 - val_loss: 0.2725 - val_accuracy: 0.4054\n","Epoch 35/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2445 - accuracy: 0.5455 - val_loss: 0.2744 - val_accuracy: 0.4054\n","Epoch 36/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2487 - accuracy: 0.5455 - val_loss: 0.2741 - val_accuracy: 0.4054\n","Epoch 37/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2372 - accuracy: 0.5455 - val_loss: 0.2712 - val_accuracy: 0.4054\n","Epoch 38/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2440 - accuracy: 0.4545 - val_loss: 0.2671 - val_accuracy: 0.4054\n","Epoch 39/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2448 - accuracy: 0.5455 - val_loss: 0.2628 - val_accuracy: 0.4054\n","Epoch 40/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2343 - accuracy: 0.7273 - val_loss: 0.2580 - val_accuracy: 0.4865\n","Epoch 41/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2446 - accuracy: 0.5455 - val_loss: 0.2539 - val_accuracy: 0.4865\n","Epoch 42/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2747 - accuracy: 0.5455 - val_loss: 0.2526 - val_accuracy: 0.4865\n","Epoch 43/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2349 - accuracy: 0.5455 - val_loss: 0.2524 - val_accuracy: 0.5135\n","Epoch 44/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2376 - accuracy: 0.5455 - val_loss: 0.2539 - val_accuracy: 0.4865\n","Epoch 45/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2409 - accuracy: 0.4545 - val_loss: 0.2568 - val_accuracy: 0.5135\n","Epoch 46/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2351 - accuracy: 0.5455 - val_loss: 0.2602 - val_accuracy: 0.4865\n","Epoch 47/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2332 - accuracy: 0.7273 - val_loss: 0.2632 - val_accuracy: 0.4324\n","Epoch 48/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2421 - accuracy: 0.5455 - val_loss: 0.2657 - val_accuracy: 0.4054\n","Epoch 49/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2389 - accuracy: 0.5455 - val_loss: 0.2685 - val_accuracy: 0.4054\n","Epoch 50/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2440 - accuracy: 0.5455 - val_loss: 0.2701 - val_accuracy: 0.4054\n","Epoch 51/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2602 - accuracy: 0.6364 - val_loss: 0.2712 - val_accuracy: 0.4054\n","Epoch 52/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2474 - accuracy: 0.3636 - val_loss: 0.2722 - val_accuracy: 0.4054\n","Epoch 53/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2137 - accuracy: 0.7273 - val_loss: 0.2718 - val_accuracy: 0.4054\n","Epoch 54/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2337 - accuracy: 0.5455 - val_loss: 0.2698 - val_accuracy: 0.4324\n","Epoch 55/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2344 - accuracy: 0.5455 - val_loss: 0.2677 - val_accuracy: 0.4865\n","Epoch 56/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2600 - accuracy: 0.4545 - val_loss: 0.2665 - val_accuracy: 0.4865\n","Epoch 57/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2196 - accuracy: 0.6364 - val_loss: 0.2653 - val_accuracy: 0.4595\n","Epoch 58/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2400 - accuracy: 0.4545 - val_loss: 0.2646 - val_accuracy: 0.4865\n","Epoch 59/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2489 - accuracy: 0.4545 - val_loss: 0.2665 - val_accuracy: 0.4595\n","Epoch 60/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2155 - accuracy: 0.5455 - val_loss: 0.2680 - val_accuracy: 0.4595\n","Epoch 61/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2412 - accuracy: 0.6364 - val_loss: 0.2701 - val_accuracy: 0.4865\n","Epoch 62/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2122 - accuracy: 0.6364 - val_loss: 0.2708 - val_accuracy: 0.4865\n","Epoch 63/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2294 - accuracy: 0.6364 - val_loss: 0.2726 - val_accuracy: 0.4865\n","Epoch 64/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2099 - accuracy: 0.7273 - val_loss: 0.2729 - val_accuracy: 0.4865\n","Epoch 65/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2344 - accuracy: 0.7273 - val_loss: 0.2733 - val_accuracy: 0.4595\n","Epoch 66/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2454 - accuracy: 0.5455 - val_loss: 0.2744 - val_accuracy: 0.4595\n","Epoch 67/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2178 - accuracy: 0.8182 - val_loss: 0.2768 - val_accuracy: 0.4865\n","Epoch 68/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2520 - accuracy: 0.5455 - val_loss: 0.2800 - val_accuracy: 0.4865\n","Epoch 69/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2191 - accuracy: 0.4545 - val_loss: 0.2834 - val_accuracy: 0.4865\n","Epoch 70/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2206 - accuracy: 0.6364 - val_loss: 0.2859 - val_accuracy: 0.4324\n","Epoch 71/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2466 - accuracy: 0.5455 - val_loss: 0.2917 - val_accuracy: 0.4054\n","Epoch 72/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2283 - accuracy: 0.5455 - val_loss: 0.2941 - val_accuracy: 0.4324\n","Epoch 73/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2238 - accuracy: 0.5455 - val_loss: 0.2955 - val_accuracy: 0.4054\n","Epoch 74/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2218 - accuracy: 0.7273 - val_loss: 0.2945 - val_accuracy: 0.4324\n","Epoch 75/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2170 - accuracy: 0.5455 - val_loss: 0.2955 - val_accuracy: 0.4324\n","Epoch 76/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2205 - accuracy: 0.6364 - val_loss: 0.2955 - val_accuracy: 0.4595\n","Epoch 77/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2433 - accuracy: 0.6364 - val_loss: 0.2940 - val_accuracy: 0.4865\n","Epoch 78/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2065 - accuracy: 0.8182 - val_loss: 0.2927 - val_accuracy: 0.4865\n","Epoch 79/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2150 - accuracy: 0.5455 - val_loss: 0.2923 - val_accuracy: 0.5135\n","Epoch 80/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2331 - accuracy: 0.6364 - val_loss: 0.2988 - val_accuracy: 0.4595\n","Epoch 81/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1923 - accuracy: 0.6364 - val_loss: 0.3059 - val_accuracy: 0.4324\n","Epoch 82/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2235 - accuracy: 0.6364 - val_loss: 0.3136 - val_accuracy: 0.4054\n","Epoch 83/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2323 - accuracy: 0.6364 - val_loss: 0.3193 - val_accuracy: 0.4054\n","Epoch 84/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2206 - accuracy: 0.6364 - val_loss: 0.3272 - val_accuracy: 0.4054\n","Epoch 85/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2463 - accuracy: 0.6364 - val_loss: 0.3328 - val_accuracy: 0.4054\n","Epoch 86/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2280 - accuracy: 0.4545 - val_loss: 0.3297 - val_accuracy: 0.4054\n","Epoch 87/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2385 - accuracy: 0.6364 - val_loss: 0.3234 - val_accuracy: 0.4054\n","Epoch 88/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2530 - accuracy: 0.6364 - val_loss: 0.3207 - val_accuracy: 0.4054\n","Epoch 89/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2492 - accuracy: 0.6364 - val_loss: 0.3224 - val_accuracy: 0.4054\n","Epoch 90/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2620 - accuracy: 0.4545 - val_loss: 0.3230 - val_accuracy: 0.4054\n","Epoch 91/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2270 - accuracy: 0.5455 - val_loss: 0.3239 - val_accuracy: 0.4054\n","Epoch 92/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2796 - accuracy: 0.4545 - val_loss: 0.3288 - val_accuracy: 0.4054\n","Epoch 93/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2406 - accuracy: 0.6364 - val_loss: 0.3280 - val_accuracy: 0.4054\n","Epoch 94/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1943 - accuracy: 0.6364 - val_loss: 0.3226 - val_accuracy: 0.4054\n","Epoch 95/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2278 - accuracy: 0.6364 - val_loss: 0.3161 - val_accuracy: 0.4054\n","Epoch 96/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2430 - accuracy: 0.6364 - val_loss: 0.3158 - val_accuracy: 0.4054\n","Epoch 97/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2224 - accuracy: 0.6364 - val_loss: 0.3177 - val_accuracy: 0.4054\n","Epoch 98/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2285 - accuracy: 0.5455 - val_loss: 0.3240 - val_accuracy: 0.4054\n","Epoch 99/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2154 - accuracy: 0.6364 - val_loss: 0.3280 - val_accuracy: 0.4054\n","Epoch 100/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2208 - accuracy: 0.6364 - val_loss: 0.3285 - val_accuracy: 0.4054\n","Epoch 101/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2157 - accuracy: 0.6364 - val_loss: 0.3280 - val_accuracy: 0.4054\n","Epoch 102/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2306 - accuracy: 0.5455 - val_loss: 0.3257 - val_accuracy: 0.4054\n","Epoch 103/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2132 - accuracy: 0.6364 - val_loss: 0.3254 - val_accuracy: 0.4054\n","Epoch 104/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2212 - accuracy: 0.6364 - val_loss: 0.3270 - val_accuracy: 0.4054\n","Epoch 105/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2362 - accuracy: 0.6364 - val_loss: 0.3252 - val_accuracy: 0.4054\n","Epoch 106/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2284 - accuracy: 0.6364 - val_loss: 0.3261 - val_accuracy: 0.4054\n","Epoch 107/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2143 - accuracy: 0.6364 - val_loss: 0.3271 - val_accuracy: 0.4054\n","Epoch 108/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2177 - accuracy: 0.5455 - val_loss: 0.3258 - val_accuracy: 0.4054\n","Epoch 109/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2516 - accuracy: 0.6364 - val_loss: 0.3285 - val_accuracy: 0.4054\n","Epoch 110/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2388 - accuracy: 0.5455 - val_loss: 0.3297 - val_accuracy: 0.4054\n","Epoch 111/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2173 - accuracy: 0.6364 - val_loss: 0.3313 - val_accuracy: 0.4054\n","Epoch 112/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2640 - accuracy: 0.4545 - val_loss: 0.3333 - val_accuracy: 0.4054\n","Epoch 113/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2516 - accuracy: 0.5455 - val_loss: 0.3345 - val_accuracy: 0.4054\n","Epoch 114/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2328 - accuracy: 0.6364 - val_loss: 0.3356 - val_accuracy: 0.4054\n","Epoch 115/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2336 - accuracy: 0.6364 - val_loss: 0.3304 - val_accuracy: 0.4054\n","Epoch 116/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2415 - accuracy: 0.6364 - val_loss: 0.3236 - val_accuracy: 0.4054\n","Epoch 117/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2014 - accuracy: 0.5455 - val_loss: 0.3154 - val_accuracy: 0.4054\n","Epoch 118/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2418 - accuracy: 0.7273 - val_loss: 0.3082 - val_accuracy: 0.4054\n","Epoch 119/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2567 - accuracy: 0.5455 - val_loss: 0.3089 - val_accuracy: 0.4054\n","Epoch 120/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2156 - accuracy: 0.6364 - val_loss: 0.3145 - val_accuracy: 0.4054\n","Epoch 121/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2122 - accuracy: 0.5455 - val_loss: 0.3228 - val_accuracy: 0.4054\n","Epoch 122/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2529 - accuracy: 0.5455 - val_loss: 0.3269 - val_accuracy: 0.4054\n","Epoch 123/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2227 - accuracy: 0.6364 - val_loss: 0.3249 - val_accuracy: 0.4054\n","Epoch 124/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2122 - accuracy: 0.6364 - val_loss: 0.3198 - val_accuracy: 0.4054\n","Epoch 125/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2106 - accuracy: 0.6364 - val_loss: 0.3165 - val_accuracy: 0.4054\n","Epoch 126/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2171 - accuracy: 0.6364 - val_loss: 0.3143 - val_accuracy: 0.4054\n","Epoch 127/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2151 - accuracy: 0.6364 - val_loss: 0.3123 - val_accuracy: 0.4054\n","Epoch 128/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2100 - accuracy: 0.5455 - val_loss: 0.3107 - val_accuracy: 0.4054\n","Epoch 129/130\n","1/1 [==============================] - 2s 2s/step - loss: 0.2072 - accuracy: 0.6364 - val_loss: 0.3102 - val_accuracy: 0.4054\n","Epoch 130/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1979 - accuracy: 0.6364 - val_loss: 0.3134 - val_accuracy: 0.4054\n","WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f76bc15e050> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n","2/2 [==============================] - 0s 105ms/step - loss: 0.3134 - accuracy: 0.4054\n","loss :  0.4054054021835327\n","total_loss :  3.0810811519622803\n","num :  6\n","WARNING:tensorflow:Layer gru_30 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","WARNING:tensorflow:Layer gru_31 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","WARNING:tensorflow:Layer gru_32 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","WARNING:tensorflow:Layer gru_33 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","WARNING:tensorflow:Layer gru_34 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","Epoch 1/130\n","1/1 [==============================] - 12s 12s/step - loss: 0.4494 - accuracy: 0.5455 - val_loss: 0.4456 - val_accuracy: 0.5135\n","Epoch 2/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.4035 - accuracy: 0.5455 - val_loss: 0.4071 - val_accuracy: 0.5135\n","Epoch 3/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.3641 - accuracy: 0.5455 - val_loss: 0.3625 - val_accuracy: 0.5135\n","Epoch 4/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.3153 - accuracy: 0.5455 - val_loss: 0.3145 - val_accuracy: 0.5135\n","Epoch 5/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2761 - accuracy: 0.5455 - val_loss: 0.2711 - val_accuracy: 0.5135\n","Epoch 6/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2403 - accuracy: 0.5455 - val_loss: 0.2517 - val_accuracy: 0.4324\n","Epoch 7/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2698 - accuracy: 0.3636 - val_loss: 0.2519 - val_accuracy: 0.4865\n","Epoch 8/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2885 - accuracy: 0.4545 - val_loss: 0.2522 - val_accuracy: 0.4324\n","Epoch 9/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2554 - accuracy: 0.5455 - val_loss: 0.2569 - val_accuracy: 0.5135\n","Epoch 10/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2480 - accuracy: 0.6364 - val_loss: 0.2667 - val_accuracy: 0.5135\n","Epoch 11/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2529 - accuracy: 0.4545 - val_loss: 0.2776 - val_accuracy: 0.5135\n","Epoch 12/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2401 - accuracy: 0.5455 - val_loss: 0.2863 - val_accuracy: 0.5135\n","Epoch 13/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2486 - accuracy: 0.5455 - val_loss: 0.2914 - val_accuracy: 0.5135\n","Epoch 14/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2448 - accuracy: 0.5455 - val_loss: 0.2924 - val_accuracy: 0.5135\n","Epoch 15/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2655 - accuracy: 0.5455 - val_loss: 0.2910 - val_accuracy: 0.5135\n","Epoch 16/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2503 - accuracy: 0.5455 - val_loss: 0.2873 - val_accuracy: 0.5135\n","Epoch 17/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2506 - accuracy: 0.5455 - val_loss: 0.2811 - val_accuracy: 0.5135\n","Epoch 18/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2398 - accuracy: 0.6364 - val_loss: 0.2744 - val_accuracy: 0.5135\n","Epoch 19/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2526 - accuracy: 0.5455 - val_loss: 0.2688 - val_accuracy: 0.5135\n","Epoch 20/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2592 - accuracy: 0.3636 - val_loss: 0.2651 - val_accuracy: 0.5135\n","Epoch 21/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2402 - accuracy: 0.5455 - val_loss: 0.2630 - val_accuracy: 0.5135\n","Epoch 22/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2442 - accuracy: 0.5455 - val_loss: 0.2626 - val_accuracy: 0.5135\n","Epoch 23/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2557 - accuracy: 0.5455 - val_loss: 0.2635 - val_accuracy: 0.5135\n","Epoch 24/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2470 - accuracy: 0.5455 - val_loss: 0.2655 - val_accuracy: 0.5135\n","Epoch 25/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2464 - accuracy: 0.6364 - val_loss: 0.2690 - val_accuracy: 0.5135\n","Epoch 26/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2484 - accuracy: 0.6364 - val_loss: 0.2723 - val_accuracy: 0.5135\n","Epoch 27/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2443 - accuracy: 0.5455 - val_loss: 0.2745 - val_accuracy: 0.5135\n","Epoch 28/130\n","1/1 [==============================] - 2s 2s/step - loss: 0.2241 - accuracy: 0.7273 - val_loss: 0.2755 - val_accuracy: 0.5135\n","Epoch 29/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2342 - accuracy: 0.6364 - val_loss: 0.2750 - val_accuracy: 0.5135\n","Epoch 30/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2241 - accuracy: 0.6364 - val_loss: 0.2734 - val_accuracy: 0.5135\n","Epoch 31/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2370 - accuracy: 0.6364 - val_loss: 0.2710 - val_accuracy: 0.5135\n","Epoch 32/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2486 - accuracy: 0.4545 - val_loss: 0.2691 - val_accuracy: 0.5135\n","Epoch 33/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2412 - accuracy: 0.6364 - val_loss: 0.2677 - val_accuracy: 0.4865\n","Epoch 34/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2262 - accuracy: 0.7273 - val_loss: 0.2667 - val_accuracy: 0.4324\n","Epoch 35/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2295 - accuracy: 0.6364 - val_loss: 0.2660 - val_accuracy: 0.4324\n","Epoch 36/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2386 - accuracy: 0.6364 - val_loss: 0.2660 - val_accuracy: 0.4324\n","Epoch 37/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2410 - accuracy: 0.6364 - val_loss: 0.2668 - val_accuracy: 0.4324\n","Epoch 38/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2385 - accuracy: 0.5455 - val_loss: 0.2685 - val_accuracy: 0.4054\n","Epoch 39/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2330 - accuracy: 0.6364 - val_loss: 0.2703 - val_accuracy: 0.4054\n","Epoch 40/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2342 - accuracy: 0.5455 - val_loss: 0.2716 - val_accuracy: 0.4324\n","Epoch 41/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2529 - accuracy: 0.6364 - val_loss: 0.2743 - val_accuracy: 0.4865\n","Epoch 42/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2220 - accuracy: 0.6364 - val_loss: 0.2763 - val_accuracy: 0.5135\n","Epoch 43/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2328 - accuracy: 0.5455 - val_loss: 0.2778 - val_accuracy: 0.5135\n","Epoch 44/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2357 - accuracy: 0.7273 - val_loss: 0.2782 - val_accuracy: 0.4865\n","Epoch 45/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2345 - accuracy: 0.7273 - val_loss: 0.2781 - val_accuracy: 0.4865\n","Epoch 46/130\n","1/1 [==============================] - 2s 2s/step - loss: 0.2507 - accuracy: 0.5455 - val_loss: 0.2778 - val_accuracy: 0.4595\n","Epoch 47/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2286 - accuracy: 0.6364 - val_loss: 0.2763 - val_accuracy: 0.4054\n","Epoch 48/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2265 - accuracy: 0.7273 - val_loss: 0.2744 - val_accuracy: 0.4324\n","Epoch 49/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2233 - accuracy: 0.8182 - val_loss: 0.2728 - val_accuracy: 0.4324\n","Epoch 50/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2409 - accuracy: 0.5455 - val_loss: 0.2728 - val_accuracy: 0.4324\n","Epoch 51/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2428 - accuracy: 0.7273 - val_loss: 0.2737 - val_accuracy: 0.4324\n","Epoch 52/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2304 - accuracy: 0.6364 - val_loss: 0.2746 - val_accuracy: 0.4324\n","Epoch 53/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2279 - accuracy: 0.6364 - val_loss: 0.2764 - val_accuracy: 0.4324\n","Epoch 54/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2301 - accuracy: 0.5455 - val_loss: 0.2790 - val_accuracy: 0.4595\n","Epoch 55/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2315 - accuracy: 0.7273 - val_loss: 0.2804 - val_accuracy: 0.4595\n","Epoch 56/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2518 - accuracy: 0.5455 - val_loss: 0.2813 - val_accuracy: 0.4595\n","Epoch 57/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2494 - accuracy: 0.5455 - val_loss: 0.2827 - val_accuracy: 0.4324\n","Epoch 58/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2287 - accuracy: 0.6364 - val_loss: 0.2831 - val_accuracy: 0.4595\n","Epoch 59/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2464 - accuracy: 0.5455 - val_loss: 0.2838 - val_accuracy: 0.4595\n","Epoch 60/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2274 - accuracy: 0.6364 - val_loss: 0.2833 - val_accuracy: 0.4595\n","Epoch 61/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2167 - accuracy: 0.7273 - val_loss: 0.2814 - val_accuracy: 0.4324\n","Epoch 62/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2316 - accuracy: 0.6364 - val_loss: 0.2809 - val_accuracy: 0.4595\n","Epoch 63/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2402 - accuracy: 0.6364 - val_loss: 0.2819 - val_accuracy: 0.4595\n","Epoch 64/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2153 - accuracy: 0.7273 - val_loss: 0.2822 - val_accuracy: 0.4595\n","Epoch 65/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2017 - accuracy: 0.7273 - val_loss: 0.2830 - val_accuracy: 0.4595\n","Epoch 66/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2387 - accuracy: 0.5455 - val_loss: 0.2840 - val_accuracy: 0.4595\n","Epoch 67/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2211 - accuracy: 0.6364 - val_loss: 0.2859 - val_accuracy: 0.4324\n","Epoch 68/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2307 - accuracy: 0.4545 - val_loss: 0.2905 - val_accuracy: 0.4595\n","Epoch 69/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2361 - accuracy: 0.5455 - val_loss: 0.2955 - val_accuracy: 0.4324\n","Epoch 70/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2413 - accuracy: 0.5455 - val_loss: 0.2984 - val_accuracy: 0.4054\n","Epoch 71/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2258 - accuracy: 0.5455 - val_loss: 0.2971 - val_accuracy: 0.4324\n","Epoch 72/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2288 - accuracy: 0.6364 - val_loss: 0.2945 - val_accuracy: 0.4595\n","Epoch 73/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2424 - accuracy: 0.5455 - val_loss: 0.2904 - val_accuracy: 0.4324\n","Epoch 74/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2442 - accuracy: 0.5455 - val_loss: 0.2881 - val_accuracy: 0.4595\n","Epoch 75/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2612 - accuracy: 0.6364 - val_loss: 0.2873 - val_accuracy: 0.4324\n","Epoch 76/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2594 - accuracy: 0.5455 - val_loss: 0.2872 - val_accuracy: 0.4324\n","Epoch 77/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2146 - accuracy: 0.7273 - val_loss: 0.2874 - val_accuracy: 0.4324\n","Epoch 78/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2362 - accuracy: 0.5455 - val_loss: 0.2884 - val_accuracy: 0.4595\n","Epoch 79/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2539 - accuracy: 0.5455 - val_loss: 0.2905 - val_accuracy: 0.4324\n","Epoch 80/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2023 - accuracy: 0.7273 - val_loss: 0.2922 - val_accuracy: 0.4324\n","Epoch 81/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2462 - accuracy: 0.4545 - val_loss: 0.2928 - val_accuracy: 0.4324\n","Epoch 82/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2331 - accuracy: 0.5455 - val_loss: 0.2927 - val_accuracy: 0.4595\n","Epoch 83/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2444 - accuracy: 0.6364 - val_loss: 0.2920 - val_accuracy: 0.4595\n","Epoch 84/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2339 - accuracy: 0.6364 - val_loss: 0.2914 - val_accuracy: 0.4324\n","Epoch 85/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2409 - accuracy: 0.6364 - val_loss: 0.2912 - val_accuracy: 0.4324\n","Epoch 86/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2392 - accuracy: 0.5455 - val_loss: 0.2912 - val_accuracy: 0.4324\n","Epoch 87/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2369 - accuracy: 0.5455 - val_loss: 0.2912 - val_accuracy: 0.4324\n","Epoch 88/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2125 - accuracy: 0.7273 - val_loss: 0.2913 - val_accuracy: 0.4324\n","Epoch 89/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2346 - accuracy: 0.6364 - val_loss: 0.2915 - val_accuracy: 0.4324\n","Epoch 90/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2336 - accuracy: 0.6364 - val_loss: 0.2920 - val_accuracy: 0.4324\n","Epoch 91/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2474 - accuracy: 0.6364 - val_loss: 0.2926 - val_accuracy: 0.4595\n","Epoch 92/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2238 - accuracy: 0.5455 - val_loss: 0.2929 - val_accuracy: 0.4595\n","Epoch 93/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2157 - accuracy: 0.6364 - val_loss: 0.2913 - val_accuracy: 0.4595\n","Epoch 94/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2422 - accuracy: 0.4545 - val_loss: 0.2897 - val_accuracy: 0.4324\n","Epoch 95/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2502 - accuracy: 0.4545 - val_loss: 0.2887 - val_accuracy: 0.4595\n","Epoch 96/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2305 - accuracy: 0.5455 - val_loss: 0.2879 - val_accuracy: 0.4595\n","Epoch 97/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2384 - accuracy: 0.6364 - val_loss: 0.2874 - val_accuracy: 0.4324\n","Epoch 98/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2286 - accuracy: 0.5455 - val_loss: 0.2872 - val_accuracy: 0.4595\n","Epoch 99/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2192 - accuracy: 0.6364 - val_loss: 0.2883 - val_accuracy: 0.4595\n","Epoch 100/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2442 - accuracy: 0.6364 - val_loss: 0.2890 - val_accuracy: 0.4324\n","Epoch 101/130\n","1/1 [==============================] - 2s 2s/step - loss: 0.2331 - accuracy: 0.6364 - val_loss: 0.2887 - val_accuracy: 0.4595\n","Epoch 102/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2398 - accuracy: 0.6364 - val_loss: 0.2879 - val_accuracy: 0.4595\n","Epoch 103/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2260 - accuracy: 0.6364 - val_loss: 0.2872 - val_accuracy: 0.4324\n","Epoch 104/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2268 - accuracy: 0.6364 - val_loss: 0.2871 - val_accuracy: 0.4324\n","Epoch 105/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2058 - accuracy: 0.5455 - val_loss: 0.2887 - val_accuracy: 0.4595\n","Epoch 106/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2203 - accuracy: 0.6364 - val_loss: 0.2902 - val_accuracy: 0.4595\n","Epoch 107/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2475 - accuracy: 0.5455 - val_loss: 0.2894 - val_accuracy: 0.4595\n","Epoch 108/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2335 - accuracy: 0.6364 - val_loss: 0.2908 - val_accuracy: 0.4595\n","Epoch 109/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2087 - accuracy: 0.6364 - val_loss: 0.2939 - val_accuracy: 0.4595\n","Epoch 110/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2043 - accuracy: 0.6364 - val_loss: 0.2960 - val_accuracy: 0.4324\n","Epoch 111/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2340 - accuracy: 0.7273 - val_loss: 0.2956 - val_accuracy: 0.4595\n","Epoch 112/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2432 - accuracy: 0.6364 - val_loss: 0.2955 - val_accuracy: 0.4595\n","Epoch 113/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2313 - accuracy: 0.4545 - val_loss: 0.2938 - val_accuracy: 0.4595\n","Epoch 114/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2433 - accuracy: 0.6364 - val_loss: 0.2927 - val_accuracy: 0.4324\n","Epoch 115/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2411 - accuracy: 0.5455 - val_loss: 0.2930 - val_accuracy: 0.4595\n","Epoch 116/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2266 - accuracy: 0.6364 - val_loss: 0.2936 - val_accuracy: 0.4595\n","Epoch 117/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2237 - accuracy: 0.5455 - val_loss: 0.2936 - val_accuracy: 0.4595\n","Epoch 118/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2159 - accuracy: 0.6364 - val_loss: 0.2933 - val_accuracy: 0.4595\n","Epoch 119/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2269 - accuracy: 0.6364 - val_loss: 0.2931 - val_accuracy: 0.4324\n","Epoch 120/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2105 - accuracy: 0.6364 - val_loss: 0.2941 - val_accuracy: 0.4595\n","Epoch 121/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2375 - accuracy: 0.4545 - val_loss: 0.2955 - val_accuracy: 0.4595\n","Epoch 122/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2342 - accuracy: 0.5455 - val_loss: 0.2958 - val_accuracy: 0.4595\n","Epoch 123/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2250 - accuracy: 0.8182 - val_loss: 0.2963 - val_accuracy: 0.4595\n","Epoch 124/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1893 - accuracy: 0.8182 - val_loss: 0.3001 - val_accuracy: 0.4324\n","Epoch 125/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2218 - accuracy: 0.7273 - val_loss: 0.3040 - val_accuracy: 0.4595\n","Epoch 126/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2414 - accuracy: 0.4545 - val_loss: 0.3022 - val_accuracy: 0.4324\n","Epoch 127/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1843 - accuracy: 0.8182 - val_loss: 0.3046 - val_accuracy: 0.4324\n","Epoch 128/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2651 - accuracy: 0.5455 - val_loss: 0.3029 - val_accuracy: 0.4595\n","Epoch 129/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2180 - accuracy: 0.7273 - val_loss: 0.3040 - val_accuracy: 0.4324\n","Epoch 130/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2292 - accuracy: 0.5455 - val_loss: 0.3047 - val_accuracy: 0.4324\n","2/2 [==============================] - 0s 117ms/step - loss: 0.3047 - accuracy: 0.4324\n","loss :  0.4324324429035187\n","total_loss :  3.513513594865799\n","num :  7\n","WARNING:tensorflow:Layer gru_35 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","WARNING:tensorflow:Layer gru_36 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","WARNING:tensorflow:Layer gru_37 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","WARNING:tensorflow:Layer gru_38 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","WARNING:tensorflow:Layer gru_39 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","Epoch 1/130\n","1/1 [==============================] - 12s 12s/step - loss: 0.3614 - accuracy: 0.6364 - val_loss: 0.4839 - val_accuracy: 0.4865\n","Epoch 2/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.3368 - accuracy: 0.6364 - val_loss: 0.4513 - val_accuracy: 0.4865\n","Epoch 3/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.3132 - accuracy: 0.6364 - val_loss: 0.4123 - val_accuracy: 0.4865\n","Epoch 4/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2813 - accuracy: 0.6364 - val_loss: 0.3659 - val_accuracy: 0.4865\n","Epoch 5/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2563 - accuracy: 0.6364 - val_loss: 0.3148 - val_accuracy: 0.4865\n","Epoch 6/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2346 - accuracy: 0.6364 - val_loss: 0.2729 - val_accuracy: 0.4865\n","Epoch 7/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2308 - accuracy: 0.6364 - val_loss: 0.2596 - val_accuracy: 0.4865\n","Epoch 8/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2417 - accuracy: 0.6364 - val_loss: 0.2645 - val_accuracy: 0.4865\n","Epoch 9/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2575 - accuracy: 0.5455 - val_loss: 0.2788 - val_accuracy: 0.4865\n","Epoch 10/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2395 - accuracy: 0.6364 - val_loss: 0.2965 - val_accuracy: 0.4865\n","Epoch 11/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2204 - accuracy: 0.6364 - val_loss: 0.3128 - val_accuracy: 0.4865\n","Epoch 12/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2313 - accuracy: 0.6364 - val_loss: 0.3253 - val_accuracy: 0.4865\n","Epoch 13/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2304 - accuracy: 0.6364 - val_loss: 0.3338 - val_accuracy: 0.4865\n","Epoch 14/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2368 - accuracy: 0.6364 - val_loss: 0.3382 - val_accuracy: 0.4865\n","Epoch 15/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2343 - accuracy: 0.6364 - val_loss: 0.3386 - val_accuracy: 0.4865\n","Epoch 16/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2398 - accuracy: 0.6364 - val_loss: 0.3359 - val_accuracy: 0.4865\n","Epoch 17/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2215 - accuracy: 0.6364 - val_loss: 0.3293 - val_accuracy: 0.4865\n","Epoch 18/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2280 - accuracy: 0.6364 - val_loss: 0.3206 - val_accuracy: 0.4865\n","Epoch 19/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2303 - accuracy: 0.6364 - val_loss: 0.3103 - val_accuracy: 0.4865\n","Epoch 20/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2374 - accuracy: 0.6364 - val_loss: 0.3014 - val_accuracy: 0.4865\n","Epoch 21/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2260 - accuracy: 0.6364 - val_loss: 0.2946 - val_accuracy: 0.4865\n","Epoch 22/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2273 - accuracy: 0.6364 - val_loss: 0.2908 - val_accuracy: 0.4865\n","Epoch 23/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2387 - accuracy: 0.6364 - val_loss: 0.2909 - val_accuracy: 0.4865\n","Epoch 24/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2321 - accuracy: 0.6364 - val_loss: 0.2946 - val_accuracy: 0.4865\n","Epoch 25/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2164 - accuracy: 0.7273 - val_loss: 0.3007 - val_accuracy: 0.4865\n","Epoch 26/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2255 - accuracy: 0.6364 - val_loss: 0.3073 - val_accuracy: 0.4865\n","Epoch 27/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2101 - accuracy: 0.6364 - val_loss: 0.3131 - val_accuracy: 0.4865\n","Epoch 28/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2374 - accuracy: 0.6364 - val_loss: 0.3184 - val_accuracy: 0.4865\n","Epoch 29/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2293 - accuracy: 0.6364 - val_loss: 0.3223 - val_accuracy: 0.4865\n","Epoch 30/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2116 - accuracy: 0.6364 - val_loss: 0.3231 - val_accuracy: 0.4865\n","Epoch 31/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2378 - accuracy: 0.6364 - val_loss: 0.3231 - val_accuracy: 0.4865\n","Epoch 32/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2138 - accuracy: 0.6364 - val_loss: 0.3205 - val_accuracy: 0.4865\n","Epoch 33/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2242 - accuracy: 0.6364 - val_loss: 0.3166 - val_accuracy: 0.4865\n","Epoch 34/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2332 - accuracy: 0.6364 - val_loss: 0.3128 - val_accuracy: 0.4865\n","Epoch 35/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1984 - accuracy: 0.6364 - val_loss: 0.3080 - val_accuracy: 0.4865\n","Epoch 36/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1989 - accuracy: 0.7273 - val_loss: 0.3039 - val_accuracy: 0.4865\n","Epoch 37/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2173 - accuracy: 0.7273 - val_loss: 0.3020 - val_accuracy: 0.4865\n","Epoch 38/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2174 - accuracy: 0.5455 - val_loss: 0.3023 - val_accuracy: 0.4865\n","Epoch 39/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2181 - accuracy: 0.6364 - val_loss: 0.3070 - val_accuracy: 0.4865\n","Epoch 40/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2149 - accuracy: 0.6364 - val_loss: 0.3132 - val_accuracy: 0.4865\n","Epoch 41/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2314 - accuracy: 0.5455 - val_loss: 0.3216 - val_accuracy: 0.4865\n","Epoch 42/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2285 - accuracy: 0.6364 - val_loss: 0.3315 - val_accuracy: 0.4865\n","Epoch 43/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2225 - accuracy: 0.6364 - val_loss: 0.3381 - val_accuracy: 0.4865\n","Epoch 44/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2416 - accuracy: 0.6364 - val_loss: 0.3415 - val_accuracy: 0.4865\n","Epoch 45/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2153 - accuracy: 0.6364 - val_loss: 0.3401 - val_accuracy: 0.4865\n","Epoch 46/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2110 - accuracy: 0.5455 - val_loss: 0.3368 - val_accuracy: 0.4865\n","Epoch 47/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2118 - accuracy: 0.6364 - val_loss: 0.3330 - val_accuracy: 0.4865\n","Epoch 48/130\n","1/1 [==============================] - 2s 2s/step - loss: 0.2206 - accuracy: 0.7273 - val_loss: 0.3294 - val_accuracy: 0.4865\n","Epoch 49/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1993 - accuracy: 0.8182 - val_loss: 0.3261 - val_accuracy: 0.4865\n","Epoch 50/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2298 - accuracy: 0.5455 - val_loss: 0.3281 - val_accuracy: 0.4865\n","Epoch 51/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2175 - accuracy: 0.6364 - val_loss: 0.3350 - val_accuracy: 0.4595\n","Epoch 52/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2355 - accuracy: 0.5455 - val_loss: 0.3465 - val_accuracy: 0.4865\n","Epoch 53/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2318 - accuracy: 0.6364 - val_loss: 0.3557 - val_accuracy: 0.4865\n","Epoch 54/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2116 - accuracy: 0.6364 - val_loss: 0.3598 - val_accuracy: 0.4865\n","Epoch 55/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2245 - accuracy: 0.6364 - val_loss: 0.3582 - val_accuracy: 0.4865\n","Epoch 56/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2318 - accuracy: 0.6364 - val_loss: 0.3536 - val_accuracy: 0.4865\n","Epoch 57/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2030 - accuracy: 0.7273 - val_loss: 0.3446 - val_accuracy: 0.4865\n","Epoch 58/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2183 - accuracy: 0.7273 - val_loss: 0.3367 - val_accuracy: 0.5135\n","Epoch 59/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1985 - accuracy: 0.7273 - val_loss: 0.3310 - val_accuracy: 0.5405\n","Epoch 60/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2060 - accuracy: 0.7273 - val_loss: 0.3319 - val_accuracy: 0.5135\n","Epoch 61/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2129 - accuracy: 0.5455 - val_loss: 0.3339 - val_accuracy: 0.5135\n","Epoch 62/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2249 - accuracy: 0.7273 - val_loss: 0.3408 - val_accuracy: 0.5135\n","Epoch 63/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2324 - accuracy: 0.6364 - val_loss: 0.3494 - val_accuracy: 0.4054\n","Epoch 64/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2053 - accuracy: 0.5455 - val_loss: 0.3563 - val_accuracy: 0.4865\n","Epoch 65/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2086 - accuracy: 0.6364 - val_loss: 0.3573 - val_accuracy: 0.4865\n","Epoch 66/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2093 - accuracy: 0.6364 - val_loss: 0.3518 - val_accuracy: 0.4054\n","Epoch 67/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2016 - accuracy: 0.6364 - val_loss: 0.3470 - val_accuracy: 0.5135\n","Epoch 68/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2342 - accuracy: 0.6364 - val_loss: 0.3466 - val_accuracy: 0.5135\n","Epoch 69/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1691 - accuracy: 0.8182 - val_loss: 0.3450 - val_accuracy: 0.5405\n","Epoch 70/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1892 - accuracy: 0.7273 - val_loss: 0.3452 - val_accuracy: 0.5405\n","Epoch 71/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2062 - accuracy: 0.5455 - val_loss: 0.3476 - val_accuracy: 0.5405\n","Epoch 72/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2000 - accuracy: 0.6364 - val_loss: 0.3510 - val_accuracy: 0.5405\n","Epoch 73/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2237 - accuracy: 0.6364 - val_loss: 0.3537 - val_accuracy: 0.5135\n","Epoch 74/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1702 - accuracy: 0.8182 - val_loss: 0.3541 - val_accuracy: 0.5405\n","Epoch 75/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2269 - accuracy: 0.6364 - val_loss: 0.3533 - val_accuracy: 0.5135\n","Epoch 76/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2030 - accuracy: 0.6364 - val_loss: 0.3522 - val_accuracy: 0.5405\n","Epoch 77/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2108 - accuracy: 0.5455 - val_loss: 0.3543 - val_accuracy: 0.5135\n","Epoch 78/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2160 - accuracy: 0.7273 - val_loss: 0.3549 - val_accuracy: 0.5405\n","Epoch 79/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2176 - accuracy: 0.7273 - val_loss: 0.3576 - val_accuracy: 0.5135\n","Epoch 80/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2352 - accuracy: 0.6364 - val_loss: 0.3682 - val_accuracy: 0.4595\n","Epoch 81/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2121 - accuracy: 0.6364 - val_loss: 0.3783 - val_accuracy: 0.4865\n","Epoch 82/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2566 - accuracy: 0.5455 - val_loss: 0.3837 - val_accuracy: 0.4865\n","Epoch 83/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2517 - accuracy: 0.6364 - val_loss: 0.3784 - val_accuracy: 0.4865\n","Epoch 84/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2374 - accuracy: 0.6364 - val_loss: 0.3688 - val_accuracy: 0.4865\n","Epoch 85/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2553 - accuracy: 0.5455 - val_loss: 0.3578 - val_accuracy: 0.4054\n","Epoch 86/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1956 - accuracy: 0.8182 - val_loss: 0.3472 - val_accuracy: 0.5135\n","Epoch 87/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2227 - accuracy: 0.6364 - val_loss: 0.3375 - val_accuracy: 0.5135\n","Epoch 88/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2407 - accuracy: 0.5455 - val_loss: 0.3327 - val_accuracy: 0.5135\n","Epoch 89/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2056 - accuracy: 0.6364 - val_loss: 0.3310 - val_accuracy: 0.5135\n","Epoch 90/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2429 - accuracy: 0.4545 - val_loss: 0.3329 - val_accuracy: 0.5405\n","Epoch 91/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1815 - accuracy: 0.8182 - val_loss: 0.3339 - val_accuracy: 0.4865\n","Epoch 92/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2032 - accuracy: 0.6364 - val_loss: 0.3349 - val_accuracy: 0.4595\n","Epoch 93/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2121 - accuracy: 0.7273 - val_loss: 0.3351 - val_accuracy: 0.4324\n","Epoch 94/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2202 - accuracy: 0.6364 - val_loss: 0.3341 - val_accuracy: 0.4595\n","Epoch 95/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2120 - accuracy: 0.5455 - val_loss: 0.3332 - val_accuracy: 0.4865\n","Epoch 96/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2225 - accuracy: 0.5455 - val_loss: 0.3316 - val_accuracy: 0.4865\n","Epoch 97/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2081 - accuracy: 0.6364 - val_loss: 0.3299 - val_accuracy: 0.5405\n","Epoch 98/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2533 - accuracy: 0.5455 - val_loss: 0.3333 - val_accuracy: 0.4865\n","Epoch 99/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2221 - accuracy: 0.6364 - val_loss: 0.3377 - val_accuracy: 0.4865\n","Epoch 100/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2162 - accuracy: 0.6364 - val_loss: 0.3410 - val_accuracy: 0.4865\n","Epoch 101/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2082 - accuracy: 0.6364 - val_loss: 0.3429 - val_accuracy: 0.4865\n","Epoch 102/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2409 - accuracy: 0.5455 - val_loss: 0.3444 - val_accuracy: 0.4865\n","Epoch 103/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2322 - accuracy: 0.6364 - val_loss: 0.3431 - val_accuracy: 0.4865\n","Epoch 104/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2232 - accuracy: 0.6364 - val_loss: 0.3410 - val_accuracy: 0.4865\n","Epoch 105/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2047 - accuracy: 0.7273 - val_loss: 0.3368 - val_accuracy: 0.4324\n","Epoch 106/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1937 - accuracy: 0.6364 - val_loss: 0.3319 - val_accuracy: 0.5405\n","Epoch 107/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2126 - accuracy: 0.6364 - val_loss: 0.3315 - val_accuracy: 0.5405\n","Epoch 108/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1957 - accuracy: 0.6364 - val_loss: 0.3323 - val_accuracy: 0.5135\n","Epoch 109/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2097 - accuracy: 0.7273 - val_loss: 0.3381 - val_accuracy: 0.5405\n","Epoch 110/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1971 - accuracy: 0.7273 - val_loss: 0.3424 - val_accuracy: 0.4865\n","Epoch 111/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1589 - accuracy: 0.8182 - val_loss: 0.3446 - val_accuracy: 0.5135\n","Epoch 112/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1991 - accuracy: 0.7273 - val_loss: 0.3481 - val_accuracy: 0.5135\n","Epoch 113/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1992 - accuracy: 0.7273 - val_loss: 0.3517 - val_accuracy: 0.5135\n","Epoch 114/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1703 - accuracy: 0.8182 - val_loss: 0.3539 - val_accuracy: 0.5405\n","Epoch 115/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2215 - accuracy: 0.5455 - val_loss: 0.3554 - val_accuracy: 0.5405\n","Epoch 116/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2302 - accuracy: 0.7273 - val_loss: 0.3586 - val_accuracy: 0.5405\n","Epoch 117/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1952 - accuracy: 0.6364 - val_loss: 0.3619 - val_accuracy: 0.5405\n","Epoch 118/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2231 - accuracy: 0.7273 - val_loss: 0.3638 - val_accuracy: 0.5405\n","Epoch 119/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1978 - accuracy: 0.6364 - val_loss: 0.3651 - val_accuracy: 0.5405\n","Epoch 120/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2041 - accuracy: 0.7273 - val_loss: 0.3638 - val_accuracy: 0.5405\n","Epoch 121/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2208 - accuracy: 0.5455 - val_loss: 0.3659 - val_accuracy: 0.5405\n","Epoch 122/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1896 - accuracy: 0.7273 - val_loss: 0.3672 - val_accuracy: 0.5405\n","Epoch 123/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1981 - accuracy: 0.7273 - val_loss: 0.3686 - val_accuracy: 0.5405\n","Epoch 124/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2215 - accuracy: 0.6364 - val_loss: 0.3686 - val_accuracy: 0.5405\n","Epoch 125/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1727 - accuracy: 0.8182 - val_loss: 0.3660 - val_accuracy: 0.5135\n","Epoch 126/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2142 - accuracy: 0.5455 - val_loss: 0.3654 - val_accuracy: 0.5135\n","Epoch 127/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2092 - accuracy: 0.7273 - val_loss: 0.3651 - val_accuracy: 0.5135\n","Epoch 128/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2402 - accuracy: 0.6364 - val_loss: 0.3656 - val_accuracy: 0.5135\n","Epoch 129/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1954 - accuracy: 0.7273 - val_loss: 0.3665 - val_accuracy: 0.5405\n","Epoch 130/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1809 - accuracy: 0.7273 - val_loss: 0.3638 - val_accuracy: 0.5135\n","2/2 [==============================] - 0s 105ms/step - loss: 0.3638 - accuracy: 0.5135\n","loss :  0.5135135054588318\n","total_loss :  4.027027100324631\n","num :  8\n","WARNING:tensorflow:Layer gru_40 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","WARNING:tensorflow:Layer gru_41 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","WARNING:tensorflow:Layer gru_42 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","WARNING:tensorflow:Layer gru_43 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","WARNING:tensorflow:Layer gru_44 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","Epoch 1/130\n","1/1 [==============================] - 13s 13s/step - loss: 0.6838 - accuracy: 0.2727 - val_loss: 0.4378 - val_accuracy: 0.4865\n","Epoch 2/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.6039 - accuracy: 0.2727 - val_loss: 0.3856 - val_accuracy: 0.4865\n","Epoch 3/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.5116 - accuracy: 0.2727 - val_loss: 0.3297 - val_accuracy: 0.4865\n","Epoch 4/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.4193 - accuracy: 0.2727 - val_loss: 0.2805 - val_accuracy: 0.4865\n","Epoch 5/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2862 - accuracy: 0.2727 - val_loss: 0.2614 - val_accuracy: 0.4324\n","Epoch 6/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2014 - accuracy: 0.7273 - val_loss: 0.3329 - val_accuracy: 0.5135\n","Epoch 7/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2213 - accuracy: 0.7273 - val_loss: 0.4176 - val_accuracy: 0.5135\n","Epoch 8/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2873 - accuracy: 0.7273 - val_loss: 0.3895 - val_accuracy: 0.5135\n","Epoch 9/130\n","1/1 [==============================] - 2s 2s/step - loss: 0.2640 - accuracy: 0.7273 - val_loss: 0.3283 - val_accuracy: 0.5135\n","Epoch 10/130\n","1/1 [==============================] - 2s 2s/step - loss: 0.2114 - accuracy: 0.7273 - val_loss: 0.2870 - val_accuracy: 0.5135\n","Epoch 11/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2139 - accuracy: 0.7273 - val_loss: 0.2664 - val_accuracy: 0.5135\n","Epoch 12/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2172 - accuracy: 0.7273 - val_loss: 0.2600 - val_accuracy: 0.4324\n","Epoch 13/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2298 - accuracy: 0.7273 - val_loss: 0.2596 - val_accuracy: 0.3784\n","Epoch 14/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2298 - accuracy: 0.6364 - val_loss: 0.2604 - val_accuracy: 0.4324\n","Epoch 15/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2364 - accuracy: 0.7273 - val_loss: 0.2606 - val_accuracy: 0.4324\n","Epoch 16/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2337 - accuracy: 0.7273 - val_loss: 0.2598 - val_accuracy: 0.4324\n","Epoch 17/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2440 - accuracy: 0.5455 - val_loss: 0.2588 - val_accuracy: 0.3784\n","Epoch 18/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2200 - accuracy: 0.8182 - val_loss: 0.2586 - val_accuracy: 0.4324\n","Epoch 19/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1998 - accuracy: 0.7273 - val_loss: 0.2617 - val_accuracy: 0.5135\n","Epoch 20/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2102 - accuracy: 0.7273 - val_loss: 0.2709 - val_accuracy: 0.5135\n","Epoch 21/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2030 - accuracy: 0.7273 - val_loss: 0.2857 - val_accuracy: 0.5135\n","Epoch 22/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1892 - accuracy: 0.7273 - val_loss: 0.3046 - val_accuracy: 0.5135\n","Epoch 23/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2213 - accuracy: 0.7273 - val_loss: 0.3155 - val_accuracy: 0.5135\n","Epoch 24/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2013 - accuracy: 0.7273 - val_loss: 0.3178 - val_accuracy: 0.5135\n","Epoch 25/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2504 - accuracy: 0.7273 - val_loss: 0.3047 - val_accuracy: 0.5135\n","Epoch 26/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2083 - accuracy: 0.7273 - val_loss: 0.2904 - val_accuracy: 0.5135\n","Epoch 27/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1907 - accuracy: 0.7273 - val_loss: 0.2782 - val_accuracy: 0.5135\n","Epoch 28/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1861 - accuracy: 0.7273 - val_loss: 0.2704 - val_accuracy: 0.5135\n","Epoch 29/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1844 - accuracy: 0.7273 - val_loss: 0.2657 - val_accuracy: 0.5135\n","Epoch 30/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1813 - accuracy: 0.7273 - val_loss: 0.2630 - val_accuracy: 0.5135\n","Epoch 31/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1903 - accuracy: 0.7273 - val_loss: 0.2620 - val_accuracy: 0.5135\n","Epoch 32/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1935 - accuracy: 0.7273 - val_loss: 0.2623 - val_accuracy: 0.5135\n","Epoch 33/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1795 - accuracy: 0.7273 - val_loss: 0.2638 - val_accuracy: 0.5135\n","Epoch 34/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1847 - accuracy: 0.7273 - val_loss: 0.2668 - val_accuracy: 0.5135\n","Epoch 35/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1983 - accuracy: 0.7273 - val_loss: 0.2710 - val_accuracy: 0.5135\n","Epoch 36/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2052 - accuracy: 0.7273 - val_loss: 0.2764 - val_accuracy: 0.5135\n","Epoch 37/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2237 - accuracy: 0.7273 - val_loss: 0.2804 - val_accuracy: 0.5135\n","Epoch 38/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1979 - accuracy: 0.7273 - val_loss: 0.2841 - val_accuracy: 0.5135\n","Epoch 39/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1964 - accuracy: 0.7273 - val_loss: 0.2874 - val_accuracy: 0.5135\n","Epoch 40/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1961 - accuracy: 0.7273 - val_loss: 0.2875 - val_accuracy: 0.5135\n","Epoch 41/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1913 - accuracy: 0.7273 - val_loss: 0.2856 - val_accuracy: 0.5135\n","Epoch 42/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1923 - accuracy: 0.7273 - val_loss: 0.2824 - val_accuracy: 0.5135\n","Epoch 43/130\n","1/1 [==============================] - 2s 2s/step - loss: 0.1970 - accuracy: 0.7273 - val_loss: 0.2782 - val_accuracy: 0.5135\n","Epoch 44/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2008 - accuracy: 0.7273 - val_loss: 0.2738 - val_accuracy: 0.5135\n","Epoch 45/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1867 - accuracy: 0.7273 - val_loss: 0.2714 - val_accuracy: 0.5135\n","Epoch 46/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2119 - accuracy: 0.7273 - val_loss: 0.2702 - val_accuracy: 0.5135\n","Epoch 47/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1985 - accuracy: 0.7273 - val_loss: 0.2694 - val_accuracy: 0.5135\n","Epoch 48/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1949 - accuracy: 0.7273 - val_loss: 0.2694 - val_accuracy: 0.5135\n","Epoch 49/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1761 - accuracy: 0.7273 - val_loss: 0.2705 - val_accuracy: 0.5135\n","Epoch 50/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1914 - accuracy: 0.7273 - val_loss: 0.2725 - val_accuracy: 0.5135\n","Epoch 51/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1801 - accuracy: 0.7273 - val_loss: 0.2751 - val_accuracy: 0.5135\n","Epoch 52/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1882 - accuracy: 0.7273 - val_loss: 0.2782 - val_accuracy: 0.5135\n","Epoch 53/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1922 - accuracy: 0.7273 - val_loss: 0.2807 - val_accuracy: 0.5135\n","Epoch 54/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1643 - accuracy: 0.7273 - val_loss: 0.2845 - val_accuracy: 0.5135\n","Epoch 55/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1796 - accuracy: 0.7273 - val_loss: 0.2862 - val_accuracy: 0.5135\n","Epoch 56/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2128 - accuracy: 0.7273 - val_loss: 0.2847 - val_accuracy: 0.5135\n","Epoch 57/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1672 - accuracy: 0.7273 - val_loss: 0.2817 - val_accuracy: 0.5135\n","Epoch 58/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1764 - accuracy: 0.7273 - val_loss: 0.2791 - val_accuracy: 0.5135\n","Epoch 59/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1839 - accuracy: 0.7273 - val_loss: 0.2779 - val_accuracy: 0.5135\n","Epoch 60/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1890 - accuracy: 0.7273 - val_loss: 0.2769 - val_accuracy: 0.5135\n","Epoch 61/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2053 - accuracy: 0.7273 - val_loss: 0.2754 - val_accuracy: 0.5135\n","Epoch 62/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1983 - accuracy: 0.7273 - val_loss: 0.2756 - val_accuracy: 0.5135\n","Epoch 63/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1975 - accuracy: 0.7273 - val_loss: 0.2757 - val_accuracy: 0.5135\n","Epoch 64/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1713 - accuracy: 0.7273 - val_loss: 0.2778 - val_accuracy: 0.5135\n","Epoch 65/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1760 - accuracy: 0.7273 - val_loss: 0.2781 - val_accuracy: 0.5135\n","Epoch 66/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1936 - accuracy: 0.7273 - val_loss: 0.2776 - val_accuracy: 0.5135\n","Epoch 67/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1906 - accuracy: 0.7273 - val_loss: 0.2775 - val_accuracy: 0.5135\n","Epoch 68/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1782 - accuracy: 0.7273 - val_loss: 0.2790 - val_accuracy: 0.5135\n","Epoch 69/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1882 - accuracy: 0.7273 - val_loss: 0.2791 - val_accuracy: 0.5135\n","Epoch 70/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2229 - accuracy: 0.7273 - val_loss: 0.2769 - val_accuracy: 0.5135\n","Epoch 71/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1812 - accuracy: 0.7273 - val_loss: 0.2744 - val_accuracy: 0.5135\n","Epoch 72/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1763 - accuracy: 0.7273 - val_loss: 0.2739 - val_accuracy: 0.5135\n","Epoch 73/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1771 - accuracy: 0.7273 - val_loss: 0.2742 - val_accuracy: 0.5135\n","Epoch 74/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1678 - accuracy: 0.7273 - val_loss: 0.2759 - val_accuracy: 0.5135\n","Epoch 75/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2105 - accuracy: 0.7273 - val_loss: 0.2758 - val_accuracy: 0.5135\n","Epoch 76/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1912 - accuracy: 0.7273 - val_loss: 0.2762 - val_accuracy: 0.5135\n","Epoch 77/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1888 - accuracy: 0.7273 - val_loss: 0.2761 - val_accuracy: 0.5135\n","Epoch 78/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2005 - accuracy: 0.7273 - val_loss: 0.2747 - val_accuracy: 0.5135\n","Epoch 79/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1887 - accuracy: 0.7273 - val_loss: 0.2737 - val_accuracy: 0.5135\n","Epoch 80/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2031 - accuracy: 0.7273 - val_loss: 0.2758 - val_accuracy: 0.5135\n","Epoch 81/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1886 - accuracy: 0.7273 - val_loss: 0.2793 - val_accuracy: 0.5135\n","Epoch 82/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1745 - accuracy: 0.7273 - val_loss: 0.2861 - val_accuracy: 0.5135\n","Epoch 83/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1969 - accuracy: 0.7273 - val_loss: 0.2867 - val_accuracy: 0.5135\n","Epoch 84/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1891 - accuracy: 0.7273 - val_loss: 0.2819 - val_accuracy: 0.5135\n","Epoch 85/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1872 - accuracy: 0.7273 - val_loss: 0.2768 - val_accuracy: 0.5135\n","Epoch 86/130\n","1/1 [==============================] - 2s 2s/step - loss: 0.1811 - accuracy: 0.7273 - val_loss: 0.2746 - val_accuracy: 0.5135\n","Epoch 87/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1795 - accuracy: 0.7273 - val_loss: 0.2735 - val_accuracy: 0.5135\n","Epoch 88/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2026 - accuracy: 0.7273 - val_loss: 0.2727 - val_accuracy: 0.5135\n","Epoch 89/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1813 - accuracy: 0.7273 - val_loss: 0.2732 - val_accuracy: 0.5135\n","Epoch 90/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1923 - accuracy: 0.7273 - val_loss: 0.2728 - val_accuracy: 0.5135\n","Epoch 91/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1996 - accuracy: 0.7273 - val_loss: 0.2740 - val_accuracy: 0.5135\n","Epoch 92/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1620 - accuracy: 0.7273 - val_loss: 0.2744 - val_accuracy: 0.5135\n","Epoch 93/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2231 - accuracy: 0.7273 - val_loss: 0.2729 - val_accuracy: 0.5135\n","Epoch 94/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1627 - accuracy: 0.7273 - val_loss: 0.2732 - val_accuracy: 0.5135\n","Epoch 95/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1854 - accuracy: 0.7273 - val_loss: 0.2764 - val_accuracy: 0.5135\n","Epoch 96/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2051 - accuracy: 0.7273 - val_loss: 0.2770 - val_accuracy: 0.5135\n","Epoch 97/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1888 - accuracy: 0.7273 - val_loss: 0.2786 - val_accuracy: 0.5135\n","Epoch 98/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1870 - accuracy: 0.7273 - val_loss: 0.2802 - val_accuracy: 0.5135\n","Epoch 99/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1779 - accuracy: 0.7273 - val_loss: 0.2871 - val_accuracy: 0.5135\n","Epoch 100/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1895 - accuracy: 0.7273 - val_loss: 0.2924 - val_accuracy: 0.5135\n","Epoch 101/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1946 - accuracy: 0.7273 - val_loss: 0.2891 - val_accuracy: 0.5135\n","Epoch 102/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1653 - accuracy: 0.7273 - val_loss: 0.2815 - val_accuracy: 0.5135\n","Epoch 103/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1730 - accuracy: 0.7273 - val_loss: 0.2773 - val_accuracy: 0.4865\n","Epoch 104/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1800 - accuracy: 0.7273 - val_loss: 0.2728 - val_accuracy: 0.5405\n","Epoch 105/130\n","1/1 [==============================] - 2s 2s/step - loss: 0.1885 - accuracy: 0.7273 - val_loss: 0.2700 - val_accuracy: 0.5405\n","Epoch 106/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1878 - accuracy: 0.7273 - val_loss: 0.2709 - val_accuracy: 0.5135\n","Epoch 107/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1993 - accuracy: 0.8182 - val_loss: 0.2765 - val_accuracy: 0.5676\n","Epoch 108/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1680 - accuracy: 0.7273 - val_loss: 0.2869 - val_accuracy: 0.5135\n","Epoch 109/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1503 - accuracy: 0.8182 - val_loss: 0.3021 - val_accuracy: 0.5135\n","Epoch 110/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2209 - accuracy: 0.7273 - val_loss: 0.2968 - val_accuracy: 0.5135\n","Epoch 111/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2188 - accuracy: 0.7273 - val_loss: 0.2822 - val_accuracy: 0.5676\n","Epoch 112/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1437 - accuracy: 0.7273 - val_loss: 0.2762 - val_accuracy: 0.5135\n","Epoch 113/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1552 - accuracy: 0.7273 - val_loss: 0.2750 - val_accuracy: 0.5135\n","Epoch 114/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1652 - accuracy: 0.7273 - val_loss: 0.2787 - val_accuracy: 0.5135\n","Epoch 115/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2077 - accuracy: 0.7273 - val_loss: 0.2808 - val_accuracy: 0.5135\n","Epoch 116/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1760 - accuracy: 0.6364 - val_loss: 0.2842 - val_accuracy: 0.5135\n","Epoch 117/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1639 - accuracy: 0.7273 - val_loss: 0.2908 - val_accuracy: 0.5405\n","Epoch 118/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1562 - accuracy: 0.8182 - val_loss: 0.2944 - val_accuracy: 0.5405\n","Epoch 119/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2072 - accuracy: 0.7273 - val_loss: 0.2972 - val_accuracy: 0.5405\n","Epoch 120/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1670 - accuracy: 0.7273 - val_loss: 0.2971 - val_accuracy: 0.5135\n","Epoch 121/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1992 - accuracy: 0.7273 - val_loss: 0.2951 - val_accuracy: 0.5135\n","Epoch 122/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2174 - accuracy: 0.7273 - val_loss: 0.2872 - val_accuracy: 0.5135\n","Epoch 123/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1814 - accuracy: 0.8182 - val_loss: 0.2847 - val_accuracy: 0.5135\n","Epoch 124/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1339 - accuracy: 0.8182 - val_loss: 0.2836 - val_accuracy: 0.5135\n","Epoch 125/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1988 - accuracy: 0.6364 - val_loss: 0.2859 - val_accuracy: 0.5135\n","Epoch 126/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1820 - accuracy: 0.7273 - val_loss: 0.2933 - val_accuracy: 0.4865\n","Epoch 127/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1645 - accuracy: 0.7273 - val_loss: 0.3090 - val_accuracy: 0.5135\n","Epoch 128/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1427 - accuracy: 0.7273 - val_loss: 0.3188 - val_accuracy: 0.5405\n","Epoch 129/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1845 - accuracy: 0.8182 - val_loss: 0.3202 - val_accuracy: 0.5405\n","Epoch 130/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1672 - accuracy: 0.7273 - val_loss: 0.3065 - val_accuracy: 0.5135\n","2/2 [==============================] - 0s 112ms/step - loss: 0.3065 - accuracy: 0.5135\n","loss :  0.5135135054588318\n","total_loss :  4.5405406057834625\n","num :  9\n","WARNING:tensorflow:Layer gru_45 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","WARNING:tensorflow:Layer gru_46 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","WARNING:tensorflow:Layer gru_47 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","WARNING:tensorflow:Layer gru_48 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","WARNING:tensorflow:Layer gru_49 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","Epoch 1/130\n","1/1 [==============================] - 12s 12s/step - loss: 0.2707 - accuracy: 0.7273 - val_loss: 0.5148 - val_accuracy: 0.4324\n","Epoch 2/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2460 - accuracy: 0.7273 - val_loss: 0.4683 - val_accuracy: 0.4324\n","Epoch 3/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2281 - accuracy: 0.7273 - val_loss: 0.4128 - val_accuracy: 0.4324\n","Epoch 4/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2064 - accuracy: 0.7273 - val_loss: 0.3546 - val_accuracy: 0.4324\n","Epoch 5/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1988 - accuracy: 0.7273 - val_loss: 0.3080 - val_accuracy: 0.4324\n","Epoch 6/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2047 - accuracy: 0.7273 - val_loss: 0.3011 - val_accuracy: 0.4324\n","Epoch 7/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2199 - accuracy: 0.7273 - val_loss: 0.3164 - val_accuracy: 0.4324\n","Epoch 8/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2023 - accuracy: 0.7273 - val_loss: 0.3372 - val_accuracy: 0.4324\n","Epoch 9/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2072 - accuracy: 0.7273 - val_loss: 0.3597 - val_accuracy: 0.4324\n","Epoch 10/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1964 - accuracy: 0.7273 - val_loss: 0.3766 - val_accuracy: 0.4324\n","Epoch 11/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1997 - accuracy: 0.7273 - val_loss: 0.3867 - val_accuracy: 0.4324\n","Epoch 12/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1993 - accuracy: 0.7273 - val_loss: 0.3897 - val_accuracy: 0.4324\n","Epoch 13/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2015 - accuracy: 0.7273 - val_loss: 0.3875 - val_accuracy: 0.4324\n","Epoch 14/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2063 - accuracy: 0.7273 - val_loss: 0.3807 - val_accuracy: 0.4324\n","Epoch 15/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2001 - accuracy: 0.7273 - val_loss: 0.3704 - val_accuracy: 0.4324\n","Epoch 16/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1962 - accuracy: 0.7273 - val_loss: 0.3577 - val_accuracy: 0.4324\n","Epoch 17/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1860 - accuracy: 0.7273 - val_loss: 0.3429 - val_accuracy: 0.4324\n","Epoch 18/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1900 - accuracy: 0.7273 - val_loss: 0.3306 - val_accuracy: 0.4324\n","Epoch 19/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1969 - accuracy: 0.7273 - val_loss: 0.3221 - val_accuracy: 0.4324\n","Epoch 20/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1952 - accuracy: 0.7273 - val_loss: 0.3181 - val_accuracy: 0.4324\n","Epoch 21/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1983 - accuracy: 0.7273 - val_loss: 0.3191 - val_accuracy: 0.4324\n","Epoch 22/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1928 - accuracy: 0.7273 - val_loss: 0.3241 - val_accuracy: 0.4324\n","Epoch 23/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1926 - accuracy: 0.7273 - val_loss: 0.3329 - val_accuracy: 0.4324\n","Epoch 24/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1947 - accuracy: 0.7273 - val_loss: 0.3428 - val_accuracy: 0.4324\n","Epoch 25/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1921 - accuracy: 0.7273 - val_loss: 0.3514 - val_accuracy: 0.4324\n","Epoch 26/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1905 - accuracy: 0.7273 - val_loss: 0.3584 - val_accuracy: 0.4324\n","Epoch 27/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1870 - accuracy: 0.7273 - val_loss: 0.3604 - val_accuracy: 0.4324\n","Epoch 28/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1821 - accuracy: 0.7273 - val_loss: 0.3574 - val_accuracy: 0.4324\n","Epoch 29/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1978 - accuracy: 0.7273 - val_loss: 0.3520 - val_accuracy: 0.4324\n","Epoch 30/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1875 - accuracy: 0.7273 - val_loss: 0.3461 - val_accuracy: 0.4324\n","Epoch 31/130\n","1/1 [==============================] - 2s 2s/step - loss: 0.1864 - accuracy: 0.7273 - val_loss: 0.3398 - val_accuracy: 0.4324\n","Epoch 32/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1798 - accuracy: 0.7273 - val_loss: 0.3321 - val_accuracy: 0.4324\n","Epoch 33/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1763 - accuracy: 0.7273 - val_loss: 0.3260 - val_accuracy: 0.4324\n","Epoch 34/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1800 - accuracy: 0.7273 - val_loss: 0.3221 - val_accuracy: 0.4595\n","Epoch 35/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1755 - accuracy: 0.7273 - val_loss: 0.3213 - val_accuracy: 0.4324\n","Epoch 36/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1808 - accuracy: 0.7273 - val_loss: 0.3266 - val_accuracy: 0.4324\n","Epoch 37/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1704 - accuracy: 0.7273 - val_loss: 0.3347 - val_accuracy: 0.4324\n","Epoch 38/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1883 - accuracy: 0.7273 - val_loss: 0.3437 - val_accuracy: 0.4324\n","Epoch 39/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1662 - accuracy: 0.7273 - val_loss: 0.3489 - val_accuracy: 0.4054\n","Epoch 40/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1545 - accuracy: 0.7273 - val_loss: 0.3537 - val_accuracy: 0.4324\n","Epoch 41/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1890 - accuracy: 0.7273 - val_loss: 0.3608 - val_accuracy: 0.4865\n","Epoch 42/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1822 - accuracy: 0.7273 - val_loss: 0.3584 - val_accuracy: 0.4595\n","Epoch 43/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1624 - accuracy: 0.7273 - val_loss: 0.3564 - val_accuracy: 0.4865\n","Epoch 44/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1638 - accuracy: 0.7273 - val_loss: 0.3566 - val_accuracy: 0.5135\n","Epoch 45/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1728 - accuracy: 0.7273 - val_loss: 0.3656 - val_accuracy: 0.5405\n","Epoch 46/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1633 - accuracy: 0.8182 - val_loss: 0.3796 - val_accuracy: 0.5135\n","Epoch 47/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1761 - accuracy: 0.7273 - val_loss: 0.3940 - val_accuracy: 0.5135\n","Epoch 48/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1766 - accuracy: 0.7273 - val_loss: 0.4064 - val_accuracy: 0.4865\n","Epoch 49/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1700 - accuracy: 0.7273 - val_loss: 0.4176 - val_accuracy: 0.5135\n","Epoch 50/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1687 - accuracy: 0.7273 - val_loss: 0.4388 - val_accuracy: 0.5405\n","Epoch 51/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1353 - accuracy: 0.7273 - val_loss: 0.5008 - val_accuracy: 0.5676\n","Epoch 52/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1531 - accuracy: 0.7273 - val_loss: 0.5339 - val_accuracy: 0.5676\n","Epoch 53/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1368 - accuracy: 0.8182 - val_loss: 0.5073 - val_accuracy: 0.5405\n","Epoch 54/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1826 - accuracy: 0.6364 - val_loss: 0.4982 - val_accuracy: 0.5405\n","Epoch 55/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1315 - accuracy: 0.7273 - val_loss: 0.5181 - val_accuracy: 0.5405\n","Epoch 56/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1529 - accuracy: 0.7273 - val_loss: 0.5757 - val_accuracy: 0.5676\n","Epoch 57/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1352 - accuracy: 0.8182 - val_loss: 0.6775 - val_accuracy: 0.5405\n","Epoch 58/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1550 - accuracy: 0.6364 - val_loss: 0.6877 - val_accuracy: 0.5405\n","Epoch 59/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1729 - accuracy: 0.9091 - val_loss: 0.6040 - val_accuracy: 0.5676\n","Epoch 60/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1747 - accuracy: 0.7273 - val_loss: 0.5513 - val_accuracy: 0.5405\n","Epoch 61/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1914 - accuracy: 0.7273 - val_loss: 0.5419 - val_accuracy: 0.5405\n","Epoch 62/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1786 - accuracy: 0.7273 - val_loss: 0.5556 - val_accuracy: 0.5676\n","Epoch 63/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1497 - accuracy: 0.8182 - val_loss: 0.5860 - val_accuracy: 0.5405\n","Epoch 64/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1651 - accuracy: 0.7273 - val_loss: 0.6181 - val_accuracy: 0.5405\n","Epoch 65/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1348 - accuracy: 0.8182 - val_loss: 0.6295 - val_accuracy: 0.5135\n","Epoch 66/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1649 - accuracy: 0.7273 - val_loss: 0.6140 - val_accuracy: 0.5135\n","Epoch 67/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1278 - accuracy: 0.8182 - val_loss: 0.5802 - val_accuracy: 0.5405\n","Epoch 68/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1423 - accuracy: 0.8182 - val_loss: 0.5471 - val_accuracy: 0.5405\n","Epoch 69/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1406 - accuracy: 0.8182 - val_loss: 0.5184 - val_accuracy: 0.5676\n","Epoch 70/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1284 - accuracy: 0.8182 - val_loss: 0.4988 - val_accuracy: 0.5676\n","Epoch 71/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1578 - accuracy: 0.7273 - val_loss: 0.4979 - val_accuracy: 0.5676\n","Epoch 72/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1564 - accuracy: 0.7273 - val_loss: 0.5100 - val_accuracy: 0.5676\n","Epoch 73/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1432 - accuracy: 0.6364 - val_loss: 0.5399 - val_accuracy: 0.5405\n","Epoch 74/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1331 - accuracy: 0.7273 - val_loss: 0.5761 - val_accuracy: 0.5405\n","Epoch 75/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1684 - accuracy: 0.5455 - val_loss: 0.6031 - val_accuracy: 0.5135\n","Epoch 76/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1241 - accuracy: 0.8182 - val_loss: 0.6204 - val_accuracy: 0.5135\n","Epoch 77/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1301 - accuracy: 0.9091 - val_loss: 0.6204 - val_accuracy: 0.5135\n","Epoch 78/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1321 - accuracy: 0.7273 - val_loss: 0.6184 - val_accuracy: 0.5405\n","Epoch 79/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1612 - accuracy: 0.7273 - val_loss: 0.6198 - val_accuracy: 0.5405\n","Epoch 80/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1438 - accuracy: 0.7273 - val_loss: 0.6192 - val_accuracy: 0.5405\n","Epoch 81/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1532 - accuracy: 0.7273 - val_loss: 0.6024 - val_accuracy: 0.5405\n","Epoch 82/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1241 - accuracy: 0.8182 - val_loss: 0.5999 - val_accuracy: 0.5405\n","Epoch 83/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1334 - accuracy: 0.7273 - val_loss: 0.6371 - val_accuracy: 0.5405\n","Epoch 84/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1568 - accuracy: 0.6364 - val_loss: 0.6968 - val_accuracy: 0.5135\n","Epoch 85/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1415 - accuracy: 0.6364 - val_loss: 0.7571 - val_accuracy: 0.5135\n","Epoch 86/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1405 - accuracy: 0.6364 - val_loss: 0.7578 - val_accuracy: 0.5135\n","Epoch 87/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1113 - accuracy: 0.8182 - val_loss: 0.7180 - val_accuracy: 0.5135\n","Epoch 88/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1029 - accuracy: 0.8182 - val_loss: 0.6982 - val_accuracy: 0.5405\n","Epoch 89/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1309 - accuracy: 0.8182 - val_loss: 0.7137 - val_accuracy: 0.5405\n","Epoch 90/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1014 - accuracy: 0.8182 - val_loss: 0.7595 - val_accuracy: 0.5135\n","Epoch 91/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1090 - accuracy: 0.8182 - val_loss: 0.8288 - val_accuracy: 0.5135\n","Epoch 92/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1415 - accuracy: 0.8182 - val_loss: 0.8842 - val_accuracy: 0.5135\n","Epoch 93/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1549 - accuracy: 0.6364 - val_loss: 0.9117 - val_accuracy: 0.5135\n","Epoch 94/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1695 - accuracy: 0.7273 - val_loss: 0.9447 - val_accuracy: 0.5405\n","Epoch 95/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1294 - accuracy: 0.8182 - val_loss: 0.8923 - val_accuracy: 0.5135\n","Epoch 96/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1510 - accuracy: 0.8182 - val_loss: 0.8010 - val_accuracy: 0.5135\n","Epoch 97/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1563 - accuracy: 0.7273 - val_loss: 0.7403 - val_accuracy: 0.5405\n","Epoch 98/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1332 - accuracy: 0.8182 - val_loss: 0.7286 - val_accuracy: 0.5405\n","Epoch 99/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1116 - accuracy: 0.9091 - val_loss: 0.7645 - val_accuracy: 0.5135\n","Epoch 100/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1568 - accuracy: 0.7273 - val_loss: 0.7728 - val_accuracy: 0.5135\n","Epoch 101/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1323 - accuracy: 0.8182 - val_loss: 0.7949 - val_accuracy: 0.5135\n","Epoch 102/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1589 - accuracy: 0.7273 - val_loss: 0.6993 - val_accuracy: 0.5405\n","Epoch 103/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1294 - accuracy: 0.7273 - val_loss: 0.6399 - val_accuracy: 0.5405\n","Epoch 104/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1651 - accuracy: 0.8182 - val_loss: 0.5992 - val_accuracy: 0.5405\n","Epoch 105/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1793 - accuracy: 0.7273 - val_loss: 0.5703 - val_accuracy: 0.5405\n","Epoch 106/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1490 - accuracy: 0.7273 - val_loss: 0.5569 - val_accuracy: 0.5405\n","Epoch 107/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1770 - accuracy: 0.6364 - val_loss: 0.5537 - val_accuracy: 0.5405\n","Epoch 108/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1650 - accuracy: 0.7273 - val_loss: 0.5473 - val_accuracy: 0.5135\n","Epoch 109/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1379 - accuracy: 0.7273 - val_loss: 0.5598 - val_accuracy: 0.5135\n","Epoch 110/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1211 - accuracy: 0.7273 - val_loss: 0.5673 - val_accuracy: 0.5135\n","Epoch 111/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2015 - accuracy: 0.7273 - val_loss: 0.5203 - val_accuracy: 0.5135\n","Epoch 112/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1559 - accuracy: 0.7273 - val_loss: 0.4862 - val_accuracy: 0.5405\n","Epoch 113/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1252 - accuracy: 0.8182 - val_loss: 0.4677 - val_accuracy: 0.5405\n","Epoch 114/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1559 - accuracy: 0.8182 - val_loss: 0.4576 - val_accuracy: 0.5676\n","Epoch 115/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1520 - accuracy: 0.7273 - val_loss: 0.4588 - val_accuracy: 0.5405\n","Epoch 116/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1536 - accuracy: 0.8182 - val_loss: 0.4649 - val_accuracy: 0.5405\n","Epoch 117/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1550 - accuracy: 0.8182 - val_loss: 0.4812 - val_accuracy: 0.5405\n","Epoch 118/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1564 - accuracy: 0.7273 - val_loss: 0.5109 - val_accuracy: 0.5135\n","Epoch 119/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1355 - accuracy: 0.7273 - val_loss: 0.5407 - val_accuracy: 0.5135\n","Epoch 120/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1241 - accuracy: 0.9091 - val_loss: 0.5750 - val_accuracy: 0.5135\n","Epoch 121/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1387 - accuracy: 0.7273 - val_loss: 0.5949 - val_accuracy: 0.5135\n","Epoch 122/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1284 - accuracy: 0.8182 - val_loss: 0.5837 - val_accuracy: 0.5135\n","Epoch 123/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1127 - accuracy: 0.8182 - val_loss: 0.5741 - val_accuracy: 0.5135\n","Epoch 124/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1624 - accuracy: 0.8182 - val_loss: 0.5681 - val_accuracy: 0.5405\n","Epoch 125/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1594 - accuracy: 0.7273 - val_loss: 0.5719 - val_accuracy: 0.5405\n","Epoch 126/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1402 - accuracy: 0.7273 - val_loss: 0.6132 - val_accuracy: 0.5135\n","Epoch 127/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1598 - accuracy: 0.8182 - val_loss: 0.6839 - val_accuracy: 0.5135\n","Epoch 128/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1260 - accuracy: 0.8182 - val_loss: 0.7937 - val_accuracy: 0.5405\n","Epoch 129/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1167 - accuracy: 0.8182 - val_loss: 0.8535 - val_accuracy: 0.5405\n","Epoch 130/130\n","1/1 [==============================] - 2s 2s/step - loss: 0.2123 - accuracy: 0.7273 - val_loss: 0.7218 - val_accuracy: 0.5135\n","2/2 [==============================] - 0s 98ms/step - loss: 0.7218 - accuracy: 0.5135\n","loss :  0.5135135054588318\n","total_loss :  5.054054111242294\n","num :  10\n","WARNING:tensorflow:Layer gru_50 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","WARNING:tensorflow:Layer gru_51 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","WARNING:tensorflow:Layer gru_52 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","WARNING:tensorflow:Layer gru_53 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","WARNING:tensorflow:Layer gru_54 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","Epoch 1/130\n","1/1 [==============================] - 12s 12s/step - loss: 0.3726 - accuracy: 0.6364 - val_loss: 0.5209 - val_accuracy: 0.4595\n","Epoch 2/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.3500 - accuracy: 0.6364 - val_loss: 0.4941 - val_accuracy: 0.4595\n","Epoch 3/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.3322 - accuracy: 0.6364 - val_loss: 0.4644 - val_accuracy: 0.4595\n","Epoch 4/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.3101 - accuracy: 0.6364 - val_loss: 0.4270 - val_accuracy: 0.4595\n","Epoch 5/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2895 - accuracy: 0.6364 - val_loss: 0.3821 - val_accuracy: 0.4595\n","Epoch 6/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2580 - accuracy: 0.6364 - val_loss: 0.3325 - val_accuracy: 0.4595\n","Epoch 7/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2425 - accuracy: 0.6364 - val_loss: 0.2850 - val_accuracy: 0.4595\n","Epoch 8/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2347 - accuracy: 0.6364 - val_loss: 0.2563 - val_accuracy: 0.4595\n","Epoch 9/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2524 - accuracy: 0.3636 - val_loss: 0.2534 - val_accuracy: 0.4595\n","Epoch 10/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2464 - accuracy: 0.6364 - val_loss: 0.2594 - val_accuracy: 0.4595\n","Epoch 11/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2404 - accuracy: 0.5455 - val_loss: 0.2711 - val_accuracy: 0.4595\n","Epoch 12/130\n","1/1 [==============================] - 2s 2s/step - loss: 0.2331 - accuracy: 0.6364 - val_loss: 0.2867 - val_accuracy: 0.4595\n","Epoch 13/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2449 - accuracy: 0.6364 - val_loss: 0.3034 - val_accuracy: 0.4595\n","Epoch 14/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2232 - accuracy: 0.6364 - val_loss: 0.3166 - val_accuracy: 0.4595\n","Epoch 15/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2240 - accuracy: 0.6364 - val_loss: 0.3253 - val_accuracy: 0.4595\n","Epoch 16/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2299 - accuracy: 0.6364 - val_loss: 0.3293 - val_accuracy: 0.4595\n","Epoch 17/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2360 - accuracy: 0.6364 - val_loss: 0.3302 - val_accuracy: 0.4595\n","Epoch 18/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2346 - accuracy: 0.6364 - val_loss: 0.3279 - val_accuracy: 0.4595\n","Epoch 19/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2299 - accuracy: 0.6364 - val_loss: 0.3228 - val_accuracy: 0.4595\n","Epoch 20/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2329 - accuracy: 0.6364 - val_loss: 0.3160 - val_accuracy: 0.4595\n","Epoch 21/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2323 - accuracy: 0.6364 - val_loss: 0.3079 - val_accuracy: 0.4595\n","Epoch 22/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2337 - accuracy: 0.6364 - val_loss: 0.2996 - val_accuracy: 0.4595\n","Epoch 23/130\n","1/1 [==============================] - 2s 2s/step - loss: 0.2361 - accuracy: 0.6364 - val_loss: 0.2925 - val_accuracy: 0.4595\n","Epoch 24/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2200 - accuracy: 0.6364 - val_loss: 0.2861 - val_accuracy: 0.4595\n","Epoch 25/130\n","1/1 [==============================] - 2s 2s/step - loss: 0.2280 - accuracy: 0.6364 - val_loss: 0.2821 - val_accuracy: 0.4595\n","Epoch 26/130\n","1/1 [==============================] - 2s 2s/step - loss: 0.2378 - accuracy: 0.6364 - val_loss: 0.2816 - val_accuracy: 0.4595\n","Epoch 27/130\n","1/1 [==============================] - 2s 2s/step - loss: 0.2162 - accuracy: 0.6364 - val_loss: 0.2832 - val_accuracy: 0.4595\n","Epoch 28/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2253 - accuracy: 0.6364 - val_loss: 0.2869 - val_accuracy: 0.4595\n","Epoch 29/130\n","1/1 [==============================] - 2s 2s/step - loss: 0.2431 - accuracy: 0.6364 - val_loss: 0.2930 - val_accuracy: 0.4595\n","Epoch 30/130\n","1/1 [==============================] - 2s 2s/step - loss: 0.2289 - accuracy: 0.6364 - val_loss: 0.2996 - val_accuracy: 0.4595\n","Epoch 31/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2321 - accuracy: 0.6364 - val_loss: 0.3060 - val_accuracy: 0.4595\n","Epoch 32/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2251 - accuracy: 0.6364 - val_loss: 0.3110 - val_accuracy: 0.4595\n","Epoch 33/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2190 - accuracy: 0.6364 - val_loss: 0.3134 - val_accuracy: 0.4595\n","Epoch 34/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2299 - accuracy: 0.6364 - val_loss: 0.3144 - val_accuracy: 0.4595\n","Epoch 35/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2357 - accuracy: 0.6364 - val_loss: 0.3140 - val_accuracy: 0.4595\n","Epoch 36/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2330 - accuracy: 0.6364 - val_loss: 0.3129 - val_accuracy: 0.4595\n","Epoch 37/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2289 - accuracy: 0.6364 - val_loss: 0.3110 - val_accuracy: 0.4595\n","Epoch 38/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2245 - accuracy: 0.6364 - val_loss: 0.3084 - val_accuracy: 0.4595\n","Epoch 39/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2264 - accuracy: 0.6364 - val_loss: 0.3053 - val_accuracy: 0.4595\n","Epoch 40/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2229 - accuracy: 0.6364 - val_loss: 0.3024 - val_accuracy: 0.4595\n","Epoch 41/130\n","1/1 [==============================] - 2s 2s/step - loss: 0.2208 - accuracy: 0.6364 - val_loss: 0.3001 - val_accuracy: 0.4595\n","Epoch 42/130\n","1/1 [==============================] - 2s 2s/step - loss: 0.2235 - accuracy: 0.6364 - val_loss: 0.2988 - val_accuracy: 0.4595\n","Epoch 43/130\n","1/1 [==============================] - 2s 2s/step - loss: 0.2143 - accuracy: 0.6364 - val_loss: 0.2974 - val_accuracy: 0.4595\n","Epoch 44/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2049 - accuracy: 0.7273 - val_loss: 0.2968 - val_accuracy: 0.4595\n","Epoch 45/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2220 - accuracy: 0.6364 - val_loss: 0.2993 - val_accuracy: 0.4595\n","Epoch 46/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2129 - accuracy: 0.6364 - val_loss: 0.3029 - val_accuracy: 0.4595\n","Epoch 47/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2166 - accuracy: 0.6364 - val_loss: 0.3069 - val_accuracy: 0.4595\n","Epoch 48/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2137 - accuracy: 0.6364 - val_loss: 0.3113 - val_accuracy: 0.4595\n","Epoch 49/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2248 - accuracy: 0.6364 - val_loss: 0.3159 - val_accuracy: 0.4595\n","Epoch 50/130\n","1/1 [==============================] - 2s 2s/step - loss: 0.2144 - accuracy: 0.6364 - val_loss: 0.3207 - val_accuracy: 0.4595\n","Epoch 51/130\n","1/1 [==============================] - 2s 2s/step - loss: 0.2239 - accuracy: 0.6364 - val_loss: 0.3250 - val_accuracy: 0.4595\n","Epoch 52/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2396 - accuracy: 0.6364 - val_loss: 0.3296 - val_accuracy: 0.4595\n","Epoch 53/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2305 - accuracy: 0.6364 - val_loss: 0.3319 - val_accuracy: 0.4595\n","Epoch 54/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1972 - accuracy: 0.6364 - val_loss: 0.3307 - val_accuracy: 0.4595\n","Epoch 55/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2139 - accuracy: 0.6364 - val_loss: 0.3276 - val_accuracy: 0.4595\n","Epoch 56/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2230 - accuracy: 0.6364 - val_loss: 0.3232 - val_accuracy: 0.4595\n","Epoch 57/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2014 - accuracy: 0.6364 - val_loss: 0.3176 - val_accuracy: 0.4595\n","Epoch 58/130\n","1/1 [==============================] - 2s 2s/step - loss: 0.2203 - accuracy: 0.5455 - val_loss: 0.3166 - val_accuracy: 0.4054\n","Epoch 59/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2311 - accuracy: 0.6364 - val_loss: 0.3204 - val_accuracy: 0.4054\n","Epoch 60/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2123 - accuracy: 0.7273 - val_loss: 0.3247 - val_accuracy: 0.4324\n","Epoch 61/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2054 - accuracy: 0.7273 - val_loss: 0.3306 - val_accuracy: 0.4595\n","Epoch 62/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2281 - accuracy: 0.6364 - val_loss: 0.3389 - val_accuracy: 0.4595\n","Epoch 63/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1896 - accuracy: 0.7273 - val_loss: 0.3449 - val_accuracy: 0.4595\n","Epoch 64/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1980 - accuracy: 0.6364 - val_loss: 0.3493 - val_accuracy: 0.4595\n","Epoch 65/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1965 - accuracy: 0.7273 - val_loss: 0.3498 - val_accuracy: 0.4595\n","Epoch 66/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1894 - accuracy: 0.8182 - val_loss: 0.3490 - val_accuracy: 0.4324\n","Epoch 67/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2013 - accuracy: 0.7273 - val_loss: 0.3482 - val_accuracy: 0.4054\n","Epoch 68/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2042 - accuracy: 0.7273 - val_loss: 0.3490 - val_accuracy: 0.4054\n","Epoch 69/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2185 - accuracy: 0.7273 - val_loss: 0.3534 - val_accuracy: 0.4054\n","Epoch 70/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2148 - accuracy: 0.7273 - val_loss: 0.3584 - val_accuracy: 0.4054\n","Epoch 71/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1848 - accuracy: 0.8182 - val_loss: 0.3608 - val_accuracy: 0.4054\n","Epoch 72/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1946 - accuracy: 0.7273 - val_loss: 0.3636 - val_accuracy: 0.4054\n","Epoch 73/130\n","1/1 [==============================] - 2s 2s/step - loss: 0.1935 - accuracy: 0.7273 - val_loss: 0.3666 - val_accuracy: 0.4324\n","Epoch 74/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1825 - accuracy: 0.9091 - val_loss: 0.3706 - val_accuracy: 0.4324\n","Epoch 75/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1950 - accuracy: 0.8182 - val_loss: 0.3749 - val_accuracy: 0.4324\n","Epoch 76/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2030 - accuracy: 0.8182 - val_loss: 0.3781 - val_accuracy: 0.4054\n","Epoch 77/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2477 - accuracy: 0.4545 - val_loss: 0.3822 - val_accuracy: 0.3784\n","Epoch 78/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1735 - accuracy: 0.8182 - val_loss: 0.3853 - val_accuracy: 0.4054\n","Epoch 79/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1785 - accuracy: 0.8182 - val_loss: 0.3877 - val_accuracy: 0.4324\n","Epoch 80/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1856 - accuracy: 0.8182 - val_loss: 0.3866 - val_accuracy: 0.4054\n","Epoch 81/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1878 - accuracy: 0.7273 - val_loss: 0.3854 - val_accuracy: 0.4324\n","Epoch 82/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1863 - accuracy: 0.7273 - val_loss: 0.3911 - val_accuracy: 0.4865\n","Epoch 83/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1970 - accuracy: 0.7273 - val_loss: 0.3971 - val_accuracy: 0.5135\n","Epoch 84/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2306 - accuracy: 0.7273 - val_loss: 0.3883 - val_accuracy: 0.4595\n","Epoch 85/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1817 - accuracy: 0.7273 - val_loss: 0.3859 - val_accuracy: 0.4324\n","Epoch 86/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1814 - accuracy: 0.7273 - val_loss: 0.3867 - val_accuracy: 0.4324\n","Epoch 87/130\n","1/1 [==============================] - 2s 2s/step - loss: 0.2107 - accuracy: 0.7273 - val_loss: 0.3903 - val_accuracy: 0.4595\n","Epoch 88/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2229 - accuracy: 0.6364 - val_loss: 0.3921 - val_accuracy: 0.4324\n","Epoch 89/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2029 - accuracy: 0.6364 - val_loss: 0.3856 - val_accuracy: 0.4054\n","Epoch 90/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1888 - accuracy: 0.7273 - val_loss: 0.3803 - val_accuracy: 0.4324\n","Epoch 91/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2304 - accuracy: 0.6364 - val_loss: 0.3795 - val_accuracy: 0.4595\n","Epoch 92/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2027 - accuracy: 0.7273 - val_loss: 0.3802 - val_accuracy: 0.4595\n","Epoch 93/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2009 - accuracy: 0.7273 - val_loss: 0.3773 - val_accuracy: 0.4595\n","Epoch 94/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2841 - accuracy: 0.8182 - val_loss: 0.3716 - val_accuracy: 0.4324\n","Epoch 95/130\n","1/1 [==============================] - 2s 2s/step - loss: 0.1658 - accuracy: 0.9091 - val_loss: 0.3709 - val_accuracy: 0.4324\n","Epoch 96/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1865 - accuracy: 0.7273 - val_loss: 0.3701 - val_accuracy: 0.4324\n","Epoch 97/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1785 - accuracy: 0.7273 - val_loss: 0.3673 - val_accuracy: 0.4324\n","Epoch 98/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1637 - accuracy: 0.9091 - val_loss: 0.3632 - val_accuracy: 0.4324\n","Epoch 99/130\n","1/1 [==============================] - 2s 2s/step - loss: 0.1734 - accuracy: 0.7273 - val_loss: 0.3593 - val_accuracy: 0.4324\n","Epoch 100/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1766 - accuracy: 0.8182 - val_loss: 0.3580 - val_accuracy: 0.4595\n","Epoch 101/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2078 - accuracy: 0.7273 - val_loss: 0.3576 - val_accuracy: 0.4595\n","Epoch 102/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2079 - accuracy: 0.7273 - val_loss: 0.3573 - val_accuracy: 0.4595\n","Epoch 103/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1759 - accuracy: 0.7273 - val_loss: 0.3581 - val_accuracy: 0.4595\n","Epoch 104/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1832 - accuracy: 0.8182 - val_loss: 0.3572 - val_accuracy: 0.4595\n","Epoch 105/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1688 - accuracy: 0.8182 - val_loss: 0.3558 - val_accuracy: 0.4595\n","Epoch 106/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1924 - accuracy: 0.8182 - val_loss: 0.3534 - val_accuracy: 0.4324\n","Epoch 107/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1980 - accuracy: 0.6364 - val_loss: 0.3532 - val_accuracy: 0.4324\n","Epoch 108/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2051 - accuracy: 0.8182 - val_loss: 0.3534 - val_accuracy: 0.4324\n","Epoch 109/130\n","1/1 [==============================] - 2s 2s/step - loss: 0.2149 - accuracy: 0.6364 - val_loss: 0.3526 - val_accuracy: 0.4324\n","Epoch 110/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2201 - accuracy: 0.5455 - val_loss: 0.3504 - val_accuracy: 0.4324\n","Epoch 111/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2427 - accuracy: 0.5455 - val_loss: 0.3467 - val_accuracy: 0.4595\n","Epoch 112/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2115 - accuracy: 0.6364 - val_loss: 0.3436 - val_accuracy: 0.4324\n","Epoch 113/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2019 - accuracy: 0.6364 - val_loss: 0.3426 - val_accuracy: 0.4595\n","Epoch 114/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1788 - accuracy: 0.7273 - val_loss: 0.3456 - val_accuracy: 0.4865\n","Epoch 115/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2023 - accuracy: 0.8182 - val_loss: 0.3478 - val_accuracy: 0.5135\n","Epoch 116/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2067 - accuracy: 0.6364 - val_loss: 0.3405 - val_accuracy: 0.4865\n","Epoch 117/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2143 - accuracy: 0.5455 - val_loss: 0.3381 - val_accuracy: 0.4595\n","Epoch 118/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1611 - accuracy: 0.7273 - val_loss: 0.3371 - val_accuracy: 0.4595\n","Epoch 119/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1772 - accuracy: 0.8182 - val_loss: 0.3376 - val_accuracy: 0.4595\n","Epoch 120/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1593 - accuracy: 0.9091 - val_loss: 0.3399 - val_accuracy: 0.4865\n","Epoch 121/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1869 - accuracy: 0.7273 - val_loss: 0.3419 - val_accuracy: 0.4865\n","Epoch 122/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2254 - accuracy: 0.6364 - val_loss: 0.3412 - val_accuracy: 0.4595\n","Epoch 123/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1696 - accuracy: 0.7273 - val_loss: 0.3409 - val_accuracy: 0.4595\n","Epoch 124/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1815 - accuracy: 0.8182 - val_loss: 0.3414 - val_accuracy: 0.4595\n","Epoch 125/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1626 - accuracy: 0.7273 - val_loss: 0.3403 - val_accuracy: 0.4595\n","Epoch 126/130\n","1/1 [==============================] - 2s 2s/step - loss: 0.2564 - accuracy: 0.6364 - val_loss: 0.3377 - val_accuracy: 0.4595\n","Epoch 127/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1570 - accuracy: 0.8182 - val_loss: 0.3369 - val_accuracy: 0.4595\n","Epoch 128/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2034 - accuracy: 0.6364 - val_loss: 0.3348 - val_accuracy: 0.4595\n","Epoch 129/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2175 - accuracy: 0.7273 - val_loss: 0.3313 - val_accuracy: 0.4324\n","Epoch 130/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2444 - accuracy: 0.6364 - val_loss: 0.3258 - val_accuracy: 0.4324\n","2/2 [==============================] - 0s 106ms/step - loss: 0.3258 - accuracy: 0.4324\n","loss :  0.4324324429035187\n","total_loss :  5.486486554145813\n","num :  11\n","WARNING:tensorflow:Layer gru_55 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","WARNING:tensorflow:Layer gru_56 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","WARNING:tensorflow:Layer gru_57 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","WARNING:tensorflow:Layer gru_58 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","WARNING:tensorflow:Layer gru_59 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","Epoch 1/130\n","1/1 [==============================] - 13s 13s/step - loss: 0.3607 - accuracy: 0.6364 - val_loss: 0.5658 - val_accuracy: 0.3784\n","Epoch 2/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.3250 - accuracy: 0.6364 - val_loss: 0.5080 - val_accuracy: 0.3784\n","Epoch 3/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2866 - accuracy: 0.6364 - val_loss: 0.4442 - val_accuracy: 0.3784\n","Epoch 4/130\n","1/1 [==============================] - 2s 2s/step - loss: 0.2609 - accuracy: 0.6364 - val_loss: 0.3741 - val_accuracy: 0.3784\n","Epoch 5/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2378 - accuracy: 0.6364 - val_loss: 0.3107 - val_accuracy: 0.3784\n","Epoch 6/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2563 - accuracy: 0.6364 - val_loss: 0.2900 - val_accuracy: 0.3784\n","Epoch 7/130\n","1/1 [==============================] - 2s 2s/step - loss: 0.2493 - accuracy: 0.4545 - val_loss: 0.2968 - val_accuracy: 0.3784\n","Epoch 8/130\n","1/1 [==============================] - 2s 2s/step - loss: 0.2341 - accuracy: 0.7273 - val_loss: 0.3162 - val_accuracy: 0.3784\n","Epoch 9/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2212 - accuracy: 0.6364 - val_loss: 0.3366 - val_accuracy: 0.3784\n","Epoch 10/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2265 - accuracy: 0.6364 - val_loss: 0.3542 - val_accuracy: 0.3784\n","Epoch 11/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2142 - accuracy: 0.6364 - val_loss: 0.3650 - val_accuracy: 0.3784\n","Epoch 12/130\n","1/1 [==============================] - 2s 2s/step - loss: 0.2289 - accuracy: 0.6364 - val_loss: 0.3716 - val_accuracy: 0.3784\n","Epoch 13/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2307 - accuracy: 0.6364 - val_loss: 0.3740 - val_accuracy: 0.3784\n","Epoch 14/130\n","1/1 [==============================] - 2s 2s/step - loss: 0.2385 - accuracy: 0.6364 - val_loss: 0.3726 - val_accuracy: 0.3784\n","Epoch 15/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2304 - accuracy: 0.6364 - val_loss: 0.3679 - val_accuracy: 0.3784\n","Epoch 16/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2261 - accuracy: 0.6364 - val_loss: 0.3598 - val_accuracy: 0.3784\n","Epoch 17/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2287 - accuracy: 0.6364 - val_loss: 0.3488 - val_accuracy: 0.3784\n","Epoch 18/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2191 - accuracy: 0.6364 - val_loss: 0.3371 - val_accuracy: 0.3784\n","Epoch 19/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2060 - accuracy: 0.6364 - val_loss: 0.3256 - val_accuracy: 0.3784\n","Epoch 20/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2233 - accuracy: 0.6364 - val_loss: 0.3186 - val_accuracy: 0.3784\n","Epoch 21/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2390 - accuracy: 0.5455 - val_loss: 0.3186 - val_accuracy: 0.3784\n","Epoch 22/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2191 - accuracy: 0.6364 - val_loss: 0.3204 - val_accuracy: 0.3784\n","Epoch 23/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2213 - accuracy: 0.6364 - val_loss: 0.3270 - val_accuracy: 0.3784\n","Epoch 24/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2167 - accuracy: 0.6364 - val_loss: 0.3347 - val_accuracy: 0.3784\n","Epoch 25/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2104 - accuracy: 0.6364 - val_loss: 0.3431 - val_accuracy: 0.3784\n","Epoch 26/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2296 - accuracy: 0.6364 - val_loss: 0.3535 - val_accuracy: 0.3784\n","Epoch 27/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2413 - accuracy: 0.6364 - val_loss: 0.3643 - val_accuracy: 0.3784\n","Epoch 28/130\n","1/1 [==============================] - 2s 2s/step - loss: 0.2264 - accuracy: 0.6364 - val_loss: 0.3719 - val_accuracy: 0.3784\n","Epoch 29/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2234 - accuracy: 0.6364 - val_loss: 0.3744 - val_accuracy: 0.3784\n","Epoch 30/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2132 - accuracy: 0.6364 - val_loss: 0.3717 - val_accuracy: 0.3784\n","Epoch 31/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2187 - accuracy: 0.6364 - val_loss: 0.3668 - val_accuracy: 0.3784\n","Epoch 32/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2100 - accuracy: 0.6364 - val_loss: 0.3609 - val_accuracy: 0.3784\n","Epoch 33/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2184 - accuracy: 0.6364 - val_loss: 0.3549 - val_accuracy: 0.3784\n","Epoch 34/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2343 - accuracy: 0.5455 - val_loss: 0.3539 - val_accuracy: 0.3784\n","Epoch 35/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2303 - accuracy: 0.6364 - val_loss: 0.3560 - val_accuracy: 0.3784\n","Epoch 36/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2242 - accuracy: 0.6364 - val_loss: 0.3620 - val_accuracy: 0.3784\n","Epoch 37/130\n","1/1 [==============================] - 2s 2s/step - loss: 0.2151 - accuracy: 0.7273 - val_loss: 0.3738 - val_accuracy: 0.3784\n","Epoch 38/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2106 - accuracy: 0.6364 - val_loss: 0.3870 - val_accuracy: 0.3784\n","Epoch 39/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1999 - accuracy: 0.7273 - val_loss: 0.4008 - val_accuracy: 0.3784\n","Epoch 40/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2315 - accuracy: 0.5455 - val_loss: 0.4117 - val_accuracy: 0.3784\n","Epoch 41/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1970 - accuracy: 0.6364 - val_loss: 0.4127 - val_accuracy: 0.3784\n","Epoch 42/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2168 - accuracy: 0.6364 - val_loss: 0.4112 - val_accuracy: 0.3784\n","Epoch 43/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2300 - accuracy: 0.6364 - val_loss: 0.4038 - val_accuracy: 0.3784\n","Epoch 44/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2211 - accuracy: 0.6364 - val_loss: 0.3918 - val_accuracy: 0.3784\n","Epoch 45/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2091 - accuracy: 0.6364 - val_loss: 0.3884 - val_accuracy: 0.4054\n","Epoch 46/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2240 - accuracy: 0.6364 - val_loss: 0.3922 - val_accuracy: 0.4054\n","Epoch 47/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2159 - accuracy: 0.6364 - val_loss: 0.3986 - val_accuracy: 0.4054\n","Epoch 48/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2046 - accuracy: 0.7273 - val_loss: 0.4150 - val_accuracy: 0.3784\n","Epoch 49/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2127 - accuracy: 0.7273 - val_loss: 0.4317 - val_accuracy: 0.3784\n","Epoch 50/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2253 - accuracy: 0.5455 - val_loss: 0.4431 - val_accuracy: 0.3784\n","Epoch 51/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2287 - accuracy: 0.5455 - val_loss: 0.4475 - val_accuracy: 0.3784\n","Epoch 52/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2219 - accuracy: 0.6364 - val_loss: 0.4417 - val_accuracy: 0.3784\n","Epoch 53/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2009 - accuracy: 0.6364 - val_loss: 0.4291 - val_accuracy: 0.3784\n","Epoch 54/130\n","1/1 [==============================] - 2s 2s/step - loss: 0.2025 - accuracy: 0.5455 - val_loss: 0.4127 - val_accuracy: 0.3784\n","Epoch 55/130\n","1/1 [==============================] - 2s 2s/step - loss: 0.1916 - accuracy: 0.7273 - val_loss: 0.4000 - val_accuracy: 0.4324\n","Epoch 56/130\n","1/1 [==============================] - 2s 2s/step - loss: 0.2254 - accuracy: 0.3636 - val_loss: 0.4004 - val_accuracy: 0.4324\n","Epoch 57/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2096 - accuracy: 0.7273 - val_loss: 0.4108 - val_accuracy: 0.3784\n","Epoch 58/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1790 - accuracy: 0.8182 - val_loss: 0.4267 - val_accuracy: 0.3784\n","Epoch 59/130\n","1/1 [==============================] - 2s 2s/step - loss: 0.1921 - accuracy: 0.5455 - val_loss: 0.4498 - val_accuracy: 0.3784\n","Epoch 60/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2021 - accuracy: 0.7273 - val_loss: 0.4689 - val_accuracy: 0.3784\n","Epoch 61/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1954 - accuracy: 0.7273 - val_loss: 0.4833 - val_accuracy: 0.3784\n","Epoch 62/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2449 - accuracy: 0.5455 - val_loss: 0.4893 - val_accuracy: 0.3784\n","Epoch 63/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1803 - accuracy: 0.6364 - val_loss: 0.4832 - val_accuracy: 0.3784\n","Epoch 64/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2253 - accuracy: 0.6364 - val_loss: 0.4694 - val_accuracy: 0.3784\n","Epoch 65/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1699 - accuracy: 0.7273 - val_loss: 0.4609 - val_accuracy: 0.3784\n","Epoch 66/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2229 - accuracy: 0.5455 - val_loss: 0.4645 - val_accuracy: 0.3784\n","Epoch 67/130\n","1/1 [==============================] - 2s 2s/step - loss: 0.1993 - accuracy: 0.7273 - val_loss: 0.4657 - val_accuracy: 0.3784\n","Epoch 68/130\n","1/1 [==============================] - 2s 2s/step - loss: 0.2269 - accuracy: 0.6364 - val_loss: 0.4884 - val_accuracy: 0.3784\n","Epoch 69/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1954 - accuracy: 0.7273 - val_loss: 0.4979 - val_accuracy: 0.3784\n","Epoch 70/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1938 - accuracy: 0.7273 - val_loss: 0.5046 - val_accuracy: 0.3784\n","Epoch 71/130\n","1/1 [==============================] - 2s 2s/step - loss: 0.2428 - accuracy: 0.5455 - val_loss: 0.5062 - val_accuracy: 0.3784\n","Epoch 72/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1991 - accuracy: 0.6364 - val_loss: 0.5010 - val_accuracy: 0.3784\n","Epoch 73/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2143 - accuracy: 0.6364 - val_loss: 0.4895 - val_accuracy: 0.3784\n","Epoch 74/130\n","1/1 [==============================] - 2s 2s/step - loss: 0.1792 - accuracy: 0.7273 - val_loss: 0.4698 - val_accuracy: 0.3784\n","Epoch 75/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2017 - accuracy: 0.6364 - val_loss: 0.4587 - val_accuracy: 0.3784\n","Epoch 76/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1570 - accuracy: 0.7273 - val_loss: 0.4453 - val_accuracy: 0.4054\n","Epoch 77/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2108 - accuracy: 0.7273 - val_loss: 0.4558 - val_accuracy: 0.4054\n","Epoch 78/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2238 - accuracy: 0.5455 - val_loss: 0.4911 - val_accuracy: 0.3784\n","Epoch 79/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1507 - accuracy: 0.7273 - val_loss: 0.5196 - val_accuracy: 0.3784\n","Epoch 80/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2132 - accuracy: 0.5455 - val_loss: 0.5414 - val_accuracy: 0.3784\n","Epoch 81/130\n","1/1 [==============================] - 2s 2s/step - loss: 0.2692 - accuracy: 0.6364 - val_loss: 0.5512 - val_accuracy: 0.3784\n","Epoch 82/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2268 - accuracy: 0.7273 - val_loss: 0.5487 - val_accuracy: 0.3784\n","Epoch 83/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2357 - accuracy: 0.6364 - val_loss: 0.5360 - val_accuracy: 0.3784\n","Epoch 84/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2046 - accuracy: 0.7273 - val_loss: 0.5150 - val_accuracy: 0.3784\n","Epoch 85/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2102 - accuracy: 0.5455 - val_loss: 0.4857 - val_accuracy: 0.3784\n","Epoch 86/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2331 - accuracy: 0.5455 - val_loss: 0.4709 - val_accuracy: 0.3784\n","Epoch 87/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2097 - accuracy: 0.6364 - val_loss: 0.4644 - val_accuracy: 0.3784\n","Epoch 88/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2224 - accuracy: 0.6364 - val_loss: 0.4664 - val_accuracy: 0.3784\n","Epoch 89/130\n","1/1 [==============================] - 2s 2s/step - loss: 0.1993 - accuracy: 0.7273 - val_loss: 0.4780 - val_accuracy: 0.3784\n","Epoch 90/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1979 - accuracy: 0.7273 - val_loss: 0.4921 - val_accuracy: 0.3784\n","Epoch 91/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2054 - accuracy: 0.7273 - val_loss: 0.5028 - val_accuracy: 0.3784\n","Epoch 92/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2370 - accuracy: 0.6364 - val_loss: 0.5071 - val_accuracy: 0.3784\n","Epoch 93/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2083 - accuracy: 0.4545 - val_loss: 0.5069 - val_accuracy: 0.3784\n","Epoch 94/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2539 - accuracy: 0.5455 - val_loss: 0.5035 - val_accuracy: 0.3784\n","Epoch 95/130\n","1/1 [==============================] - 2s 2s/step - loss: 0.2318 - accuracy: 0.6364 - val_loss: 0.4974 - val_accuracy: 0.3784\n","Epoch 96/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2090 - accuracy: 0.5455 - val_loss: 0.4946 - val_accuracy: 0.3784\n","Epoch 97/130\n","1/1 [==============================] - 2s 2s/step - loss: 0.2294 - accuracy: 0.5455 - val_loss: 0.4944 - val_accuracy: 0.3784\n","Epoch 98/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2303 - accuracy: 0.5455 - val_loss: 0.4939 - val_accuracy: 0.3784\n","Epoch 99/130\n","1/1 [==============================] - 2s 2s/step - loss: 0.2090 - accuracy: 0.6364 - val_loss: 0.4916 - val_accuracy: 0.3784\n","Epoch 100/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1801 - accuracy: 0.7273 - val_loss: 0.4872 - val_accuracy: 0.3784\n","Epoch 101/130\n","1/1 [==============================] - 2s 2s/step - loss: 0.2231 - accuracy: 0.6364 - val_loss: 0.4836 - val_accuracy: 0.3784\n","Epoch 102/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2058 - accuracy: 0.7273 - val_loss: 0.4816 - val_accuracy: 0.3784\n","Epoch 103/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2085 - accuracy: 0.6364 - val_loss: 0.4870 - val_accuracy: 0.3784\n","Epoch 104/130\n","1/1 [==============================] - 2s 2s/step - loss: 0.1969 - accuracy: 0.6364 - val_loss: 0.4976 - val_accuracy: 0.3784\n","Epoch 105/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2424 - accuracy: 0.5455 - val_loss: 0.5187 - val_accuracy: 0.3784\n","Epoch 106/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2629 - accuracy: 0.6364 - val_loss: 0.5365 - val_accuracy: 0.3784\n","Epoch 107/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2017 - accuracy: 0.6364 - val_loss: 0.5386 - val_accuracy: 0.3784\n","Epoch 108/130\n","1/1 [==============================] - 2s 2s/step - loss: 0.2108 - accuracy: 0.6364 - val_loss: 0.5335 - val_accuracy: 0.3784\n","Epoch 109/130\n","1/1 [==============================] - 2s 2s/step - loss: 0.2363 - accuracy: 0.6364 - val_loss: 0.5141 - val_accuracy: 0.3784\n","Epoch 110/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2315 - accuracy: 0.5455 - val_loss: 0.4912 - val_accuracy: 0.3784\n","Epoch 111/130\n","1/1 [==============================] - 2s 2s/step - loss: 0.2144 - accuracy: 0.6364 - val_loss: 0.4719 - val_accuracy: 0.3784\n","Epoch 112/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2312 - accuracy: 0.5455 - val_loss: 0.4595 - val_accuracy: 0.3784\n","Epoch 113/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2200 - accuracy: 0.6364 - val_loss: 0.4565 - val_accuracy: 0.3784\n","Epoch 114/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2344 - accuracy: 0.5455 - val_loss: 0.4697 - val_accuracy: 0.3784\n","Epoch 115/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2193 - accuracy: 0.6364 - val_loss: 0.4827 - val_accuracy: 0.3784\n","Epoch 116/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1924 - accuracy: 0.5455 - val_loss: 0.4994 - val_accuracy: 0.3784\n","Epoch 117/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2034 - accuracy: 0.6364 - val_loss: 0.5168 - val_accuracy: 0.3784\n","Epoch 118/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2217 - accuracy: 0.6364 - val_loss: 0.5259 - val_accuracy: 0.3784\n","Epoch 119/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2202 - accuracy: 0.6364 - val_loss: 0.5183 - val_accuracy: 0.3784\n","Epoch 120/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2020 - accuracy: 0.6364 - val_loss: 0.5075 - val_accuracy: 0.3784\n","Epoch 121/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1909 - accuracy: 0.7273 - val_loss: 0.4889 - val_accuracy: 0.3784\n","Epoch 122/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2193 - accuracy: 0.6364 - val_loss: 0.4700 - val_accuracy: 0.3784\n","Epoch 123/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1905 - accuracy: 0.7273 - val_loss: 0.4595 - val_accuracy: 0.3784\n","Epoch 124/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2124 - accuracy: 0.6364 - val_loss: 0.4589 - val_accuracy: 0.3784\n","Epoch 125/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2133 - accuracy: 0.5455 - val_loss: 0.4809 - val_accuracy: 0.3784\n","Epoch 126/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2017 - accuracy: 0.5455 - val_loss: 0.5129 - val_accuracy: 0.3784\n","Epoch 127/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2511 - accuracy: 0.5455 - val_loss: 0.5196 - val_accuracy: 0.3784\n","Epoch 128/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1608 - accuracy: 0.7273 - val_loss: 0.5154 - val_accuracy: 0.3784\n","Epoch 129/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1803 - accuracy: 0.6364 - val_loss: 0.5075 - val_accuracy: 0.3784\n","Epoch 130/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1884 - accuracy: 0.8182 - val_loss: 0.4976 - val_accuracy: 0.3784\n","2/2 [==============================] - 0s 108ms/step - loss: 0.4976 - accuracy: 0.3784\n","loss :  0.37837839126586914\n","total_loss :  5.864864945411682\n","num :  12\n","WARNING:tensorflow:Layer gru_60 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","WARNING:tensorflow:Layer gru_61 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","WARNING:tensorflow:Layer gru_62 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","WARNING:tensorflow:Layer gru_63 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","WARNING:tensorflow:Layer gru_64 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","Epoch 1/130\n","1/1 [==============================] - 12s 12s/step - loss: 0.6113 - accuracy: 0.3636 - val_loss: 0.4588 - val_accuracy: 0.4865\n","Epoch 2/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.5522 - accuracy: 0.3636 - val_loss: 0.4160 - val_accuracy: 0.4865\n","Epoch 3/130\n","1/1 [==============================] - 2s 2s/step - loss: 0.4872 - accuracy: 0.3636 - val_loss: 0.3652 - val_accuracy: 0.4865\n","Epoch 4/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.3956 - accuracy: 0.3636 - val_loss: 0.3106 - val_accuracy: 0.4865\n","Epoch 5/130\n","1/1 [==============================] - 2s 2s/step - loss: 0.3125 - accuracy: 0.3636 - val_loss: 0.2651 - val_accuracy: 0.4865\n","Epoch 6/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2446 - accuracy: 0.5455 - val_loss: 0.2597 - val_accuracy: 0.5135\n","Epoch 7/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2295 - accuracy: 0.6364 - val_loss: 0.3072 - val_accuracy: 0.5135\n","Epoch 8/130\n","1/1 [==============================] - 2s 2s/step - loss: 0.2799 - accuracy: 0.6364 - val_loss: 0.3083 - val_accuracy: 0.5135\n","Epoch 9/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.3112 - accuracy: 0.6364 - val_loss: 0.2784 - val_accuracy: 0.5135\n","Epoch 10/130\n","1/1 [==============================] - 2s 2s/step - loss: 0.2854 - accuracy: 0.6364 - val_loss: 0.2584 - val_accuracy: 0.5135\n","Epoch 11/130\n","1/1 [==============================] - 2s 2s/step - loss: 0.2276 - accuracy: 0.6364 - val_loss: 0.2534 - val_accuracy: 0.4324\n","Epoch 12/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2486 - accuracy: 0.6364 - val_loss: 0.2565 - val_accuracy: 0.4865\n","Epoch 13/130\n","1/1 [==============================] - 2s 2s/step - loss: 0.2225 - accuracy: 0.6364 - val_loss: 0.2616 - val_accuracy: 0.4865\n","Epoch 14/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2622 - accuracy: 0.4545 - val_loss: 0.2659 - val_accuracy: 0.4865\n","Epoch 15/130\n","1/1 [==============================] - 2s 2s/step - loss: 0.2551 - accuracy: 0.4545 - val_loss: 0.2680 - val_accuracy: 0.4865\n","Epoch 16/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2528 - accuracy: 0.4545 - val_loss: 0.2675 - val_accuracy: 0.4865\n","Epoch 17/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2328 - accuracy: 0.8182 - val_loss: 0.2649 - val_accuracy: 0.4865\n","Epoch 18/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2469 - accuracy: 0.5455 - val_loss: 0.2608 - val_accuracy: 0.4865\n","Epoch 19/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2317 - accuracy: 0.7273 - val_loss: 0.2568 - val_accuracy: 0.4865\n","Epoch 20/130\n","1/1 [==============================] - 2s 2s/step - loss: 0.2607 - accuracy: 0.5455 - val_loss: 0.2545 - val_accuracy: 0.4865\n","Epoch 21/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2440 - accuracy: 0.6364 - val_loss: 0.2545 - val_accuracy: 0.4324\n","Epoch 22/130\n","1/1 [==============================] - 2s 2s/step - loss: 0.2265 - accuracy: 0.6364 - val_loss: 0.2565 - val_accuracy: 0.5135\n","Epoch 23/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2476 - accuracy: 0.6364 - val_loss: 0.2586 - val_accuracy: 0.5135\n","Epoch 24/130\n","1/1 [==============================] - 2s 2s/step - loss: 0.2021 - accuracy: 0.6364 - val_loss: 0.2600 - val_accuracy: 0.5135\n","Epoch 25/130\n","1/1 [==============================] - 2s 2s/step - loss: 0.2558 - accuracy: 0.6364 - val_loss: 0.2592 - val_accuracy: 0.5135\n","Epoch 26/130\n","1/1 [==============================] - 2s 2s/step - loss: 0.2479 - accuracy: 0.6364 - val_loss: 0.2572 - val_accuracy: 0.5135\n","Epoch 27/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2316 - accuracy: 0.6364 - val_loss: 0.2554 - val_accuracy: 0.4865\n","Epoch 28/130\n","1/1 [==============================] - 2s 2s/step - loss: 0.2197 - accuracy: 0.6364 - val_loss: 0.2547 - val_accuracy: 0.4324\n","Epoch 29/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2171 - accuracy: 0.6364 - val_loss: 0.2546 - val_accuracy: 0.4324\n","Epoch 30/130\n","1/1 [==============================] - 2s 2s/step - loss: 0.2354 - accuracy: 0.6364 - val_loss: 0.2550 - val_accuracy: 0.4595\n","Epoch 31/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2373 - accuracy: 0.6364 - val_loss: 0.2557 - val_accuracy: 0.4865\n","Epoch 32/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2076 - accuracy: 0.6364 - val_loss: 0.2562 - val_accuracy: 0.4595\n","Epoch 33/130\n","1/1 [==============================] - 2s 2s/step - loss: 0.2404 - accuracy: 0.6364 - val_loss: 0.2566 - val_accuracy: 0.4324\n","Epoch 34/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2415 - accuracy: 0.6364 - val_loss: 0.2566 - val_accuracy: 0.4324\n","Epoch 35/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2299 - accuracy: 0.6364 - val_loss: 0.2564 - val_accuracy: 0.4865\n","Epoch 36/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2388 - accuracy: 0.6364 - val_loss: 0.2561 - val_accuracy: 0.4324\n","Epoch 37/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2303 - accuracy: 0.6364 - val_loss: 0.2560 - val_accuracy: 0.4595\n","Epoch 38/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2241 - accuracy: 0.6364 - val_loss: 0.2560 - val_accuracy: 0.4324\n","Epoch 39/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2209 - accuracy: 0.6364 - val_loss: 0.2561 - val_accuracy: 0.4324\n","Epoch 40/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2315 - accuracy: 0.6364 - val_loss: 0.2563 - val_accuracy: 0.4595\n","Epoch 41/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2192 - accuracy: 0.6364 - val_loss: 0.2564 - val_accuracy: 0.4324\n","Epoch 42/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2141 - accuracy: 0.6364 - val_loss: 0.2567 - val_accuracy: 0.4324\n","Epoch 43/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2299 - accuracy: 0.6364 - val_loss: 0.2570 - val_accuracy: 0.4865\n","Epoch 44/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2200 - accuracy: 0.6364 - val_loss: 0.2573 - val_accuracy: 0.4595\n","Epoch 45/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2092 - accuracy: 0.6364 - val_loss: 0.2578 - val_accuracy: 0.4324\n","Epoch 46/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2299 - accuracy: 0.6364 - val_loss: 0.2583 - val_accuracy: 0.4595\n","Epoch 47/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2415 - accuracy: 0.6364 - val_loss: 0.2589 - val_accuracy: 0.4324\n","Epoch 48/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2124 - accuracy: 0.6364 - val_loss: 0.2593 - val_accuracy: 0.4324\n","Epoch 49/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2237 - accuracy: 0.6364 - val_loss: 0.2593 - val_accuracy: 0.4324\n","Epoch 50/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2217 - accuracy: 0.6364 - val_loss: 0.2593 - val_accuracy: 0.4595\n","Epoch 51/130\n","1/1 [==============================] - 2s 2s/step - loss: 0.2086 - accuracy: 0.6364 - val_loss: 0.2593 - val_accuracy: 0.4595\n","Epoch 52/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2256 - accuracy: 0.6364 - val_loss: 0.2595 - val_accuracy: 0.4595\n","Epoch 53/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2169 - accuracy: 0.6364 - val_loss: 0.2598 - val_accuracy: 0.4595\n","Epoch 54/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2144 - accuracy: 0.6364 - val_loss: 0.2603 - val_accuracy: 0.4595\n","Epoch 55/130\n","1/1 [==============================] - 2s 2s/step - loss: 0.2246 - accuracy: 0.6364 - val_loss: 0.2610 - val_accuracy: 0.4324\n","Epoch 56/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2325 - accuracy: 0.6364 - val_loss: 0.2620 - val_accuracy: 0.4324\n","Epoch 57/130\n","1/1 [==============================] - 2s 2s/step - loss: 0.2117 - accuracy: 0.6364 - val_loss: 0.2629 - val_accuracy: 0.4865\n","Epoch 58/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2275 - accuracy: 0.6364 - val_loss: 0.2638 - val_accuracy: 0.4865\n","Epoch 59/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2048 - accuracy: 0.5455 - val_loss: 0.2641 - val_accuracy: 0.4865\n","Epoch 60/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2460 - accuracy: 0.5455 - val_loss: 0.2642 - val_accuracy: 0.4595\n","Epoch 61/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2176 - accuracy: 0.6364 - val_loss: 0.2639 - val_accuracy: 0.4324\n","Epoch 62/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2209 - accuracy: 0.6364 - val_loss: 0.2636 - val_accuracy: 0.4324\n","Epoch 63/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2324 - accuracy: 0.6364 - val_loss: 0.2635 - val_accuracy: 0.4324\n","Epoch 64/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2280 - accuracy: 0.6364 - val_loss: 0.2634 - val_accuracy: 0.4865\n","Epoch 65/130\n","1/1 [==============================] - 2s 2s/step - loss: 0.2755 - accuracy: 0.6364 - val_loss: 0.2644 - val_accuracy: 0.4054\n","Epoch 66/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2260 - accuracy: 0.6364 - val_loss: 0.2659 - val_accuracy: 0.4324\n","Epoch 67/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2187 - accuracy: 0.6364 - val_loss: 0.2674 - val_accuracy: 0.4595\n","Epoch 68/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2331 - accuracy: 0.6364 - val_loss: 0.2691 - val_accuracy: 0.4595\n","Epoch 69/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2319 - accuracy: 0.6364 - val_loss: 0.2705 - val_accuracy: 0.4865\n","Epoch 70/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2336 - accuracy: 0.6364 - val_loss: 0.2719 - val_accuracy: 0.4865\n","Epoch 71/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2354 - accuracy: 0.6364 - val_loss: 0.2727 - val_accuracy: 0.4865\n","Epoch 72/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2446 - accuracy: 0.6364 - val_loss: 0.2728 - val_accuracy: 0.4865\n","Epoch 73/130\n","1/1 [==============================] - 2s 2s/step - loss: 0.2331 - accuracy: 0.6364 - val_loss: 0.2731 - val_accuracy: 0.4865\n","Epoch 74/130\n","1/1 [==============================] - 2s 2s/step - loss: 0.2284 - accuracy: 0.6364 - val_loss: 0.2731 - val_accuracy: 0.4865\n","Epoch 75/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2345 - accuracy: 0.6364 - val_loss: 0.2736 - val_accuracy: 0.4865\n","Epoch 76/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2296 - accuracy: 0.6364 - val_loss: 0.2745 - val_accuracy: 0.4865\n","Epoch 77/130\n","1/1 [==============================] - 2s 2s/step - loss: 0.2272 - accuracy: 0.6364 - val_loss: 0.2755 - val_accuracy: 0.4865\n","Epoch 78/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2216 - accuracy: 0.6364 - val_loss: 0.2762 - val_accuracy: 0.4865\n","Epoch 79/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2197 - accuracy: 0.6364 - val_loss: 0.2761 - val_accuracy: 0.4595\n","Epoch 80/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2186 - accuracy: 0.6364 - val_loss: 0.2764 - val_accuracy: 0.4595\n","Epoch 81/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2028 - accuracy: 0.6364 - val_loss: 0.2768 - val_accuracy: 0.4595\n","Epoch 82/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2123 - accuracy: 0.6364 - val_loss: 0.2777 - val_accuracy: 0.4595\n","Epoch 83/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2135 - accuracy: 0.6364 - val_loss: 0.2791 - val_accuracy: 0.4595\n","Epoch 84/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2031 - accuracy: 0.6364 - val_loss: 0.2807 - val_accuracy: 0.4595\n","Epoch 85/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2329 - accuracy: 0.6364 - val_loss: 0.2821 - val_accuracy: 0.4595\n","Epoch 86/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2098 - accuracy: 0.6364 - val_loss: 0.2832 - val_accuracy: 0.4595\n","Epoch 87/130\n","1/1 [==============================] - 2s 2s/step - loss: 0.2046 - accuracy: 0.6364 - val_loss: 0.2855 - val_accuracy: 0.4865\n","Epoch 88/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2148 - accuracy: 0.6364 - val_loss: 0.2885 - val_accuracy: 0.4865\n","Epoch 89/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2163 - accuracy: 0.6364 - val_loss: 0.2916 - val_accuracy: 0.4865\n","Epoch 90/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2052 - accuracy: 0.6364 - val_loss: 0.2946 - val_accuracy: 0.4865\n","Epoch 91/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2130 - accuracy: 0.7273 - val_loss: 0.2951 - val_accuracy: 0.4865\n","Epoch 92/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2197 - accuracy: 0.6364 - val_loss: 0.2948 - val_accuracy: 0.4865\n","Epoch 93/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2148 - accuracy: 0.6364 - val_loss: 0.2952 - val_accuracy: 0.4865\n","Epoch 94/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1999 - accuracy: 0.7273 - val_loss: 0.2968 - val_accuracy: 0.4865\n","Epoch 95/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2154 - accuracy: 0.6364 - val_loss: 0.3011 - val_accuracy: 0.4865\n","Epoch 96/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2169 - accuracy: 0.7273 - val_loss: 0.3049 - val_accuracy: 0.4865\n","Epoch 97/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2124 - accuracy: 0.6364 - val_loss: 0.3092 - val_accuracy: 0.4865\n","Epoch 98/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2023 - accuracy: 0.6364 - val_loss: 0.3104 - val_accuracy: 0.4865\n","Epoch 99/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2328 - accuracy: 0.7273 - val_loss: 0.3110 - val_accuracy: 0.4865\n","Epoch 100/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2112 - accuracy: 0.7273 - val_loss: 0.3097 - val_accuracy: 0.4865\n","Epoch 101/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2462 - accuracy: 0.5455 - val_loss: 0.3109 - val_accuracy: 0.4865\n","Epoch 102/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2084 - accuracy: 0.6364 - val_loss: 0.3130 - val_accuracy: 0.4595\n","Epoch 103/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1896 - accuracy: 0.7273 - val_loss: 0.3170 - val_accuracy: 0.4865\n","Epoch 104/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2284 - accuracy: 0.7273 - val_loss: 0.3183 - val_accuracy: 0.4595\n","Epoch 105/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2117 - accuracy: 0.6364 - val_loss: 0.3212 - val_accuracy: 0.4595\n","Epoch 106/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2263 - accuracy: 0.6364 - val_loss: 0.3274 - val_accuracy: 0.4865\n","Epoch 107/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2143 - accuracy: 0.5455 - val_loss: 0.3349 - val_accuracy: 0.4865\n","Epoch 108/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2081 - accuracy: 0.6364 - val_loss: 0.3414 - val_accuracy: 0.4865\n","Epoch 109/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1916 - accuracy: 0.6364 - val_loss: 0.3407 - val_accuracy: 0.4865\n","Epoch 110/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2261 - accuracy: 0.6364 - val_loss: 0.3361 - val_accuracy: 0.4595\n","Epoch 111/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1758 - accuracy: 0.7273 - val_loss: 0.3348 - val_accuracy: 0.4595\n","Epoch 112/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1798 - accuracy: 0.6364 - val_loss: 0.3424 - val_accuracy: 0.4595\n","Epoch 113/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1693 - accuracy: 0.8182 - val_loss: 0.3490 - val_accuracy: 0.4595\n","Epoch 114/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2024 - accuracy: 0.7273 - val_loss: 0.3548 - val_accuracy: 0.4595\n","Epoch 115/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2001 - accuracy: 0.6364 - val_loss: 0.3608 - val_accuracy: 0.4595\n","Epoch 116/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1749 - accuracy: 0.8182 - val_loss: 0.3618 - val_accuracy: 0.4595\n","Epoch 117/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1818 - accuracy: 0.7273 - val_loss: 0.3616 - val_accuracy: 0.4595\n","Epoch 118/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2007 - accuracy: 0.5455 - val_loss: 0.3723 - val_accuracy: 0.4595\n","Epoch 119/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2304 - accuracy: 0.7273 - val_loss: 0.3861 - val_accuracy: 0.4865\n","Epoch 120/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2034 - accuracy: 0.5455 - val_loss: 0.3895 - val_accuracy: 0.4865\n","Epoch 121/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2062 - accuracy: 0.6364 - val_loss: 0.3817 - val_accuracy: 0.4595\n","Epoch 122/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1782 - accuracy: 0.7273 - val_loss: 0.3663 - val_accuracy: 0.4865\n","Epoch 123/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2251 - accuracy: 0.6364 - val_loss: 0.3643 - val_accuracy: 0.4865\n","Epoch 124/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1722 - accuracy: 0.6364 - val_loss: 0.3699 - val_accuracy: 0.4865\n","Epoch 125/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1944 - accuracy: 0.6364 - val_loss: 0.3791 - val_accuracy: 0.4595\n","Epoch 126/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1818 - accuracy: 0.8182 - val_loss: 0.3826 - val_accuracy: 0.4595\n","Epoch 127/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1836 - accuracy: 0.5455 - val_loss: 0.3837 - val_accuracy: 0.4595\n","Epoch 128/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1947 - accuracy: 0.7273 - val_loss: 0.3805 - val_accuracy: 0.4595\n","Epoch 129/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2087 - accuracy: 0.6364 - val_loss: 0.3758 - val_accuracy: 0.4865\n","Epoch 130/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2037 - accuracy: 0.6364 - val_loss: 0.3743 - val_accuracy: 0.4865\n","2/2 [==============================] - 0s 100ms/step - loss: 0.3743 - accuracy: 0.4865\n","loss :  0.4864864945411682\n","total_loss :  6.35135143995285\n","num :  13\n","WARNING:tensorflow:Layer gru_65 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","WARNING:tensorflow:Layer gru_66 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","WARNING:tensorflow:Layer gru_67 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","WARNING:tensorflow:Layer gru_68 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","WARNING:tensorflow:Layer gru_69 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","Epoch 1/130\n","1/1 [==============================] - 12s 12s/step - loss: 0.7425 - accuracy: 0.2727 - val_loss: 0.5051 - val_accuracy: 0.4595\n","Epoch 2/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.6682 - accuracy: 0.2727 - val_loss: 0.4667 - val_accuracy: 0.4595\n","Epoch 3/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.6032 - accuracy: 0.2727 - val_loss: 0.4231 - val_accuracy: 0.4595\n","Epoch 4/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.5337 - accuracy: 0.2727 - val_loss: 0.3699 - val_accuracy: 0.4595\n","Epoch 5/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.4523 - accuracy: 0.2727 - val_loss: 0.3117 - val_accuracy: 0.4595\n","Epoch 6/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.3151 - accuracy: 0.2727 - val_loss: 0.2639 - val_accuracy: 0.4595\n","Epoch 7/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2299 - accuracy: 0.7273 - val_loss: 0.2659 - val_accuracy: 0.5405\n","Epoch 8/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2094 - accuracy: 0.7273 - val_loss: 0.3471 - val_accuracy: 0.5405\n","Epoch 9/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.3212 - accuracy: 0.7273 - val_loss: 0.3398 - val_accuracy: 0.5405\n","Epoch 10/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2918 - accuracy: 0.7273 - val_loss: 0.2985 - val_accuracy: 0.5405\n","Epoch 11/130\n","1/1 [==============================] - 2s 2s/step - loss: 0.2429 - accuracy: 0.7273 - val_loss: 0.2678 - val_accuracy: 0.5405\n","Epoch 12/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1972 - accuracy: 0.7273 - val_loss: 0.2560 - val_accuracy: 0.5405\n","Epoch 13/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2156 - accuracy: 0.7273 - val_loss: 0.2554 - val_accuracy: 0.3784\n","Epoch 14/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2257 - accuracy: 0.7273 - val_loss: 0.2584 - val_accuracy: 0.4595\n","Epoch 15/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2320 - accuracy: 0.7273 - val_loss: 0.2610 - val_accuracy: 0.4595\n","Epoch 16/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2458 - accuracy: 0.6364 - val_loss: 0.2611 - val_accuracy: 0.4595\n","Epoch 17/130\n","1/1 [==============================] - 2s 2s/step - loss: 0.2296 - accuracy: 0.8182 - val_loss: 0.2593 - val_accuracy: 0.4595\n","Epoch 18/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2194 - accuracy: 0.8182 - val_loss: 0.2563 - val_accuracy: 0.4595\n","Epoch 19/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2190 - accuracy: 0.7273 - val_loss: 0.2538 - val_accuracy: 0.4324\n","Epoch 20/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2050 - accuracy: 0.7273 - val_loss: 0.2533 - val_accuracy: 0.5405\n","Epoch 21/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2013 - accuracy: 0.7273 - val_loss: 0.2557 - val_accuracy: 0.5405\n","Epoch 22/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1876 - accuracy: 0.7273 - val_loss: 0.2619 - val_accuracy: 0.5405\n","Epoch 23/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2025 - accuracy: 0.7273 - val_loss: 0.2704 - val_accuracy: 0.5405\n","Epoch 24/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2102 - accuracy: 0.7273 - val_loss: 0.2777 - val_accuracy: 0.5405\n","Epoch 25/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1922 - accuracy: 0.7273 - val_loss: 0.2812 - val_accuracy: 0.5405\n","Epoch 26/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2057 - accuracy: 0.7273 - val_loss: 0.2789 - val_accuracy: 0.5405\n","Epoch 27/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1978 - accuracy: 0.7273 - val_loss: 0.2730 - val_accuracy: 0.5405\n","Epoch 28/130\n","1/1 [==============================] - 2s 2s/step - loss: 0.2054 - accuracy: 0.7273 - val_loss: 0.2654 - val_accuracy: 0.5405\n","Epoch 29/130\n","1/1 [==============================] - 2s 2s/step - loss: 0.2095 - accuracy: 0.7273 - val_loss: 0.2594 - val_accuracy: 0.5405\n","Epoch 30/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1984 - accuracy: 0.7273 - val_loss: 0.2555 - val_accuracy: 0.5405\n","Epoch 31/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2318 - accuracy: 0.7273 - val_loss: 0.2533 - val_accuracy: 0.5405\n","Epoch 32/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1895 - accuracy: 0.7273 - val_loss: 0.2525 - val_accuracy: 0.5405\n","Epoch 33/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2202 - accuracy: 0.7273 - val_loss: 0.2523 - val_accuracy: 0.5405\n","Epoch 34/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2103 - accuracy: 0.7273 - val_loss: 0.2523 - val_accuracy: 0.5405\n","Epoch 35/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2092 - accuracy: 0.7273 - val_loss: 0.2524 - val_accuracy: 0.5405\n","Epoch 36/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1969 - accuracy: 0.7273 - val_loss: 0.2528 - val_accuracy: 0.5405\n","Epoch 37/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2224 - accuracy: 0.7273 - val_loss: 0.2537 - val_accuracy: 0.5405\n","Epoch 38/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2125 - accuracy: 0.7273 - val_loss: 0.2553 - val_accuracy: 0.5405\n","Epoch 39/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1980 - accuracy: 0.7273 - val_loss: 0.2571 - val_accuracy: 0.5405\n","Epoch 40/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1771 - accuracy: 0.7273 - val_loss: 0.2596 - val_accuracy: 0.5405\n","Epoch 41/130\n","1/1 [==============================] - 2s 2s/step - loss: 0.1985 - accuracy: 0.7273 - val_loss: 0.2625 - val_accuracy: 0.5405\n","Epoch 42/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1917 - accuracy: 0.7273 - val_loss: 0.2647 - val_accuracy: 0.5405\n","Epoch 43/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2202 - accuracy: 0.7273 - val_loss: 0.2649 - val_accuracy: 0.5405\n","Epoch 44/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2402 - accuracy: 0.7273 - val_loss: 0.2629 - val_accuracy: 0.5405\n","Epoch 45/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1911 - accuracy: 0.7273 - val_loss: 0.2605 - val_accuracy: 0.5405\n","Epoch 46/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2093 - accuracy: 0.7273 - val_loss: 0.2576 - val_accuracy: 0.5405\n","Epoch 47/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2099 - accuracy: 0.7273 - val_loss: 0.2555 - val_accuracy: 0.5405\n","Epoch 48/130\n","1/1 [==============================] - 2s 2s/step - loss: 0.2240 - accuracy: 0.7273 - val_loss: 0.2538 - val_accuracy: 0.5405\n","Epoch 49/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1923 - accuracy: 0.7273 - val_loss: 0.2531 - val_accuracy: 0.5405\n","Epoch 50/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1849 - accuracy: 0.7273 - val_loss: 0.2530 - val_accuracy: 0.5405\n","Epoch 51/130\n","1/1 [==============================] - 2s 2s/step - loss: 0.1989 - accuracy: 0.7273 - val_loss: 0.2531 - val_accuracy: 0.5405\n","Epoch 52/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2029 - accuracy: 0.7273 - val_loss: 0.2536 - val_accuracy: 0.5405\n","Epoch 53/130\n","1/1 [==============================] - 2s 2s/step - loss: 0.2096 - accuracy: 0.7273 - val_loss: 0.2545 - val_accuracy: 0.5405\n","Epoch 54/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2053 - accuracy: 0.7273 - val_loss: 0.2557 - val_accuracy: 0.5405\n","Epoch 55/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1901 - accuracy: 0.7273 - val_loss: 0.2577 - val_accuracy: 0.5405\n","Epoch 56/130\n","1/1 [==============================] - 2s 2s/step - loss: 0.2068 - accuracy: 0.7273 - val_loss: 0.2594 - val_accuracy: 0.5405\n","Epoch 57/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1924 - accuracy: 0.7273 - val_loss: 0.2608 - val_accuracy: 0.5405\n","Epoch 58/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1966 - accuracy: 0.7273 - val_loss: 0.2613 - val_accuracy: 0.5405\n","Epoch 59/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2110 - accuracy: 0.7273 - val_loss: 0.2606 - val_accuracy: 0.5405\n","Epoch 60/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2118 - accuracy: 0.7273 - val_loss: 0.2591 - val_accuracy: 0.5405\n","Epoch 61/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1978 - accuracy: 0.7273 - val_loss: 0.2578 - val_accuracy: 0.5405\n","Epoch 62/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1927 - accuracy: 0.7273 - val_loss: 0.2565 - val_accuracy: 0.5405\n","Epoch 63/130\n","1/1 [==============================] - 2s 2s/step - loss: 0.2145 - accuracy: 0.7273 - val_loss: 0.2555 - val_accuracy: 0.5405\n","Epoch 64/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2132 - accuracy: 0.7273 - val_loss: 0.2550 - val_accuracy: 0.5405\n","Epoch 65/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1933 - accuracy: 0.7273 - val_loss: 0.2550 - val_accuracy: 0.5405\n","Epoch 66/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2080 - accuracy: 0.7273 - val_loss: 0.2551 - val_accuracy: 0.5405\n","Epoch 67/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1993 - accuracy: 0.7273 - val_loss: 0.2555 - val_accuracy: 0.5405\n","Epoch 68/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1916 - accuracy: 0.7273 - val_loss: 0.2562 - val_accuracy: 0.5405\n","Epoch 69/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2206 - accuracy: 0.7273 - val_loss: 0.2570 - val_accuracy: 0.5405\n","Epoch 70/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1945 - accuracy: 0.7273 - val_loss: 0.2578 - val_accuracy: 0.5405\n","Epoch 71/130\n","1/1 [==============================] - 2s 2s/step - loss: 0.2032 - accuracy: 0.7273 - val_loss: 0.2580 - val_accuracy: 0.5405\n","Epoch 72/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1824 - accuracy: 0.7273 - val_loss: 0.2583 - val_accuracy: 0.5405\n","Epoch 73/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1786 - accuracy: 0.7273 - val_loss: 0.2591 - val_accuracy: 0.5405\n","Epoch 74/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1918 - accuracy: 0.7273 - val_loss: 0.2598 - val_accuracy: 0.5405\n","Epoch 75/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1968 - accuracy: 0.7273 - val_loss: 0.2592 - val_accuracy: 0.5405\n","Epoch 76/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2030 - accuracy: 0.7273 - val_loss: 0.2582 - val_accuracy: 0.5405\n","Epoch 77/130\n","1/1 [==============================] - 2s 2s/step - loss: 0.2140 - accuracy: 0.7273 - val_loss: 0.2569 - val_accuracy: 0.5405\n","Epoch 78/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2095 - accuracy: 0.7273 - val_loss: 0.2559 - val_accuracy: 0.5405\n","Epoch 79/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2061 - accuracy: 0.7273 - val_loss: 0.2554 - val_accuracy: 0.5405\n","Epoch 80/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2111 - accuracy: 0.7273 - val_loss: 0.2553 - val_accuracy: 0.5405\n","Epoch 81/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1850 - accuracy: 0.7273 - val_loss: 0.2556 - val_accuracy: 0.5405\n","Epoch 82/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2042 - accuracy: 0.7273 - val_loss: 0.2564 - val_accuracy: 0.5405\n","Epoch 83/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2078 - accuracy: 0.7273 - val_loss: 0.2573 - val_accuracy: 0.5405\n","Epoch 84/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2047 - accuracy: 0.7273 - val_loss: 0.2583 - val_accuracy: 0.5405\n","Epoch 85/130\n","1/1 [==============================] - 2s 2s/step - loss: 0.1963 - accuracy: 0.7273 - val_loss: 0.2596 - val_accuracy: 0.5405\n","Epoch 86/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2054 - accuracy: 0.7273 - val_loss: 0.2607 - val_accuracy: 0.5405\n","Epoch 87/130\n","1/1 [==============================] - 2s 2s/step - loss: 0.2061 - accuracy: 0.7273 - val_loss: 0.2616 - val_accuracy: 0.5405\n","Epoch 88/130\n","1/1 [==============================] - 2s 2s/step - loss: 0.1994 - accuracy: 0.7273 - val_loss: 0.2616 - val_accuracy: 0.5405\n","Epoch 89/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2066 - accuracy: 0.7273 - val_loss: 0.2607 - val_accuracy: 0.5405\n","Epoch 90/130\n","1/1 [==============================] - 2s 2s/step - loss: 0.2046 - accuracy: 0.7273 - val_loss: 0.2594 - val_accuracy: 0.5405\n","Epoch 91/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1994 - accuracy: 0.7273 - val_loss: 0.2582 - val_accuracy: 0.5405\n","Epoch 92/130\n","1/1 [==============================] - 2s 2s/step - loss: 0.2068 - accuracy: 0.7273 - val_loss: 0.2572 - val_accuracy: 0.5405\n","Epoch 93/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2052 - accuracy: 0.7273 - val_loss: 0.2565 - val_accuracy: 0.5405\n","Epoch 94/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1952 - accuracy: 0.7273 - val_loss: 0.2564 - val_accuracy: 0.5405\n","Epoch 95/130\n","1/1 [==============================] - 2s 2s/step - loss: 0.1849 - accuracy: 0.7273 - val_loss: 0.2567 - val_accuracy: 0.5405\n","Epoch 96/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1861 - accuracy: 0.7273 - val_loss: 0.2577 - val_accuracy: 0.5405\n","Epoch 97/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2003 - accuracy: 0.7273 - val_loss: 0.2592 - val_accuracy: 0.5405\n","Epoch 98/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2015 - accuracy: 0.7273 - val_loss: 0.2610 - val_accuracy: 0.5405\n","Epoch 99/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1954 - accuracy: 0.7273 - val_loss: 0.2623 - val_accuracy: 0.5405\n","Epoch 100/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2059 - accuracy: 0.7273 - val_loss: 0.2628 - val_accuracy: 0.5405\n","Epoch 101/130\n","1/1 [==============================] - 2s 2s/step - loss: 0.1911 - accuracy: 0.7273 - val_loss: 0.2625 - val_accuracy: 0.5405\n","Epoch 102/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2015 - accuracy: 0.7273 - val_loss: 0.2620 - val_accuracy: 0.5405\n","Epoch 103/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1933 - accuracy: 0.7273 - val_loss: 0.2612 - val_accuracy: 0.5405\n","Epoch 104/130\n","1/1 [==============================] - 2s 2s/step - loss: 0.1971 - accuracy: 0.7273 - val_loss: 0.2600 - val_accuracy: 0.5405\n","Epoch 105/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1855 - accuracy: 0.7273 - val_loss: 0.2595 - val_accuracy: 0.5405\n","Epoch 106/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2209 - accuracy: 0.7273 - val_loss: 0.2590 - val_accuracy: 0.5405\n","Epoch 107/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1909 - accuracy: 0.7273 - val_loss: 0.2587 - val_accuracy: 0.5405\n","Epoch 108/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2200 - accuracy: 0.7273 - val_loss: 0.2587 - val_accuracy: 0.5405\n","Epoch 109/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2027 - accuracy: 0.7273 - val_loss: 0.2587 - val_accuracy: 0.5405\n","Epoch 110/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1995 - accuracy: 0.7273 - val_loss: 0.2587 - val_accuracy: 0.5405\n","Epoch 111/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1924 - accuracy: 0.7273 - val_loss: 0.2589 - val_accuracy: 0.5405\n","Epoch 112/130\n","1/1 [==============================] - 2s 2s/step - loss: 0.1929 - accuracy: 0.7273 - val_loss: 0.2594 - val_accuracy: 0.5405\n","Epoch 113/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2099 - accuracy: 0.7273 - val_loss: 0.2599 - val_accuracy: 0.5405\n","Epoch 114/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2076 - accuracy: 0.7273 - val_loss: 0.2606 - val_accuracy: 0.5405\n","Epoch 115/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1885 - accuracy: 0.7273 - val_loss: 0.2614 - val_accuracy: 0.5405\n","Epoch 116/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1996 - accuracy: 0.7273 - val_loss: 0.2622 - val_accuracy: 0.5405\n","Epoch 117/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2013 - accuracy: 0.7273 - val_loss: 0.2626 - val_accuracy: 0.5405\n","Epoch 118/130\n","1/1 [==============================] - 2s 2s/step - loss: 0.1861 - accuracy: 0.7273 - val_loss: 0.2627 - val_accuracy: 0.5405\n","Epoch 119/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1941 - accuracy: 0.7273 - val_loss: 0.2624 - val_accuracy: 0.5405\n","Epoch 120/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2029 - accuracy: 0.7273 - val_loss: 0.2615 - val_accuracy: 0.5405\n","Epoch 121/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1902 - accuracy: 0.7273 - val_loss: 0.2608 - val_accuracy: 0.5405\n","Epoch 122/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2066 - accuracy: 0.7273 - val_loss: 0.2602 - val_accuracy: 0.5405\n","Epoch 123/130\n","1/1 [==============================] - 2s 2s/step - loss: 0.1811 - accuracy: 0.7273 - val_loss: 0.2600 - val_accuracy: 0.5405\n","Epoch 124/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1802 - accuracy: 0.7273 - val_loss: 0.2603 - val_accuracy: 0.5405\n","Epoch 125/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2081 - accuracy: 0.7273 - val_loss: 0.2599 - val_accuracy: 0.5405\n","Epoch 126/130\n","1/1 [==============================] - 2s 2s/step - loss: 0.1997 - accuracy: 0.7273 - val_loss: 0.2596 - val_accuracy: 0.5405\n","Epoch 127/130\n","1/1 [==============================] - 2s 2s/step - loss: 0.2074 - accuracy: 0.7273 - val_loss: 0.2595 - val_accuracy: 0.5405\n","Epoch 128/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2030 - accuracy: 0.7273 - val_loss: 0.2599 - val_accuracy: 0.5405\n","Epoch 129/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1999 - accuracy: 0.7273 - val_loss: 0.2608 - val_accuracy: 0.5405\n","Epoch 130/130\n","1/1 [==============================] - 2s 2s/step - loss: 0.2049 - accuracy: 0.7273 - val_loss: 0.2622 - val_accuracy: 0.5405\n","2/2 [==============================] - 0s 111ms/step - loss: 0.2622 - accuracy: 0.5405\n","loss :  0.5405405163764954\n","total_loss :  6.891891956329346\n","num :  14\n","WARNING:tensorflow:Layer gru_70 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","WARNING:tensorflow:Layer gru_71 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","WARNING:tensorflow:Layer gru_72 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","WARNING:tensorflow:Layer gru_73 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","WARNING:tensorflow:Layer gru_74 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","Epoch 1/130\n","1/1 [==============================] - 13s 13s/step - loss: 0.5528 - accuracy: 0.4545 - val_loss: 0.4403 - val_accuracy: 0.5405\n","Epoch 2/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.5141 - accuracy: 0.4545 - val_loss: 0.4111 - val_accuracy: 0.5405\n","Epoch 3/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.4715 - accuracy: 0.4545 - val_loss: 0.3803 - val_accuracy: 0.5405\n","Epoch 4/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.4262 - accuracy: 0.4545 - val_loss: 0.3447 - val_accuracy: 0.5405\n","Epoch 5/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.3809 - accuracy: 0.4545 - val_loss: 0.3070 - val_accuracy: 0.5405\n","Epoch 6/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.3186 - accuracy: 0.4545 - val_loss: 0.2715 - val_accuracy: 0.5405\n","Epoch 7/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2759 - accuracy: 0.4545 - val_loss: 0.2504 - val_accuracy: 0.5405\n","Epoch 8/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2509 - accuracy: 0.5455 - val_loss: 0.2603 - val_accuracy: 0.4595\n","Epoch 9/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2627 - accuracy: 0.5455 - val_loss: 0.2665 - val_accuracy: 0.4595\n","Epoch 10/130\n","1/1 [==============================] - 2s 2s/step - loss: 0.2682 - accuracy: 0.5455 - val_loss: 0.2593 - val_accuracy: 0.4595\n","Epoch 11/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2795 - accuracy: 0.5455 - val_loss: 0.2521 - val_accuracy: 0.4324\n","Epoch 12/130\n","1/1 [==============================] - 2s 2s/step - loss: 0.2460 - accuracy: 0.5455 - val_loss: 0.2508 - val_accuracy: 0.5405\n","Epoch 13/130\n","1/1 [==============================] - 2s 2s/step - loss: 0.2182 - accuracy: 0.6364 - val_loss: 0.2535 - val_accuracy: 0.5405\n","Epoch 14/130\n","1/1 [==============================] - 2s 2s/step - loss: 0.2407 - accuracy: 0.7273 - val_loss: 0.2574 - val_accuracy: 0.5405\n","Epoch 15/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2524 - accuracy: 0.4545 - val_loss: 0.2604 - val_accuracy: 0.5405\n","Epoch 16/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2630 - accuracy: 0.5455 - val_loss: 0.2619 - val_accuracy: 0.5405\n","Epoch 17/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2445 - accuracy: 0.5455 - val_loss: 0.2614 - val_accuracy: 0.5405\n","Epoch 18/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2509 - accuracy: 0.4545 - val_loss: 0.2597 - val_accuracy: 0.5405\n","Epoch 19/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2411 - accuracy: 0.5455 - val_loss: 0.2572 - val_accuracy: 0.5405\n","Epoch 20/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2403 - accuracy: 0.5455 - val_loss: 0.2549 - val_accuracy: 0.5405\n","Epoch 21/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2506 - accuracy: 0.3636 - val_loss: 0.2532 - val_accuracy: 0.5405\n","Epoch 22/130\n","1/1 [==============================] - 2s 2s/step - loss: 0.2422 - accuracy: 0.5455 - val_loss: 0.2526 - val_accuracy: 0.5946\n","Epoch 23/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2382 - accuracy: 0.6364 - val_loss: 0.2527 - val_accuracy: 0.5135\n","Epoch 24/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2468 - accuracy: 0.5455 - val_loss: 0.2531 - val_accuracy: 0.4324\n","Epoch 25/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2279 - accuracy: 0.5455 - val_loss: 0.2533 - val_accuracy: 0.4324\n","Epoch 26/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2625 - accuracy: 0.5455 - val_loss: 0.2532 - val_accuracy: 0.4595\n","Epoch 27/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2379 - accuracy: 0.5455 - val_loss: 0.2531 - val_accuracy: 0.5135\n","Epoch 28/130\n","1/1 [==============================] - 2s 2s/step - loss: 0.2671 - accuracy: 0.5455 - val_loss: 0.2534 - val_accuracy: 0.5946\n","Epoch 29/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2506 - accuracy: 0.4545 - val_loss: 0.2541 - val_accuracy: 0.5405\n","Epoch 30/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2443 - accuracy: 0.4545 - val_loss: 0.2550 - val_accuracy: 0.5405\n","Epoch 31/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2210 - accuracy: 0.6364 - val_loss: 0.2561 - val_accuracy: 0.5405\n","Epoch 32/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2679 - accuracy: 0.3636 - val_loss: 0.2571 - val_accuracy: 0.5405\n","Epoch 33/130\n","1/1 [==============================] - 2s 2s/step - loss: 0.2355 - accuracy: 0.5455 - val_loss: 0.2575 - val_accuracy: 0.5405\n","Epoch 34/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2455 - accuracy: 0.4545 - val_loss: 0.2574 - val_accuracy: 0.5405\n","Epoch 35/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2491 - accuracy: 0.4545 - val_loss: 0.2571 - val_accuracy: 0.5405\n","Epoch 36/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2455 - accuracy: 0.6364 - val_loss: 0.2567 - val_accuracy: 0.5405\n","Epoch 37/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2538 - accuracy: 0.5455 - val_loss: 0.2564 - val_accuracy: 0.5405\n","Epoch 38/130\n","1/1 [==============================] - 2s 2s/step - loss: 0.2445 - accuracy: 0.6364 - val_loss: 0.2562 - val_accuracy: 0.5405\n","Epoch 39/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2400 - accuracy: 0.7273 - val_loss: 0.2561 - val_accuracy: 0.5676\n","Epoch 40/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2585 - accuracy: 0.5455 - val_loss: 0.2561 - val_accuracy: 0.5676\n","Epoch 41/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2496 - accuracy: 0.5455 - val_loss: 0.2562 - val_accuracy: 0.5676\n","Epoch 42/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2531 - accuracy: 0.4545 - val_loss: 0.2566 - val_accuracy: 0.5676\n","Epoch 43/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2309 - accuracy: 0.5455 - val_loss: 0.2569 - val_accuracy: 0.5676\n","Epoch 44/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2474 - accuracy: 0.6364 - val_loss: 0.2573 - val_accuracy: 0.5405\n","Epoch 45/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2404 - accuracy: 0.7273 - val_loss: 0.2576 - val_accuracy: 0.5405\n","Epoch 46/130\n","1/1 [==============================] - 2s 2s/step - loss: 0.2343 - accuracy: 0.7273 - val_loss: 0.2579 - val_accuracy: 0.5405\n","Epoch 47/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2449 - accuracy: 0.5455 - val_loss: 0.2579 - val_accuracy: 0.5676\n","Epoch 48/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2507 - accuracy: 0.5455 - val_loss: 0.2580 - val_accuracy: 0.5676\n","Epoch 49/130\n","1/1 [==============================] - 2s 2s/step - loss: 0.2595 - accuracy: 0.5455 - val_loss: 0.2584 - val_accuracy: 0.5676\n","Epoch 50/130\n","1/1 [==============================] - 2s 2s/step - loss: 0.2411 - accuracy: 0.5455 - val_loss: 0.2587 - val_accuracy: 0.5676\n","Epoch 51/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2404 - accuracy: 0.3636 - val_loss: 0.2588 - val_accuracy: 0.5676\n","Epoch 52/130\n","1/1 [==============================] - 2s 2s/step - loss: 0.2511 - accuracy: 0.4545 - val_loss: 0.2590 - val_accuracy: 0.5676\n","Epoch 53/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2531 - accuracy: 0.6364 - val_loss: 0.2595 - val_accuracy: 0.5676\n","Epoch 54/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2204 - accuracy: 0.6364 - val_loss: 0.2598 - val_accuracy: 0.5946\n","Epoch 55/130\n","1/1 [==============================] - 2s 2s/step - loss: 0.2545 - accuracy: 0.4545 - val_loss: 0.2598 - val_accuracy: 0.5946\n","Epoch 56/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2635 - accuracy: 0.4545 - val_loss: 0.2600 - val_accuracy: 0.5946\n","Epoch 57/130\n","1/1 [==============================] - 2s 2s/step - loss: 0.2295 - accuracy: 0.6364 - val_loss: 0.2604 - val_accuracy: 0.5946\n","Epoch 58/130\n","1/1 [==============================] - 2s 2s/step - loss: 0.2421 - accuracy: 0.6364 - val_loss: 0.2611 - val_accuracy: 0.5946\n","Epoch 59/130\n","1/1 [==============================] - 2s 2s/step - loss: 0.2364 - accuracy: 0.6364 - val_loss: 0.2617 - val_accuracy: 0.5946\n","Epoch 60/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2425 - accuracy: 0.5455 - val_loss: 0.2628 - val_accuracy: 0.5676\n","Epoch 61/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2551 - accuracy: 0.4545 - val_loss: 0.2639 - val_accuracy: 0.5676\n","Epoch 62/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2314 - accuracy: 0.7273 - val_loss: 0.2644 - val_accuracy: 0.5676\n","Epoch 63/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2495 - accuracy: 0.4545 - val_loss: 0.2647 - val_accuracy: 0.5676\n","Epoch 64/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2521 - accuracy: 0.7273 - val_loss: 0.2651 - val_accuracy: 0.5676\n","Epoch 65/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2124 - accuracy: 0.7273 - val_loss: 0.2651 - val_accuracy: 0.5946\n","Epoch 66/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2448 - accuracy: 0.5455 - val_loss: 0.2648 - val_accuracy: 0.5946\n","Epoch 67/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2159 - accuracy: 0.5455 - val_loss: 0.2644 - val_accuracy: 0.5676\n","Epoch 68/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2470 - accuracy: 0.5455 - val_loss: 0.2650 - val_accuracy: 0.5676\n","Epoch 69/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2605 - accuracy: 0.5455 - val_loss: 0.2664 - val_accuracy: 0.5946\n","Epoch 70/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2346 - accuracy: 0.5455 - val_loss: 0.2688 - val_accuracy: 0.5676\n","Epoch 71/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2353 - accuracy: 0.6364 - val_loss: 0.2716 - val_accuracy: 0.5405\n","Epoch 72/130\n","1/1 [==============================] - 2s 2s/step - loss: 0.2346 - accuracy: 0.6364 - val_loss: 0.2741 - val_accuracy: 0.5405\n","Epoch 73/130\n","1/1 [==============================] - 2s 2s/step - loss: 0.2455 - accuracy: 0.4545 - val_loss: 0.2756 - val_accuracy: 0.5405\n","Epoch 74/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2446 - accuracy: 0.5455 - val_loss: 0.2762 - val_accuracy: 0.5405\n","Epoch 75/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2177 - accuracy: 0.7273 - val_loss: 0.2757 - val_accuracy: 0.5405\n","Epoch 76/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2544 - accuracy: 0.3636 - val_loss: 0.2752 - val_accuracy: 0.5676\n","Epoch 77/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2522 - accuracy: 0.5455 - val_loss: 0.2757 - val_accuracy: 0.5946\n","Epoch 78/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2419 - accuracy: 0.6364 - val_loss: 0.2767 - val_accuracy: 0.5946\n","Epoch 79/130\n","1/1 [==============================] - 2s 2s/step - loss: 0.2321 - accuracy: 0.4545 - val_loss: 0.2780 - val_accuracy: 0.5946\n","Epoch 80/130\n","1/1 [==============================] - 2s 2s/step - loss: 0.2079 - accuracy: 0.8182 - val_loss: 0.2783 - val_accuracy: 0.5946\n","Epoch 81/130\n","1/1 [==============================] - 2s 2s/step - loss: 0.2387 - accuracy: 0.5455 - val_loss: 0.2813 - val_accuracy: 0.5946\n","Epoch 82/130\n","1/1 [==============================] - 2s 2s/step - loss: 0.2643 - accuracy: 0.4545 - val_loss: 0.2852 - val_accuracy: 0.5676\n","Epoch 83/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2245 - accuracy: 0.7273 - val_loss: 0.2894 - val_accuracy: 0.5405\n","Epoch 84/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2214 - accuracy: 0.6364 - val_loss: 0.2916 - val_accuracy: 0.5405\n","Epoch 85/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2206 - accuracy: 0.6364 - val_loss: 0.2922 - val_accuracy: 0.5676\n","Epoch 86/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2252 - accuracy: 0.8182 - val_loss: 0.2915 - val_accuracy: 0.5946\n","Epoch 87/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2404 - accuracy: 0.6364 - val_loss: 0.2919 - val_accuracy: 0.5676\n","Epoch 88/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2431 - accuracy: 0.5455 - val_loss: 0.2945 - val_accuracy: 0.5946\n","Epoch 89/130\n","1/1 [==============================] - 2s 2s/step - loss: 0.2369 - accuracy: 0.5455 - val_loss: 0.2994 - val_accuracy: 0.5676\n","Epoch 90/130\n","1/1 [==============================] - 2s 2s/step - loss: 0.2301 - accuracy: 0.7273 - val_loss: 0.3037 - val_accuracy: 0.5676\n","Epoch 91/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2255 - accuracy: 0.7273 - val_loss: 0.3056 - val_accuracy: 0.5676\n","Epoch 92/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2469 - accuracy: 0.4545 - val_loss: 0.3060 - val_accuracy: 0.5676\n","Epoch 93/130\n","1/1 [==============================] - 2s 2s/step - loss: 0.2327 - accuracy: 0.7273 - val_loss: 0.3059 - val_accuracy: 0.5946\n","Epoch 94/130\n","1/1 [==============================] - 2s 2s/step - loss: 0.2430 - accuracy: 0.6364 - val_loss: 0.3069 - val_accuracy: 0.5946\n","Epoch 95/130\n","1/1 [==============================] - 2s 2s/step - loss: 0.2486 - accuracy: 0.6364 - val_loss: 0.3088 - val_accuracy: 0.5946\n","Epoch 96/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2206 - accuracy: 0.6364 - val_loss: 0.3099 - val_accuracy: 0.5946\n","Epoch 97/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2122 - accuracy: 0.6364 - val_loss: 0.3106 - val_accuracy: 0.5946\n","Epoch 98/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2191 - accuracy: 0.6364 - val_loss: 0.3131 - val_accuracy: 0.5946\n","Epoch 99/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2276 - accuracy: 0.7273 - val_loss: 0.3150 - val_accuracy: 0.5946\n","Epoch 100/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2050 - accuracy: 0.7273 - val_loss: 0.3175 - val_accuracy: 0.5946\n","Epoch 101/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1959 - accuracy: 0.7273 - val_loss: 0.3200 - val_accuracy: 0.5946\n","Epoch 102/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2124 - accuracy: 0.7273 - val_loss: 0.3235 - val_accuracy: 0.5946\n","Epoch 103/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2238 - accuracy: 0.7273 - val_loss: 0.3276 - val_accuracy: 0.5946\n","Epoch 104/130\n","1/1 [==============================] - 2s 2s/step - loss: 0.2086 - accuracy: 0.8182 - val_loss: 0.3314 - val_accuracy: 0.5946\n","Epoch 105/130\n","1/1 [==============================] - 2s 2s/step - loss: 0.2113 - accuracy: 0.7273 - val_loss: 0.3320 - val_accuracy: 0.5946\n","Epoch 106/130\n","1/1 [==============================] - 2s 2s/step - loss: 0.2490 - accuracy: 0.5455 - val_loss: 0.3318 - val_accuracy: 0.5676\n","Epoch 107/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2152 - accuracy: 0.7273 - val_loss: 0.3354 - val_accuracy: 0.5946\n","Epoch 108/130\n","1/1 [==============================] - 2s 2s/step - loss: 0.2130 - accuracy: 0.6364 - val_loss: 0.3407 - val_accuracy: 0.5946\n","Epoch 109/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2108 - accuracy: 0.8182 - val_loss: 0.3441 - val_accuracy: 0.5946\n","Epoch 110/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2450 - accuracy: 0.4545 - val_loss: 0.3482 - val_accuracy: 0.5676\n","Epoch 111/130\n","1/1 [==============================] - 2s 2s/step - loss: 0.2077 - accuracy: 0.7273 - val_loss: 0.3478 - val_accuracy: 0.5946\n","Epoch 112/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1957 - accuracy: 0.7273 - val_loss: 0.3481 - val_accuracy: 0.5946\n","Epoch 113/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2305 - accuracy: 0.5455 - val_loss: 0.3485 - val_accuracy: 0.5946\n","Epoch 114/130\n","1/1 [==============================] - 2s 2s/step - loss: 0.2245 - accuracy: 0.6364 - val_loss: 0.3482 - val_accuracy: 0.5676\n","Epoch 115/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2558 - accuracy: 0.4545 - val_loss: 0.3496 - val_accuracy: 0.5676\n","Epoch 116/130\n","1/1 [==============================] - 2s 2s/step - loss: 0.2213 - accuracy: 0.5455 - val_loss: 0.3514 - val_accuracy: 0.5676\n","Epoch 117/130\n","1/1 [==============================] - 2s 2s/step - loss: 0.1866 - accuracy: 0.7273 - val_loss: 0.3555 - val_accuracy: 0.5946\n","Epoch 118/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2027 - accuracy: 0.7273 - val_loss: 0.3590 - val_accuracy: 0.5946\n","Epoch 119/130\n","1/1 [==============================] - 2s 2s/step - loss: 0.2342 - accuracy: 0.7273 - val_loss: 0.3616 - val_accuracy: 0.5946\n","Epoch 120/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1892 - accuracy: 0.8182 - val_loss: 0.3600 - val_accuracy: 0.5946\n","Epoch 121/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1905 - accuracy: 0.6364 - val_loss: 0.3597 - val_accuracy: 0.5676\n","Epoch 122/130\n","1/1 [==============================] - 2s 2s/step - loss: 0.1840 - accuracy: 0.5455 - val_loss: 0.3616 - val_accuracy: 0.5676\n","Epoch 123/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1666 - accuracy: 0.7273 - val_loss: 0.3642 - val_accuracy: 0.5676\n","Epoch 124/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2276 - accuracy: 0.7273 - val_loss: 0.3672 - val_accuracy: 0.5676\n","Epoch 125/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2094 - accuracy: 0.6364 - val_loss: 0.3725 - val_accuracy: 0.5946\n","Epoch 126/130\n","1/1 [==============================] - 2s 2s/step - loss: 0.2277 - accuracy: 0.6364 - val_loss: 0.3763 - val_accuracy: 0.5676\n","Epoch 127/130\n","1/1 [==============================] - 2s 2s/step - loss: 0.2290 - accuracy: 0.6364 - val_loss: 0.3758 - val_accuracy: 0.5946\n","Epoch 128/130\n","1/1 [==============================] - 2s 2s/step - loss: 0.2279 - accuracy: 0.7273 - val_loss: 0.3746 - val_accuracy: 0.5946\n","Epoch 129/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1949 - accuracy: 0.6364 - val_loss: 0.3750 - val_accuracy: 0.5676\n","Epoch 130/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1970 - accuracy: 0.6364 - val_loss: 0.3772 - val_accuracy: 0.5405\n","2/2 [==============================] - 0s 123ms/step - loss: 0.3772 - accuracy: 0.5405\n","loss :  0.5405405163764954\n","total_loss :  7.432432472705841\n","num :  15\n","WARNING:tensorflow:Layer gru_75 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","WARNING:tensorflow:Layer gru_76 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","WARNING:tensorflow:Layer gru_77 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","WARNING:tensorflow:Layer gru_78 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","WARNING:tensorflow:Layer gru_79 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","Epoch 1/130\n","1/1 [==============================] - 13s 13s/step - loss: 0.6317 - accuracy: 0.3636 - val_loss: 0.4270 - val_accuracy: 0.5405\n","Epoch 2/130\n","1/1 [==============================] - 2s 2s/step - loss: 0.5888 - accuracy: 0.3636 - val_loss: 0.3949 - val_accuracy: 0.5405\n","Epoch 3/130\n","1/1 [==============================] - 2s 2s/step - loss: 0.5329 - accuracy: 0.3636 - val_loss: 0.3576 - val_accuracy: 0.5405\n","Epoch 4/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.4861 - accuracy: 0.3636 - val_loss: 0.3150 - val_accuracy: 0.5405\n","Epoch 5/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.3903 - accuracy: 0.3636 - val_loss: 0.2737 - val_accuracy: 0.5405\n","Epoch 6/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.3179 - accuracy: 0.3636 - val_loss: 0.2490 - val_accuracy: 0.5405\n","Epoch 7/130\n","1/1 [==============================] - 2s 2s/step - loss: 0.2431 - accuracy: 0.5455 - val_loss: 0.2819 - val_accuracy: 0.4595\n","Epoch 8/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2270 - accuracy: 0.6364 - val_loss: 0.4015 - val_accuracy: 0.4595\n","Epoch 9/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.3060 - accuracy: 0.6364 - val_loss: 0.3957 - val_accuracy: 0.4595\n","Epoch 10/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.3045 - accuracy: 0.6364 - val_loss: 0.3331 - val_accuracy: 0.4595\n","Epoch 11/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2822 - accuracy: 0.6364 - val_loss: 0.2821 - val_accuracy: 0.4595\n","Epoch 12/130\n","1/1 [==============================] - 2s 2s/step - loss: 0.2514 - accuracy: 0.6364 - val_loss: 0.2572 - val_accuracy: 0.4595\n","Epoch 13/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2544 - accuracy: 0.6364 - val_loss: 0.2493 - val_accuracy: 0.4865\n","Epoch 14/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2146 - accuracy: 0.6364 - val_loss: 0.2491 - val_accuracy: 0.5405\n","Epoch 15/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2520 - accuracy: 0.3636 - val_loss: 0.2507 - val_accuracy: 0.5405\n","Epoch 16/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2701 - accuracy: 0.2727 - val_loss: 0.2518 - val_accuracy: 0.5405\n","Epoch 17/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2564 - accuracy: 0.3636 - val_loss: 0.2518 - val_accuracy: 0.5405\n","Epoch 18/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2661 - accuracy: 0.3636 - val_loss: 0.2508 - val_accuracy: 0.5405\n","Epoch 19/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2649 - accuracy: 0.4545 - val_loss: 0.2496 - val_accuracy: 0.5405\n","Epoch 20/130\n","1/1 [==============================] - 2s 2s/step - loss: 0.2690 - accuracy: 0.2727 - val_loss: 0.2491 - val_accuracy: 0.5405\n","Epoch 21/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2465 - accuracy: 0.5455 - val_loss: 0.2504 - val_accuracy: 0.4865\n","Epoch 22/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2456 - accuracy: 0.6364 - val_loss: 0.2545 - val_accuracy: 0.4595\n","Epoch 23/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2310 - accuracy: 0.6364 - val_loss: 0.2628 - val_accuracy: 0.4595\n","Epoch 24/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2264 - accuracy: 0.6364 - val_loss: 0.2745 - val_accuracy: 0.4595\n","Epoch 25/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2407 - accuracy: 0.6364 - val_loss: 0.2868 - val_accuracy: 0.4595\n","Epoch 26/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2519 - accuracy: 0.6364 - val_loss: 0.2958 - val_accuracy: 0.4595\n","Epoch 27/130\n","1/1 [==============================] - 2s 2s/step - loss: 0.2374 - accuracy: 0.6364 - val_loss: 0.3006 - val_accuracy: 0.4595\n","Epoch 28/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2223 - accuracy: 0.6364 - val_loss: 0.3010 - val_accuracy: 0.4595\n","Epoch 29/130\n","1/1 [==============================] - 2s 2s/step - loss: 0.2406 - accuracy: 0.6364 - val_loss: 0.2964 - val_accuracy: 0.4595\n","Epoch 30/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2321 - accuracy: 0.6364 - val_loss: 0.2892 - val_accuracy: 0.4595\n","Epoch 31/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2121 - accuracy: 0.6364 - val_loss: 0.2811 - val_accuracy: 0.4595\n","Epoch 32/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2337 - accuracy: 0.6364 - val_loss: 0.2729 - val_accuracy: 0.4595\n","Epoch 33/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2247 - accuracy: 0.6364 - val_loss: 0.2670 - val_accuracy: 0.4595\n","Epoch 34/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1978 - accuracy: 0.6364 - val_loss: 0.2636 - val_accuracy: 0.4595\n","Epoch 35/130\n","1/1 [==============================] - 2s 2s/step - loss: 0.2420 - accuracy: 0.6364 - val_loss: 0.2613 - val_accuracy: 0.4595\n","Epoch 36/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2401 - accuracy: 0.6364 - val_loss: 0.2603 - val_accuracy: 0.4595\n","Epoch 37/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2357 - accuracy: 0.6364 - val_loss: 0.2603 - val_accuracy: 0.4595\n","Epoch 38/130\n","1/1 [==============================] - 2s 2s/step - loss: 0.2427 - accuracy: 0.7273 - val_loss: 0.2613 - val_accuracy: 0.4595\n","Epoch 39/130\n","1/1 [==============================] - 2s 2s/step - loss: 0.2254 - accuracy: 0.6364 - val_loss: 0.2630 - val_accuracy: 0.4595\n","Epoch 40/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2085 - accuracy: 0.6364 - val_loss: 0.2658 - val_accuracy: 0.4595\n","Epoch 41/130\n","1/1 [==============================] - 2s 2s/step - loss: 0.2241 - accuracy: 0.6364 - val_loss: 0.2692 - val_accuracy: 0.4595\n","Epoch 42/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2145 - accuracy: 0.6364 - val_loss: 0.2733 - val_accuracy: 0.4595\n","Epoch 43/130\n","1/1 [==============================] - 2s 2s/step - loss: 0.2294 - accuracy: 0.6364 - val_loss: 0.2780 - val_accuracy: 0.4595\n","Epoch 44/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2281 - accuracy: 0.6364 - val_loss: 0.2821 - val_accuracy: 0.4595\n","Epoch 45/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2401 - accuracy: 0.6364 - val_loss: 0.2848 - val_accuracy: 0.4595\n","Epoch 46/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2490 - accuracy: 0.6364 - val_loss: 0.2842 - val_accuracy: 0.4595\n","Epoch 47/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2159 - accuracy: 0.6364 - val_loss: 0.2830 - val_accuracy: 0.4595\n","Epoch 48/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2340 - accuracy: 0.6364 - val_loss: 0.2823 - val_accuracy: 0.4595\n","Epoch 49/130\n","1/1 [==============================] - 2s 2s/step - loss: 0.2109 - accuracy: 0.6364 - val_loss: 0.2813 - val_accuracy: 0.4595\n","Epoch 50/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2425 - accuracy: 0.6364 - val_loss: 0.2792 - val_accuracy: 0.4595\n","Epoch 51/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2150 - accuracy: 0.6364 - val_loss: 0.2783 - val_accuracy: 0.4595\n","Epoch 52/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2216 - accuracy: 0.6364 - val_loss: 0.2781 - val_accuracy: 0.4595\n","Epoch 53/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2289 - accuracy: 0.6364 - val_loss: 0.2783 - val_accuracy: 0.4595\n","Epoch 54/130\n","1/1 [==============================] - 2s 2s/step - loss: 0.2166 - accuracy: 0.6364 - val_loss: 0.2801 - val_accuracy: 0.4595\n","Epoch 55/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2251 - accuracy: 0.6364 - val_loss: 0.2830 - val_accuracy: 0.4595\n","Epoch 56/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2238 - accuracy: 0.6364 - val_loss: 0.2856 - val_accuracy: 0.4595\n","Epoch 57/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2513 - accuracy: 0.6364 - val_loss: 0.2861 - val_accuracy: 0.4595\n","Epoch 58/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2084 - accuracy: 0.6364 - val_loss: 0.2874 - val_accuracy: 0.4595\n","Epoch 59/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2313 - accuracy: 0.6364 - val_loss: 0.2905 - val_accuracy: 0.4595\n","Epoch 60/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2248 - accuracy: 0.6364 - val_loss: 0.2942 - val_accuracy: 0.4595\n","Epoch 61/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2396 - accuracy: 0.6364 - val_loss: 0.2981 - val_accuracy: 0.4595\n","Epoch 62/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2178 - accuracy: 0.6364 - val_loss: 0.3009 - val_accuracy: 0.4595\n","Epoch 63/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2341 - accuracy: 0.6364 - val_loss: 0.3013 - val_accuracy: 0.4595\n","Epoch 64/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2136 - accuracy: 0.6364 - val_loss: 0.3019 - val_accuracy: 0.4595\n","Epoch 65/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2065 - accuracy: 0.6364 - val_loss: 0.3007 - val_accuracy: 0.4595\n","Epoch 66/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2378 - accuracy: 0.6364 - val_loss: 0.2969 - val_accuracy: 0.4595\n","Epoch 67/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2281 - accuracy: 0.5455 - val_loss: 0.2940 - val_accuracy: 0.4595\n","Epoch 68/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2199 - accuracy: 0.7273 - val_loss: 0.2907 - val_accuracy: 0.4595\n","Epoch 69/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2295 - accuracy: 0.7273 - val_loss: 0.2891 - val_accuracy: 0.4595\n","Epoch 70/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2328 - accuracy: 0.6364 - val_loss: 0.2872 - val_accuracy: 0.4595\n","Epoch 71/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2290 - accuracy: 0.6364 - val_loss: 0.2876 - val_accuracy: 0.4595\n","Epoch 72/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2199 - accuracy: 0.6364 - val_loss: 0.2910 - val_accuracy: 0.4595\n","Epoch 73/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2063 - accuracy: 0.6364 - val_loss: 0.2990 - val_accuracy: 0.4595\n","Epoch 74/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2181 - accuracy: 0.6364 - val_loss: 0.3088 - val_accuracy: 0.4595\n","Epoch 75/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2336 - accuracy: 0.6364 - val_loss: 0.3174 - val_accuracy: 0.4595\n","Epoch 76/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2353 - accuracy: 0.6364 - val_loss: 0.3216 - val_accuracy: 0.4595\n","Epoch 77/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2304 - accuracy: 0.6364 - val_loss: 0.3208 - val_accuracy: 0.4595\n","Epoch 78/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2138 - accuracy: 0.6364 - val_loss: 0.3206 - val_accuracy: 0.4595\n","Epoch 79/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2168 - accuracy: 0.6364 - val_loss: 0.3204 - val_accuracy: 0.4595\n","Epoch 80/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2338 - accuracy: 0.6364 - val_loss: 0.3079 - val_accuracy: 0.4595\n","Epoch 81/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2021 - accuracy: 0.6364 - val_loss: 0.3006 - val_accuracy: 0.4595\n","Epoch 82/130\n","1/1 [==============================] - 2s 2s/step - loss: 0.2106 - accuracy: 0.5455 - val_loss: 0.2989 - val_accuracy: 0.4595\n","Epoch 83/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2139 - accuracy: 0.5455 - val_loss: 0.3013 - val_accuracy: 0.4865\n","Epoch 84/130\n","1/1 [==============================] - 2s 2s/step - loss: 0.2177 - accuracy: 0.5455 - val_loss: 0.3102 - val_accuracy: 0.4595\n","Epoch 85/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2272 - accuracy: 0.5455 - val_loss: 0.3170 - val_accuracy: 0.4595\n","Epoch 86/130\n","1/1 [==============================] - 2s 2s/step - loss: 0.2511 - accuracy: 0.5455 - val_loss: 0.3188 - val_accuracy: 0.4595\n","Epoch 87/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2212 - accuracy: 0.6364 - val_loss: 0.3174 - val_accuracy: 0.4595\n","Epoch 88/130\n","1/1 [==============================] - 2s 2s/step - loss: 0.1990 - accuracy: 0.8182 - val_loss: 0.3234 - val_accuracy: 0.4595\n","Epoch 89/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2281 - accuracy: 0.7273 - val_loss: 0.3351 - val_accuracy: 0.4595\n","Epoch 90/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2431 - accuracy: 0.6364 - val_loss: 0.3329 - val_accuracy: 0.4595\n","Epoch 91/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2062 - accuracy: 0.7273 - val_loss: 0.3401 - val_accuracy: 0.4595\n","Epoch 92/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2150 - accuracy: 0.6364 - val_loss: 0.3472 - val_accuracy: 0.4595\n","Epoch 93/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2320 - accuracy: 0.7273 - val_loss: 0.3472 - val_accuracy: 0.4595\n","Epoch 94/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2072 - accuracy: 0.7273 - val_loss: 0.3545 - val_accuracy: 0.4595\n","Epoch 95/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2084 - accuracy: 0.5455 - val_loss: 0.3702 - val_accuracy: 0.4595\n","Epoch 96/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2065 - accuracy: 0.5455 - val_loss: 0.3841 - val_accuracy: 0.4595\n","Epoch 97/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2257 - accuracy: 0.6364 - val_loss: 0.3764 - val_accuracy: 0.4595\n","Epoch 98/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1966 - accuracy: 0.6364 - val_loss: 0.3719 - val_accuracy: 0.4595\n","Epoch 99/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2006 - accuracy: 0.6364 - val_loss: 0.3574 - val_accuracy: 0.4595\n","Epoch 100/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2216 - accuracy: 0.7273 - val_loss: 0.3357 - val_accuracy: 0.4595\n","Epoch 101/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2110 - accuracy: 0.6364 - val_loss: 0.3263 - val_accuracy: 0.4595\n","Epoch 102/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2038 - accuracy: 0.7273 - val_loss: 0.3233 - val_accuracy: 0.4595\n","Epoch 103/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2201 - accuracy: 0.5455 - val_loss: 0.3261 - val_accuracy: 0.4595\n","Epoch 104/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2085 - accuracy: 0.7273 - val_loss: 0.3458 - val_accuracy: 0.4595\n","Epoch 105/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2416 - accuracy: 0.6364 - val_loss: 0.3712 - val_accuracy: 0.4595\n","Epoch 106/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2234 - accuracy: 0.7273 - val_loss: 0.4028 - val_accuracy: 0.4595\n","Epoch 107/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2190 - accuracy: 0.7273 - val_loss: 0.4085 - val_accuracy: 0.4595\n","Epoch 108/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1783 - accuracy: 0.6364 - val_loss: 0.4065 - val_accuracy: 0.4595\n","Epoch 109/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2201 - accuracy: 0.7273 - val_loss: 0.3939 - val_accuracy: 0.4595\n","Epoch 110/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2049 - accuracy: 0.6364 - val_loss: 0.3751 - val_accuracy: 0.4595\n","Epoch 111/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2280 - accuracy: 0.7273 - val_loss: 0.3461 - val_accuracy: 0.4595\n","Epoch 112/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2572 - accuracy: 0.4545 - val_loss: 0.3138 - val_accuracy: 0.4595\n","Epoch 113/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2025 - accuracy: 0.7273 - val_loss: 0.3039 - val_accuracy: 0.4324\n","Epoch 114/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2535 - accuracy: 0.7273 - val_loss: 0.3022 - val_accuracy: 0.4324\n","Epoch 115/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2132 - accuracy: 0.6364 - val_loss: 0.3149 - val_accuracy: 0.4865\n","Epoch 116/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2403 - accuracy: 0.6364 - val_loss: 0.3390 - val_accuracy: 0.4595\n","Epoch 117/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2184 - accuracy: 0.7273 - val_loss: 0.3572 - val_accuracy: 0.4595\n","Epoch 118/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2284 - accuracy: 0.6364 - val_loss: 0.3658 - val_accuracy: 0.4595\n","Epoch 119/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2169 - accuracy: 0.6364 - val_loss: 0.3647 - val_accuracy: 0.4595\n","Epoch 120/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2411 - accuracy: 0.7273 - val_loss: 0.3577 - val_accuracy: 0.4595\n","Epoch 121/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1833 - accuracy: 0.7273 - val_loss: 0.3540 - val_accuracy: 0.4595\n","Epoch 122/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2372 - accuracy: 0.6364 - val_loss: 0.3396 - val_accuracy: 0.4595\n","Epoch 123/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2436 - accuracy: 0.5455 - val_loss: 0.3284 - val_accuracy: 0.4595\n","Epoch 124/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2194 - accuracy: 0.6364 - val_loss: 0.3242 - val_accuracy: 0.4595\n","Epoch 125/130\n","1/1 [==============================] - 2s 2s/step - loss: 0.2201 - accuracy: 0.6364 - val_loss: 0.3248 - val_accuracy: 0.4595\n","Epoch 126/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2186 - accuracy: 0.7273 - val_loss: 0.3290 - val_accuracy: 0.4595\n","Epoch 127/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2107 - accuracy: 0.6364 - val_loss: 0.3425 - val_accuracy: 0.4595\n","Epoch 128/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2171 - accuracy: 0.6364 - val_loss: 0.3670 - val_accuracy: 0.4595\n","Epoch 129/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2107 - accuracy: 0.6364 - val_loss: 0.3867 - val_accuracy: 0.4595\n","Epoch 130/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2007 - accuracy: 0.6364 - val_loss: 0.3815 - val_accuracy: 0.4595\n","2/2 [==============================] - 0s 97ms/step - loss: 0.3815 - accuracy: 0.4595\n","loss :  0.45945945382118225\n","total_loss :  7.891891926527023\n","num :  16\n","WARNING:tensorflow:Layer gru_80 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","WARNING:tensorflow:Layer gru_81 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","WARNING:tensorflow:Layer gru_82 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","WARNING:tensorflow:Layer gru_83 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","WARNING:tensorflow:Layer gru_84 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","Epoch 1/130\n","1/1 [==============================] - 12s 12s/step - loss: 0.6177 - accuracy: 0.3636 - val_loss: 0.3693 - val_accuracy: 0.5946\n","Epoch 2/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.5668 - accuracy: 0.3636 - val_loss: 0.3382 - val_accuracy: 0.5946\n","Epoch 3/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.5047 - accuracy: 0.3636 - val_loss: 0.3018 - val_accuracy: 0.5946\n","Epoch 4/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.4197 - accuracy: 0.3636 - val_loss: 0.2650 - val_accuracy: 0.5946\n","Epoch 5/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.3310 - accuracy: 0.3636 - val_loss: 0.2408 - val_accuracy: 0.5946\n","Epoch 6/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2420 - accuracy: 0.6364 - val_loss: 0.2658 - val_accuracy: 0.4054\n","Epoch 7/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2293 - accuracy: 0.6364 - val_loss: 0.3504 - val_accuracy: 0.4054\n","Epoch 8/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2908 - accuracy: 0.6364 - val_loss: 0.3474 - val_accuracy: 0.4054\n","Epoch 9/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.3214 - accuracy: 0.6364 - val_loss: 0.2981 - val_accuracy: 0.4054\n","Epoch 10/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2768 - accuracy: 0.6364 - val_loss: 0.2612 - val_accuracy: 0.4054\n","Epoch 11/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2296 - accuracy: 0.6364 - val_loss: 0.2448 - val_accuracy: 0.5946\n","Epoch 12/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2421 - accuracy: 0.6364 - val_loss: 0.2404 - val_accuracy: 0.5946\n","Epoch 13/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2360 - accuracy: 0.6364 - val_loss: 0.2408 - val_accuracy: 0.5946\n","Epoch 14/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2427 - accuracy: 0.5455 - val_loss: 0.2420 - val_accuracy: 0.5946\n","Epoch 15/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2472 - accuracy: 0.6364 - val_loss: 0.2425 - val_accuracy: 0.5946\n","Epoch 16/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2677 - accuracy: 0.3636 - val_loss: 0.2420 - val_accuracy: 0.5946\n","Epoch 17/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2699 - accuracy: 0.3636 - val_loss: 0.2410 - val_accuracy: 0.5946\n","Epoch 18/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2615 - accuracy: 0.3636 - val_loss: 0.2403 - val_accuracy: 0.5946\n","Epoch 19/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2659 - accuracy: 0.2727 - val_loss: 0.2410 - val_accuracy: 0.5946\n","Epoch 20/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2434 - accuracy: 0.5455 - val_loss: 0.2443 - val_accuracy: 0.5946\n","Epoch 21/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2443 - accuracy: 0.6364 - val_loss: 0.2510 - val_accuracy: 0.4865\n","Epoch 22/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2196 - accuracy: 0.6364 - val_loss: 0.2607 - val_accuracy: 0.4054\n","Epoch 23/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2507 - accuracy: 0.6364 - val_loss: 0.2708 - val_accuracy: 0.4054\n","Epoch 24/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2410 - accuracy: 0.6364 - val_loss: 0.2780 - val_accuracy: 0.4054\n","Epoch 25/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2265 - accuracy: 0.6364 - val_loss: 0.2805 - val_accuracy: 0.4054\n","Epoch 26/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2150 - accuracy: 0.6364 - val_loss: 0.2769 - val_accuracy: 0.4054\n","Epoch 27/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2335 - accuracy: 0.6364 - val_loss: 0.2691 - val_accuracy: 0.4054\n","Epoch 28/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2142 - accuracy: 0.6364 - val_loss: 0.2618 - val_accuracy: 0.4054\n","Epoch 29/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2242 - accuracy: 0.6364 - val_loss: 0.2554 - val_accuracy: 0.4054\n","Epoch 30/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2433 - accuracy: 0.6364 - val_loss: 0.2503 - val_accuracy: 0.4595\n","Epoch 31/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2190 - accuracy: 0.6364 - val_loss: 0.2467 - val_accuracy: 0.6216\n","Epoch 32/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2417 - accuracy: 0.6364 - val_loss: 0.2447 - val_accuracy: 0.5946\n","Epoch 33/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2562 - accuracy: 0.6364 - val_loss: 0.2434 - val_accuracy: 0.5946\n","Epoch 34/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2144 - accuracy: 0.7273 - val_loss: 0.2432 - val_accuracy: 0.5946\n","Epoch 35/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2389 - accuracy: 0.7273 - val_loss: 0.2436 - val_accuracy: 0.5946\n","Epoch 36/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2278 - accuracy: 0.6364 - val_loss: 0.2446 - val_accuracy: 0.5946\n","Epoch 37/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2295 - accuracy: 0.6364 - val_loss: 0.2461 - val_accuracy: 0.7027\n","Epoch 38/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2307 - accuracy: 0.6364 - val_loss: 0.2481 - val_accuracy: 0.4865\n","Epoch 39/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2157 - accuracy: 0.6364 - val_loss: 0.2506 - val_accuracy: 0.4595\n","Epoch 40/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2265 - accuracy: 0.6364 - val_loss: 0.2529 - val_accuracy: 0.5405\n","Epoch 41/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2427 - accuracy: 0.6364 - val_loss: 0.2544 - val_accuracy: 0.4595\n","Epoch 42/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2112 - accuracy: 0.6364 - val_loss: 0.2553 - val_accuracy: 0.4054\n","Epoch 43/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2460 - accuracy: 0.6364 - val_loss: 0.2554 - val_accuracy: 0.4054\n","Epoch 44/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2172 - accuracy: 0.6364 - val_loss: 0.2552 - val_accuracy: 0.4324\n","Epoch 45/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1929 - accuracy: 0.6364 - val_loss: 0.2546 - val_accuracy: 0.4595\n","Epoch 46/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2318 - accuracy: 0.6364 - val_loss: 0.2538 - val_accuracy: 0.4865\n","Epoch 47/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2367 - accuracy: 0.6364 - val_loss: 0.2520 - val_accuracy: 0.4595\n","Epoch 48/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2037 - accuracy: 0.6364 - val_loss: 0.2511 - val_accuracy: 0.4595\n","Epoch 49/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2213 - accuracy: 0.6364 - val_loss: 0.2494 - val_accuracy: 0.4595\n","Epoch 50/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2315 - accuracy: 0.6364 - val_loss: 0.2474 - val_accuracy: 0.5135\n","Epoch 51/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2177 - accuracy: 0.6364 - val_loss: 0.2459 - val_accuracy: 0.5405\n","Epoch 52/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2260 - accuracy: 0.6364 - val_loss: 0.2453 - val_accuracy: 0.5676\n","Epoch 53/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2361 - accuracy: 0.6364 - val_loss: 0.2449 - val_accuracy: 0.6486\n","Epoch 54/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2233 - accuracy: 0.6364 - val_loss: 0.2453 - val_accuracy: 0.5676\n","Epoch 55/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2233 - accuracy: 0.6364 - val_loss: 0.2463 - val_accuracy: 0.5135\n","Epoch 56/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2427 - accuracy: 0.6364 - val_loss: 0.2469 - val_accuracy: 0.4865\n","Epoch 57/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2384 - accuracy: 0.6364 - val_loss: 0.2470 - val_accuracy: 0.4865\n","Epoch 58/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2295 - accuracy: 0.6364 - val_loss: 0.2463 - val_accuracy: 0.5135\n","Epoch 59/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2534 - accuracy: 0.6364 - val_loss: 0.2449 - val_accuracy: 0.5676\n","Epoch 60/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2334 - accuracy: 0.6364 - val_loss: 0.2435 - val_accuracy: 0.7027\n","Epoch 61/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2301 - accuracy: 0.6364 - val_loss: 0.2424 - val_accuracy: 0.6486\n","Epoch 62/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2514 - accuracy: 0.6364 - val_loss: 0.2415 - val_accuracy: 0.5946\n","Epoch 63/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2258 - accuracy: 0.7273 - val_loss: 0.2414 - val_accuracy: 0.5946\n","Epoch 64/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2283 - accuracy: 0.6364 - val_loss: 0.2416 - val_accuracy: 0.5946\n","Epoch 65/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2529 - accuracy: 0.6364 - val_loss: 0.2420 - val_accuracy: 0.6486\n","Epoch 66/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2371 - accuracy: 0.6364 - val_loss: 0.2426 - val_accuracy: 0.6757\n","Epoch 67/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2232 - accuracy: 0.6364 - val_loss: 0.2433 - val_accuracy: 0.6757\n","Epoch 68/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2359 - accuracy: 0.6364 - val_loss: 0.2437 - val_accuracy: 0.6486\n","Epoch 69/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2260 - accuracy: 0.6364 - val_loss: 0.2440 - val_accuracy: 0.5946\n","Epoch 70/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2251 - accuracy: 0.6364 - val_loss: 0.2439 - val_accuracy: 0.5946\n","Epoch 71/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2218 - accuracy: 0.6364 - val_loss: 0.2440 - val_accuracy: 0.5676\n","Epoch 72/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2274 - accuracy: 0.6364 - val_loss: 0.2436 - val_accuracy: 0.5946\n","Epoch 73/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2461 - accuracy: 0.6364 - val_loss: 0.2427 - val_accuracy: 0.7027\n","Epoch 74/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2178 - accuracy: 0.6364 - val_loss: 0.2419 - val_accuracy: 0.6486\n","Epoch 75/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2195 - accuracy: 0.6364 - val_loss: 0.2414 - val_accuracy: 0.6486\n","Epoch 76/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2290 - accuracy: 0.6364 - val_loss: 0.2411 - val_accuracy: 0.6216\n","Epoch 77/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2246 - accuracy: 0.6364 - val_loss: 0.2410 - val_accuracy: 0.5946\n","Epoch 78/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2342 - accuracy: 0.6364 - val_loss: 0.2410 - val_accuracy: 0.5946\n","Epoch 79/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2220 - accuracy: 0.6364 - val_loss: 0.2413 - val_accuracy: 0.6757\n","Epoch 80/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2204 - accuracy: 0.6364 - val_loss: 0.2419 - val_accuracy: 0.6757\n","Epoch 81/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2328 - accuracy: 0.6364 - val_loss: 0.2421 - val_accuracy: 0.7027\n","Epoch 82/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2286 - accuracy: 0.6364 - val_loss: 0.2417 - val_accuracy: 0.6486\n","Epoch 83/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2414 - accuracy: 0.6364 - val_loss: 0.2413 - val_accuracy: 0.6757\n","Epoch 84/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2469 - accuracy: 0.6364 - val_loss: 0.2406 - val_accuracy: 0.5946\n","Epoch 85/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2403 - accuracy: 0.6364 - val_loss: 0.2401 - val_accuracy: 0.5946\n","Epoch 86/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2224 - accuracy: 0.6364 - val_loss: 0.2399 - val_accuracy: 0.5946\n","Epoch 87/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2325 - accuracy: 0.6364 - val_loss: 0.2397 - val_accuracy: 0.5946\n","Epoch 88/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2181 - accuracy: 0.6364 - val_loss: 0.2397 - val_accuracy: 0.5946\n","Epoch 89/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1948 - accuracy: 0.7273 - val_loss: 0.2403 - val_accuracy: 0.5946\n","Epoch 90/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2255 - accuracy: 0.6364 - val_loss: 0.2409 - val_accuracy: 0.6486\n","Epoch 91/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2401 - accuracy: 0.6364 - val_loss: 0.2413 - val_accuracy: 0.6486\n","Epoch 92/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2264 - accuracy: 0.6364 - val_loss: 0.2413 - val_accuracy: 0.6486\n","Epoch 93/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2114 - accuracy: 0.6364 - val_loss: 0.2416 - val_accuracy: 0.6757\n","Epoch 94/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2276 - accuracy: 0.6364 - val_loss: 0.2418 - val_accuracy: 0.6757\n","Epoch 95/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2236 - accuracy: 0.6364 - val_loss: 0.2411 - val_accuracy: 0.6757\n","Epoch 96/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2339 - accuracy: 0.6364 - val_loss: 0.2403 - val_accuracy: 0.5946\n","Epoch 97/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2168 - accuracy: 0.6364 - val_loss: 0.2399 - val_accuracy: 0.5946\n","Epoch 98/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2419 - accuracy: 0.6364 - val_loss: 0.2395 - val_accuracy: 0.5946\n","Epoch 99/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2359 - accuracy: 0.6364 - val_loss: 0.2393 - val_accuracy: 0.5946\n","Epoch 100/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2324 - accuracy: 0.6364 - val_loss: 0.2392 - val_accuracy: 0.5946\n","Epoch 101/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2260 - accuracy: 0.6364 - val_loss: 0.2391 - val_accuracy: 0.5946\n","Epoch 102/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2202 - accuracy: 0.6364 - val_loss: 0.2391 - val_accuracy: 0.5946\n","Epoch 103/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2392 - accuracy: 0.6364 - val_loss: 0.2392 - val_accuracy: 0.5946\n","Epoch 104/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2034 - accuracy: 0.6364 - val_loss: 0.2393 - val_accuracy: 0.5946\n","Epoch 105/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2162 - accuracy: 0.6364 - val_loss: 0.2393 - val_accuracy: 0.5946\n","Epoch 106/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2168 - accuracy: 0.6364 - val_loss: 0.2393 - val_accuracy: 0.5946\n","Epoch 107/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2262 - accuracy: 0.6364 - val_loss: 0.2393 - val_accuracy: 0.5946\n","Epoch 108/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2241 - accuracy: 0.6364 - val_loss: 0.2392 - val_accuracy: 0.5946\n","Epoch 109/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2243 - accuracy: 0.6364 - val_loss: 0.2392 - val_accuracy: 0.5946\n","Epoch 110/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2104 - accuracy: 0.6364 - val_loss: 0.2393 - val_accuracy: 0.5946\n","Epoch 111/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2304 - accuracy: 0.6364 - val_loss: 0.2396 - val_accuracy: 0.5946\n","Epoch 112/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2283 - accuracy: 0.6364 - val_loss: 0.2400 - val_accuracy: 0.5946\n","Epoch 113/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2354 - accuracy: 0.6364 - val_loss: 0.2402 - val_accuracy: 0.5946\n","Epoch 114/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2261 - accuracy: 0.6364 - val_loss: 0.2402 - val_accuracy: 0.5946\n","Epoch 115/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2236 - accuracy: 0.6364 - val_loss: 0.2402 - val_accuracy: 0.5946\n","Epoch 116/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2139 - accuracy: 0.6364 - val_loss: 0.2400 - val_accuracy: 0.5946\n","Epoch 117/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2080 - accuracy: 0.7273 - val_loss: 0.2396 - val_accuracy: 0.5946\n","Epoch 118/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2259 - accuracy: 0.6364 - val_loss: 0.2395 - val_accuracy: 0.5946\n","Epoch 119/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2192 - accuracy: 0.6364 - val_loss: 0.2393 - val_accuracy: 0.5946\n","Epoch 120/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2355 - accuracy: 0.6364 - val_loss: 0.2395 - val_accuracy: 0.5946\n","Epoch 121/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2271 - accuracy: 0.7273 - val_loss: 0.2398 - val_accuracy: 0.5946\n","Epoch 122/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2294 - accuracy: 0.6364 - val_loss: 0.2404 - val_accuracy: 0.5946\n","Epoch 123/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2181 - accuracy: 0.6364 - val_loss: 0.2411 - val_accuracy: 0.5946\n","Epoch 124/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2304 - accuracy: 0.6364 - val_loss: 0.2416 - val_accuracy: 0.5946\n","Epoch 125/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2235 - accuracy: 0.5455 - val_loss: 0.2414 - val_accuracy: 0.5946\n","Epoch 126/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2166 - accuracy: 0.6364 - val_loss: 0.2410 - val_accuracy: 0.5946\n","Epoch 127/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2285 - accuracy: 0.5455 - val_loss: 0.2404 - val_accuracy: 0.5946\n","Epoch 128/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2267 - accuracy: 0.7273 - val_loss: 0.2400 - val_accuracy: 0.5946\n","Epoch 129/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2241 - accuracy: 0.6364 - val_loss: 0.2398 - val_accuracy: 0.5946\n","Epoch 130/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2601 - accuracy: 0.6364 - val_loss: 0.2400 - val_accuracy: 0.5946\n","2/2 [==============================] - 0s 102ms/step - loss: 0.2400 - accuracy: 0.5946\n","loss :  0.5945945978164673\n","total_loss :  8.48648652434349\n","num :  17\n","WARNING:tensorflow:Layer gru_85 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","WARNING:tensorflow:Layer gru_86 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","WARNING:tensorflow:Layer gru_87 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","WARNING:tensorflow:Layer gru_88 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","WARNING:tensorflow:Layer gru_89 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","Epoch 1/130\n","1/1 [==============================] - 12s 12s/step - loss: 0.3651 - accuracy: 0.6364 - val_loss: 0.4547 - val_accuracy: 0.5135\n","Epoch 2/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.3337 - accuracy: 0.6364 - val_loss: 0.4141 - val_accuracy: 0.5135\n","Epoch 3/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.3086 - accuracy: 0.6364 - val_loss: 0.3686 - val_accuracy: 0.5135\n","Epoch 4/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2728 - accuracy: 0.6364 - val_loss: 0.3219 - val_accuracy: 0.5135\n","Epoch 5/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2367 - accuracy: 0.6364 - val_loss: 0.2795 - val_accuracy: 0.5135\n","Epoch 6/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2338 - accuracy: 0.6364 - val_loss: 0.2561 - val_accuracy: 0.5135\n","Epoch 7/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2492 - accuracy: 0.6364 - val_loss: 0.2544 - val_accuracy: 0.5135\n","Epoch 8/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2445 - accuracy: 0.6364 - val_loss: 0.2596 - val_accuracy: 0.5135\n","Epoch 9/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2296 - accuracy: 0.6364 - val_loss: 0.2699 - val_accuracy: 0.5135\n","Epoch 10/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2353 - accuracy: 0.6364 - val_loss: 0.2831 - val_accuracy: 0.5135\n","Epoch 11/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2253 - accuracy: 0.6364 - val_loss: 0.2953 - val_accuracy: 0.5135\n","Epoch 12/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2214 - accuracy: 0.6364 - val_loss: 0.3046 - val_accuracy: 0.5135\n","Epoch 13/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2192 - accuracy: 0.6364 - val_loss: 0.3092 - val_accuracy: 0.5135\n","Epoch 14/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2326 - accuracy: 0.6364 - val_loss: 0.3104 - val_accuracy: 0.5135\n","Epoch 15/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2269 - accuracy: 0.6364 - val_loss: 0.3081 - val_accuracy: 0.5135\n","Epoch 16/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2248 - accuracy: 0.6364 - val_loss: 0.3032 - val_accuracy: 0.5135\n","Epoch 17/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2118 - accuracy: 0.6364 - val_loss: 0.2956 - val_accuracy: 0.5135\n","Epoch 18/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2270 - accuracy: 0.6364 - val_loss: 0.2885 - val_accuracy: 0.5135\n","Epoch 19/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2277 - accuracy: 0.6364 - val_loss: 0.2835 - val_accuracy: 0.5135\n","Epoch 20/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2396 - accuracy: 0.5455 - val_loss: 0.2824 - val_accuracy: 0.5135\n","Epoch 21/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2224 - accuracy: 0.6364 - val_loss: 0.2848 - val_accuracy: 0.5135\n","Epoch 22/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2112 - accuracy: 0.7273 - val_loss: 0.2885 - val_accuracy: 0.5135\n","Epoch 23/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2189 - accuracy: 0.5455 - val_loss: 0.2945 - val_accuracy: 0.5135\n","Epoch 24/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2046 - accuracy: 0.5455 - val_loss: 0.3009 - val_accuracy: 0.5135\n","Epoch 25/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2143 - accuracy: 0.7273 - val_loss: 0.3072 - val_accuracy: 0.5135\n","Epoch 26/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2265 - accuracy: 0.6364 - val_loss: 0.3114 - val_accuracy: 0.5135\n","Epoch 27/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2267 - accuracy: 0.6364 - val_loss: 0.3152 - val_accuracy: 0.5135\n","Epoch 28/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2065 - accuracy: 0.6364 - val_loss: 0.3161 - val_accuracy: 0.5135\n","Epoch 29/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1967 - accuracy: 0.6364 - val_loss: 0.3143 - val_accuracy: 0.5135\n","Epoch 30/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2118 - accuracy: 0.6364 - val_loss: 0.3123 - val_accuracy: 0.5135\n","Epoch 31/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2030 - accuracy: 0.5455 - val_loss: 0.3105 - val_accuracy: 0.5135\n","Epoch 32/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1972 - accuracy: 0.5455 - val_loss: 0.3118 - val_accuracy: 0.5135\n","Epoch 33/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2241 - accuracy: 0.5455 - val_loss: 0.3188 - val_accuracy: 0.5135\n","Epoch 34/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2360 - accuracy: 0.5455 - val_loss: 0.3318 - val_accuracy: 0.5135\n","Epoch 35/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2070 - accuracy: 0.5455 - val_loss: 0.3416 - val_accuracy: 0.5135\n","Epoch 36/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2059 - accuracy: 0.6364 - val_loss: 0.3483 - val_accuracy: 0.5135\n","Epoch 37/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2156 - accuracy: 0.5455 - val_loss: 0.3508 - val_accuracy: 0.5135\n","Epoch 38/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2215 - accuracy: 0.6364 - val_loss: 0.3509 - val_accuracy: 0.5135\n","Epoch 39/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2224 - accuracy: 0.5455 - val_loss: 0.3482 - val_accuracy: 0.5135\n","Epoch 40/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2003 - accuracy: 0.6364 - val_loss: 0.3444 - val_accuracy: 0.5135\n","Epoch 41/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2130 - accuracy: 0.6364 - val_loss: 0.3401 - val_accuracy: 0.5135\n","Epoch 42/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2415 - accuracy: 0.4545 - val_loss: 0.3433 - val_accuracy: 0.5135\n","Epoch 43/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2162 - accuracy: 0.7273 - val_loss: 0.3491 - val_accuracy: 0.5135\n","Epoch 44/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1886 - accuracy: 0.6364 - val_loss: 0.3566 - val_accuracy: 0.5135\n","Epoch 45/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1970 - accuracy: 0.7273 - val_loss: 0.3629 - val_accuracy: 0.5135\n","Epoch 46/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1986 - accuracy: 0.5455 - val_loss: 0.3678 - val_accuracy: 0.5135\n","Epoch 47/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2057 - accuracy: 0.7273 - val_loss: 0.3682 - val_accuracy: 0.5135\n","Epoch 48/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2006 - accuracy: 0.6364 - val_loss: 0.3664 - val_accuracy: 0.5135\n","Epoch 49/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1740 - accuracy: 0.7273 - val_loss: 0.3663 - val_accuracy: 0.5135\n","Epoch 50/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2193 - accuracy: 0.6364 - val_loss: 0.3693 - val_accuracy: 0.5135\n","Epoch 51/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1894 - accuracy: 0.6364 - val_loss: 0.3741 - val_accuracy: 0.5135\n","Epoch 52/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2055 - accuracy: 0.7273 - val_loss: 0.3779 - val_accuracy: 0.5135\n","Epoch 53/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2184 - accuracy: 0.4545 - val_loss: 0.3812 - val_accuracy: 0.5135\n","Epoch 54/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1894 - accuracy: 0.7273 - val_loss: 0.3871 - val_accuracy: 0.5135\n","Epoch 55/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2218 - accuracy: 0.5455 - val_loss: 0.3940 - val_accuracy: 0.5135\n","Epoch 56/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2190 - accuracy: 0.5455 - val_loss: 0.4002 - val_accuracy: 0.5135\n","Epoch 57/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2151 - accuracy: 0.4545 - val_loss: 0.4042 - val_accuracy: 0.5135\n","Epoch 58/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1929 - accuracy: 0.6364 - val_loss: 0.4042 - val_accuracy: 0.5135\n","Epoch 59/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2228 - accuracy: 0.4545 - val_loss: 0.4015 - val_accuracy: 0.5135\n","Epoch 60/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2035 - accuracy: 0.6364 - val_loss: 0.3984 - val_accuracy: 0.5135\n","Epoch 61/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2042 - accuracy: 0.5455 - val_loss: 0.3964 - val_accuracy: 0.5135\n","Epoch 62/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1803 - accuracy: 0.5455 - val_loss: 0.3985 - val_accuracy: 0.5135\n","Epoch 63/130\n","1/1 [==============================] - 2s 2s/step - loss: 0.1899 - accuracy: 0.7273 - val_loss: 0.4010 - val_accuracy: 0.5135\n","Epoch 64/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2521 - accuracy: 0.4545 - val_loss: 0.4103 - val_accuracy: 0.5135\n","Epoch 65/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2181 - accuracy: 0.5455 - val_loss: 0.4180 - val_accuracy: 0.5135\n","Epoch 66/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1860 - accuracy: 0.7273 - val_loss: 0.4258 - val_accuracy: 0.5135\n","Epoch 67/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2072 - accuracy: 0.6364 - val_loss: 0.4315 - val_accuracy: 0.5135\n","Epoch 68/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1849 - accuracy: 0.6364 - val_loss: 0.4327 - val_accuracy: 0.5135\n","Epoch 69/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2064 - accuracy: 0.5455 - val_loss: 0.4320 - val_accuracy: 0.5135\n","Epoch 70/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2123 - accuracy: 0.5455 - val_loss: 0.4317 - val_accuracy: 0.5135\n","Epoch 71/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1951 - accuracy: 0.6364 - val_loss: 0.4368 - val_accuracy: 0.5135\n","Epoch 72/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1867 - accuracy: 0.6364 - val_loss: 0.4458 - val_accuracy: 0.5135\n","Epoch 73/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1948 - accuracy: 0.5455 - val_loss: 0.4585 - val_accuracy: 0.5135\n","Epoch 74/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2054 - accuracy: 0.6364 - val_loss: 0.4706 - val_accuracy: 0.5135\n","Epoch 75/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1771 - accuracy: 0.6364 - val_loss: 0.4807 - val_accuracy: 0.5135\n","Epoch 76/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2123 - accuracy: 0.4545 - val_loss: 0.4847 - val_accuracy: 0.5135\n","Epoch 77/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2034 - accuracy: 0.4545 - val_loss: 0.4904 - val_accuracy: 0.5135\n","Epoch 78/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1817 - accuracy: 0.6364 - val_loss: 0.5009 - val_accuracy: 0.5135\n","Epoch 79/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1989 - accuracy: 0.5455 - val_loss: 0.5095 - val_accuracy: 0.5135\n","Epoch 80/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1810 - accuracy: 0.6364 - val_loss: 0.5195 - val_accuracy: 0.5135\n","Epoch 81/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1771 - accuracy: 0.7273 - val_loss: 0.5288 - val_accuracy: 0.5135\n","Epoch 82/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1914 - accuracy: 0.6364 - val_loss: 0.5307 - val_accuracy: 0.5135\n","Epoch 83/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1820 - accuracy: 0.6364 - val_loss: 0.5456 - val_accuracy: 0.5135\n","Epoch 84/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1869 - accuracy: 0.6364 - val_loss: 0.5566 - val_accuracy: 0.5135\n","Epoch 85/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2188 - accuracy: 0.5455 - val_loss: 0.5710 - val_accuracy: 0.5135\n","Epoch 86/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1739 - accuracy: 0.8182 - val_loss: 0.5914 - val_accuracy: 0.5135\n","Epoch 87/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1688 - accuracy: 0.8182 - val_loss: 0.6116 - val_accuracy: 0.5135\n","Epoch 88/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2221 - accuracy: 0.5455 - val_loss: 0.6036 - val_accuracy: 0.5135\n","Epoch 89/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1706 - accuracy: 0.8182 - val_loss: 0.6233 - val_accuracy: 0.5135\n","Epoch 90/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1872 - accuracy: 0.6364 - val_loss: 0.6440 - val_accuracy: 0.5135\n","Epoch 91/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2024 - accuracy: 0.5455 - val_loss: 0.6570 - val_accuracy: 0.5135\n","Epoch 92/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1848 - accuracy: 0.6364 - val_loss: 0.6583 - val_accuracy: 0.5135\n","Epoch 93/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1889 - accuracy: 0.6364 - val_loss: 0.6749 - val_accuracy: 0.5135\n","Epoch 94/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1670 - accuracy: 0.7273 - val_loss: 0.7048 - val_accuracy: 0.5135\n","Epoch 95/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1778 - accuracy: 0.5455 - val_loss: 0.7181 - val_accuracy: 0.5135\n","Epoch 96/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2066 - accuracy: 0.5455 - val_loss: 0.7241 - val_accuracy: 0.5135\n","Epoch 97/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1797 - accuracy: 0.7273 - val_loss: 0.6890 - val_accuracy: 0.5135\n","Epoch 98/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1996 - accuracy: 0.5455 - val_loss: 0.6806 - val_accuracy: 0.5135\n","Epoch 99/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1848 - accuracy: 0.6364 - val_loss: 0.6959 - val_accuracy: 0.5135\n","Epoch 100/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1951 - accuracy: 0.5455 - val_loss: 0.7036 - val_accuracy: 0.5135\n","Epoch 101/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1745 - accuracy: 0.8182 - val_loss: 0.6781 - val_accuracy: 0.5135\n","Epoch 102/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1621 - accuracy: 0.8182 - val_loss: 0.6577 - val_accuracy: 0.5135\n","Epoch 103/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1676 - accuracy: 0.8182 - val_loss: 0.6373 - val_accuracy: 0.5135\n","Epoch 104/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1539 - accuracy: 0.9091 - val_loss: 0.6372 - val_accuracy: 0.5135\n","Epoch 105/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1793 - accuracy: 0.6364 - val_loss: 0.6382 - val_accuracy: 0.5135\n","Epoch 106/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1937 - accuracy: 0.7273 - val_loss: 0.6429 - val_accuracy: 0.5135\n","Epoch 107/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2344 - accuracy: 0.5455 - val_loss: 0.6563 - val_accuracy: 0.5135\n","Epoch 108/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2123 - accuracy: 0.4545 - val_loss: 0.6410 - val_accuracy: 0.5135\n","Epoch 109/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2038 - accuracy: 0.6364 - val_loss: 0.6046 - val_accuracy: 0.5135\n","Epoch 110/130\n","1/1 [==============================] - 2s 2s/step - loss: 0.1742 - accuracy: 0.7273 - val_loss: 0.5665 - val_accuracy: 0.5135\n","Epoch 111/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1773 - accuracy: 0.5455 - val_loss: 0.5421 - val_accuracy: 0.5135\n","Epoch 112/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2087 - accuracy: 0.6364 - val_loss: 0.5394 - val_accuracy: 0.5135\n","Epoch 113/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2053 - accuracy: 0.6364 - val_loss: 0.5424 - val_accuracy: 0.5135\n","Epoch 114/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1772 - accuracy: 0.6364 - val_loss: 0.5357 - val_accuracy: 0.5135\n","Epoch 115/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1900 - accuracy: 0.5455 - val_loss: 0.5281 - val_accuracy: 0.5135\n","Epoch 116/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1989 - accuracy: 0.6364 - val_loss: 0.5152 - val_accuracy: 0.5135\n","Epoch 117/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1883 - accuracy: 0.5455 - val_loss: 0.5053 - val_accuracy: 0.5135\n","Epoch 118/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1754 - accuracy: 0.7273 - val_loss: 0.4964 - val_accuracy: 0.5135\n","Epoch 119/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1777 - accuracy: 0.6364 - val_loss: 0.4960 - val_accuracy: 0.5135\n","Epoch 120/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1835 - accuracy: 0.6364 - val_loss: 0.4967 - val_accuracy: 0.5135\n","Epoch 121/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2109 - accuracy: 0.7273 - val_loss: 0.5087 - val_accuracy: 0.5135\n","Epoch 122/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1730 - accuracy: 0.7273 - val_loss: 0.5246 - val_accuracy: 0.5135\n","Epoch 123/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2161 - accuracy: 0.5455 - val_loss: 0.5355 - val_accuracy: 0.5135\n","Epoch 124/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1923 - accuracy: 0.5455 - val_loss: 0.5410 - val_accuracy: 0.5135\n","Epoch 125/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1925 - accuracy: 0.6364 - val_loss: 0.5367 - val_accuracy: 0.5135\n","Epoch 126/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2044 - accuracy: 0.6364 - val_loss: 0.5225 - val_accuracy: 0.5135\n","Epoch 127/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1777 - accuracy: 0.7273 - val_loss: 0.5161 - val_accuracy: 0.5135\n","Epoch 128/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2096 - accuracy: 0.7273 - val_loss: 0.5199 - val_accuracy: 0.5135\n","Epoch 129/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1893 - accuracy: 0.5455 - val_loss: 0.5282 - val_accuracy: 0.5135\n","Epoch 130/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1799 - accuracy: 0.7273 - val_loss: 0.5406 - val_accuracy: 0.5135\n","2/2 [==============================] - 0s 106ms/step - loss: 0.5406 - accuracy: 0.5135\n","loss :  0.5135135054588318\n","total_loss :  9.000000029802322\n","num :  18\n","WARNING:tensorflow:Layer gru_90 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","WARNING:tensorflow:Layer gru_91 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","WARNING:tensorflow:Layer gru_92 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","WARNING:tensorflow:Layer gru_93 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","WARNING:tensorflow:Layer gru_94 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","Epoch 1/130\n","1/1 [==============================] - 13s 13s/step - loss: 0.7140 - accuracy: 0.2727 - val_loss: 0.4570 - val_accuracy: 0.5135\n","Epoch 2/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.6676 - accuracy: 0.2727 - val_loss: 0.4274 - val_accuracy: 0.5135\n","Epoch 3/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.6095 - accuracy: 0.2727 - val_loss: 0.3886 - val_accuracy: 0.5135\n","Epoch 4/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.5267 - accuracy: 0.2727 - val_loss: 0.3422 - val_accuracy: 0.5135\n","Epoch 5/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.4349 - accuracy: 0.2727 - val_loss: 0.2945 - val_accuracy: 0.5135\n","Epoch 6/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.3170 - accuracy: 0.2727 - val_loss: 0.2594 - val_accuracy: 0.5135\n","Epoch 7/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2305 - accuracy: 0.6364 - val_loss: 0.2652 - val_accuracy: 0.4865\n","Epoch 8/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1931 - accuracy: 0.7273 - val_loss: 0.3446 - val_accuracy: 0.4865\n","Epoch 9/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.3219 - accuracy: 0.7273 - val_loss: 0.3429 - val_accuracy: 0.4865\n","Epoch 10/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.3113 - accuracy: 0.7273 - val_loss: 0.3043 - val_accuracy: 0.4865\n","Epoch 11/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2697 - accuracy: 0.7273 - val_loss: 0.2709 - val_accuracy: 0.4865\n","Epoch 12/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1983 - accuracy: 0.7273 - val_loss: 0.2555 - val_accuracy: 0.4865\n","Epoch 13/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1871 - accuracy: 0.7273 - val_loss: 0.2519 - val_accuracy: 0.4595\n","Epoch 14/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2149 - accuracy: 0.7273 - val_loss: 0.2528 - val_accuracy: 0.5135\n","Epoch 15/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2257 - accuracy: 0.7273 - val_loss: 0.2544 - val_accuracy: 0.5135\n","Epoch 16/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2295 - accuracy: 0.7273 - val_loss: 0.2551 - val_accuracy: 0.5135\n","Epoch 17/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2286 - accuracy: 0.7273 - val_loss: 0.2545 - val_accuracy: 0.5135\n","Epoch 18/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2216 - accuracy: 0.7273 - val_loss: 0.2529 - val_accuracy: 0.5135\n","Epoch 19/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2289 - accuracy: 0.7273 - val_loss: 0.2512 - val_accuracy: 0.5135\n","Epoch 20/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2169 - accuracy: 0.7273 - val_loss: 0.2503 - val_accuracy: 0.4054\n","Epoch 21/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2130 - accuracy: 0.7273 - val_loss: 0.2515 - val_accuracy: 0.4865\n","Epoch 22/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2209 - accuracy: 0.6364 - val_loss: 0.2559 - val_accuracy: 0.4865\n","Epoch 23/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1951 - accuracy: 0.7273 - val_loss: 0.2639 - val_accuracy: 0.4865\n","Epoch 24/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1757 - accuracy: 0.7273 - val_loss: 0.2746 - val_accuracy: 0.4865\n","Epoch 25/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2097 - accuracy: 0.7273 - val_loss: 0.2834 - val_accuracy: 0.4865\n","Epoch 26/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2489 - accuracy: 0.7273 - val_loss: 0.2852 - val_accuracy: 0.4865\n","Epoch 27/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2062 - accuracy: 0.7273 - val_loss: 0.2820 - val_accuracy: 0.4865\n","Epoch 28/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2162 - accuracy: 0.7273 - val_loss: 0.2742 - val_accuracy: 0.4865\n","Epoch 29/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2253 - accuracy: 0.7273 - val_loss: 0.2657 - val_accuracy: 0.4865\n","Epoch 30/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2185 - accuracy: 0.7273 - val_loss: 0.2585 - val_accuracy: 0.4865\n","Epoch 31/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1969 - accuracy: 0.7273 - val_loss: 0.2535 - val_accuracy: 0.4865\n","Epoch 32/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1846 - accuracy: 0.7273 - val_loss: 0.2510 - val_accuracy: 0.4865\n","Epoch 33/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1957 - accuracy: 0.7273 - val_loss: 0.2498 - val_accuracy: 0.5405\n","Epoch 34/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2085 - accuracy: 0.7273 - val_loss: 0.2490 - val_accuracy: 0.5676\n","Epoch 35/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2085 - accuracy: 0.7273 - val_loss: 0.2487 - val_accuracy: 0.5405\n","Epoch 36/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2092 - accuracy: 0.7273 - val_loss: 0.2484 - val_accuracy: 0.5405\n","Epoch 37/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2010 - accuracy: 0.7273 - val_loss: 0.2486 - val_accuracy: 0.5405\n","Epoch 38/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2035 - accuracy: 0.7273 - val_loss: 0.2493 - val_accuracy: 0.5135\n","Epoch 39/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1836 - accuracy: 0.7273 - val_loss: 0.2505 - val_accuracy: 0.4865\n","Epoch 40/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1848 - accuracy: 0.7273 - val_loss: 0.2527 - val_accuracy: 0.4865\n","Epoch 41/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1875 - accuracy: 0.7273 - val_loss: 0.2561 - val_accuracy: 0.4865\n","Epoch 42/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1891 - accuracy: 0.7273 - val_loss: 0.2601 - val_accuracy: 0.4865\n","Epoch 43/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1963 - accuracy: 0.7273 - val_loss: 0.2625 - val_accuracy: 0.4865\n","Epoch 44/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2003 - accuracy: 0.7273 - val_loss: 0.2626 - val_accuracy: 0.4865\n","Epoch 45/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2029 - accuracy: 0.7273 - val_loss: 0.2620 - val_accuracy: 0.4865\n","Epoch 46/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2165 - accuracy: 0.7273 - val_loss: 0.2591 - val_accuracy: 0.4865\n","Epoch 47/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1868 - accuracy: 0.7273 - val_loss: 0.2562 - val_accuracy: 0.4865\n","Epoch 48/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1729 - accuracy: 0.7273 - val_loss: 0.2544 - val_accuracy: 0.4865\n","Epoch 49/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2066 - accuracy: 0.7273 - val_loss: 0.2527 - val_accuracy: 0.4865\n","Epoch 50/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1904 - accuracy: 0.7273 - val_loss: 0.2512 - val_accuracy: 0.4865\n","Epoch 51/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1870 - accuracy: 0.7273 - val_loss: 0.2506 - val_accuracy: 0.4865\n","Epoch 52/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2129 - accuracy: 0.7273 - val_loss: 0.2503 - val_accuracy: 0.4865\n","Epoch 53/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2099 - accuracy: 0.7273 - val_loss: 0.2495 - val_accuracy: 0.5135\n","Epoch 54/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1929 - accuracy: 0.7273 - val_loss: 0.2499 - val_accuracy: 0.4865\n","Epoch 55/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1992 - accuracy: 0.7273 - val_loss: 0.2500 - val_accuracy: 0.4865\n","Epoch 56/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1873 - accuracy: 0.7273 - val_loss: 0.2511 - val_accuracy: 0.4865\n","Epoch 57/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1890 - accuracy: 0.7273 - val_loss: 0.2524 - val_accuracy: 0.4865\n","Epoch 58/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1762 - accuracy: 0.7273 - val_loss: 0.2549 - val_accuracy: 0.4865\n","Epoch 59/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1775 - accuracy: 0.7273 - val_loss: 0.2583 - val_accuracy: 0.4865\n","Epoch 60/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2052 - accuracy: 0.7273 - val_loss: 0.2593 - val_accuracy: 0.4865\n","Epoch 61/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1824 - accuracy: 0.7273 - val_loss: 0.2577 - val_accuracy: 0.4865\n","Epoch 62/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1753 - accuracy: 0.7273 - val_loss: 0.2571 - val_accuracy: 0.4865\n","Epoch 63/130\n","1/1 [==============================] - 2s 2s/step - loss: 0.1721 - accuracy: 0.7273 - val_loss: 0.2561 - val_accuracy: 0.4865\n","Epoch 64/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1674 - accuracy: 0.7273 - val_loss: 0.2561 - val_accuracy: 0.4865\n","Epoch 65/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1874 - accuracy: 0.7273 - val_loss: 0.2549 - val_accuracy: 0.4865\n","Epoch 66/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1951 - accuracy: 0.7273 - val_loss: 0.2541 - val_accuracy: 0.4865\n","Epoch 67/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1889 - accuracy: 0.7273 - val_loss: 0.2541 - val_accuracy: 0.4865\n","Epoch 68/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1720 - accuracy: 0.7273 - val_loss: 0.2538 - val_accuracy: 0.5135\n","Epoch 69/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1952 - accuracy: 0.7273 - val_loss: 0.2522 - val_accuracy: 0.5676\n","Epoch 70/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1938 - accuracy: 0.7273 - val_loss: 0.2501 - val_accuracy: 0.5405\n","Epoch 71/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1794 - accuracy: 0.7273 - val_loss: 0.2484 - val_accuracy: 0.5135\n","Epoch 72/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1797 - accuracy: 0.7273 - val_loss: 0.2485 - val_accuracy: 0.5135\n","Epoch 73/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1603 - accuracy: 0.7273 - val_loss: 0.2500 - val_accuracy: 0.5135\n","Epoch 74/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1878 - accuracy: 0.7273 - val_loss: 0.2536 - val_accuracy: 0.5405\n","Epoch 75/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1827 - accuracy: 0.7273 - val_loss: 0.2587 - val_accuracy: 0.5676\n","Epoch 76/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1628 - accuracy: 0.7273 - val_loss: 0.2628 - val_accuracy: 0.5135\n","Epoch 77/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1843 - accuracy: 0.7273 - val_loss: 0.2625 - val_accuracy: 0.5405\n","Epoch 78/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1688 - accuracy: 0.7273 - val_loss: 0.2584 - val_accuracy: 0.5676\n","Epoch 79/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1844 - accuracy: 0.7273 - val_loss: 0.2533 - val_accuracy: 0.5135\n","Epoch 80/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1686 - accuracy: 0.7273 - val_loss: 0.2511 - val_accuracy: 0.5676\n","Epoch 81/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1751 - accuracy: 0.7273 - val_loss: 0.2493 - val_accuracy: 0.5676\n","Epoch 82/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1693 - accuracy: 0.7273 - val_loss: 0.2518 - val_accuracy: 0.5676\n","Epoch 83/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1644 - accuracy: 0.8182 - val_loss: 0.2561 - val_accuracy: 0.5135\n","Epoch 84/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1852 - accuracy: 0.7273 - val_loss: 0.2611 - val_accuracy: 0.5135\n","Epoch 85/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1932 - accuracy: 0.7273 - val_loss: 0.2633 - val_accuracy: 0.5676\n","Epoch 86/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1900 - accuracy: 0.7273 - val_loss: 0.2575 - val_accuracy: 0.5135\n","Epoch 87/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1941 - accuracy: 0.7273 - val_loss: 0.2520 - val_accuracy: 0.5676\n","Epoch 88/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1721 - accuracy: 0.7273 - val_loss: 0.2491 - val_accuracy: 0.5676\n","Epoch 89/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2118 - accuracy: 0.7273 - val_loss: 0.2475 - val_accuracy: 0.5676\n","Epoch 90/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1789 - accuracy: 0.7273 - val_loss: 0.2481 - val_accuracy: 0.5676\n","Epoch 91/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1772 - accuracy: 0.7273 - val_loss: 0.2513 - val_accuracy: 0.5676\n","Epoch 92/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1688 - accuracy: 0.8182 - val_loss: 0.2552 - val_accuracy: 0.5135\n","Epoch 93/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2036 - accuracy: 0.7273 - val_loss: 0.2566 - val_accuracy: 0.5135\n","Epoch 94/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1821 - accuracy: 0.7273 - val_loss: 0.2599 - val_accuracy: 0.5676\n","Epoch 95/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1929 - accuracy: 0.7273 - val_loss: 0.2641 - val_accuracy: 0.5676\n","Epoch 96/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1874 - accuracy: 0.7273 - val_loss: 0.2688 - val_accuracy: 0.5135\n","Epoch 97/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1822 - accuracy: 0.7273 - val_loss: 0.2697 - val_accuracy: 0.5135\n","Epoch 98/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2023 - accuracy: 0.7273 - val_loss: 0.2682 - val_accuracy: 0.5135\n","Epoch 99/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1676 - accuracy: 0.7273 - val_loss: 0.2663 - val_accuracy: 0.5135\n","Epoch 100/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1986 - accuracy: 0.7273 - val_loss: 0.2602 - val_accuracy: 0.5135\n","Epoch 101/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1777 - accuracy: 0.7273 - val_loss: 0.2577 - val_accuracy: 0.5676\n","Epoch 102/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1582 - accuracy: 0.8182 - val_loss: 0.2590 - val_accuracy: 0.5135\n","Epoch 103/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1652 - accuracy: 0.7273 - val_loss: 0.2644 - val_accuracy: 0.4865\n","Epoch 104/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1840 - accuracy: 0.7273 - val_loss: 0.2727 - val_accuracy: 0.4865\n","Epoch 105/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1817 - accuracy: 0.7273 - val_loss: 0.2794 - val_accuracy: 0.4865\n","Epoch 106/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2109 - accuracy: 0.7273 - val_loss: 0.2802 - val_accuracy: 0.4865\n","Epoch 107/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1868 - accuracy: 0.7273 - val_loss: 0.2787 - val_accuracy: 0.4865\n","Epoch 108/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1600 - accuracy: 0.7273 - val_loss: 0.2764 - val_accuracy: 0.4865\n","Epoch 109/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1774 - accuracy: 0.7273 - val_loss: 0.2735 - val_accuracy: 0.4865\n","Epoch 110/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1788 - accuracy: 0.7273 - val_loss: 0.2700 - val_accuracy: 0.4865\n","Epoch 111/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1536 - accuracy: 0.7273 - val_loss: 0.2692 - val_accuracy: 0.4865\n","Epoch 112/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1690 - accuracy: 0.7273 - val_loss: 0.2699 - val_accuracy: 0.4865\n","Epoch 113/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1743 - accuracy: 0.7273 - val_loss: 0.2727 - val_accuracy: 0.4865\n","Epoch 114/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1621 - accuracy: 0.7273 - val_loss: 0.2719 - val_accuracy: 0.4865\n","Epoch 115/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1447 - accuracy: 0.7273 - val_loss: 0.2805 - val_accuracy: 0.4865\n","Epoch 116/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2175 - accuracy: 0.7273 - val_loss: 0.2803 - val_accuracy: 0.4865\n","Epoch 117/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1945 - accuracy: 0.7273 - val_loss: 0.2728 - val_accuracy: 0.4865\n","Epoch 118/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2010 - accuracy: 0.7273 - val_loss: 0.2628 - val_accuracy: 0.4865\n","Epoch 119/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1825 - accuracy: 0.7273 - val_loss: 0.2530 - val_accuracy: 0.5676\n","Epoch 120/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1676 - accuracy: 0.8182 - val_loss: 0.2483 - val_accuracy: 0.5135\n","Epoch 121/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1928 - accuracy: 0.7273 - val_loss: 0.2473 - val_accuracy: 0.5135\n","Epoch 122/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1951 - accuracy: 0.8182 - val_loss: 0.2497 - val_accuracy: 0.5135\n","Epoch 123/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2373 - accuracy: 0.5455 - val_loss: 0.2537 - val_accuracy: 0.5676\n","Epoch 124/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1959 - accuracy: 0.7273 - val_loss: 0.2595 - val_accuracy: 0.4865\n","Epoch 125/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1870 - accuracy: 0.7273 - val_loss: 0.2690 - val_accuracy: 0.4865\n","Epoch 126/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1861 - accuracy: 0.7273 - val_loss: 0.2826 - val_accuracy: 0.4865\n","Epoch 127/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1658 - accuracy: 0.7273 - val_loss: 0.2850 - val_accuracy: 0.4865\n","Epoch 128/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1978 - accuracy: 0.7273 - val_loss: 0.2792 - val_accuracy: 0.4865\n","Epoch 129/130\n","1/1 [==============================] - 2s 2s/step - loss: 0.2006 - accuracy: 0.7273 - val_loss: 0.2727 - val_accuracy: 0.4865\n","Epoch 130/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1798 - accuracy: 0.7273 - val_loss: 0.2702 - val_accuracy: 0.4865\n","2/2 [==============================] - 0s 96ms/step - loss: 0.2702 - accuracy: 0.4865\n","loss :  0.4864864945411682\n","total_loss :  9.48648652434349\n","num :  19\n","WARNING:tensorflow:Layer gru_95 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","WARNING:tensorflow:Layer gru_96 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","WARNING:tensorflow:Layer gru_97 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","WARNING:tensorflow:Layer gru_98 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","WARNING:tensorflow:Layer gru_99 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","Epoch 1/130\n","1/1 [==============================] - 13s 13s/step - loss: 0.3765 - accuracy: 0.6364 - val_loss: 0.6432 - val_accuracy: 0.3243\n","Epoch 2/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.3479 - accuracy: 0.6364 - val_loss: 0.6035 - val_accuracy: 0.3243\n","Epoch 3/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.3215 - accuracy: 0.6364 - val_loss: 0.5624 - val_accuracy: 0.3243\n","Epoch 4/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.3023 - accuracy: 0.6364 - val_loss: 0.5117 - val_accuracy: 0.3243\n","Epoch 5/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2731 - accuracy: 0.6364 - val_loss: 0.4492 - val_accuracy: 0.3243\n","Epoch 6/130\n","1/1 [==============================] - 2s 2s/step - loss: 0.2492 - accuracy: 0.6364 - val_loss: 0.3782 - val_accuracy: 0.3243\n","Epoch 7/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2326 - accuracy: 0.6364 - val_loss: 0.3090 - val_accuracy: 0.3243\n","Epoch 8/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2447 - accuracy: 0.6364 - val_loss: 0.2709 - val_accuracy: 0.2703\n","Epoch 9/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2299 - accuracy: 0.6364 - val_loss: 0.2639 - val_accuracy: 0.3784\n","Epoch 10/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2453 - accuracy: 0.5455 - val_loss: 0.2746 - val_accuracy: 0.3243\n","Epoch 11/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2474 - accuracy: 0.6364 - val_loss: 0.2964 - val_accuracy: 0.3243\n","Epoch 12/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2384 - accuracy: 0.6364 - val_loss: 0.3233 - val_accuracy: 0.3243\n","Epoch 13/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2264 - accuracy: 0.6364 - val_loss: 0.3488 - val_accuracy: 0.3243\n","Epoch 14/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2215 - accuracy: 0.6364 - val_loss: 0.3694 - val_accuracy: 0.3243\n","Epoch 15/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2205 - accuracy: 0.6364 - val_loss: 0.3836 - val_accuracy: 0.3243\n","Epoch 16/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2233 - accuracy: 0.6364 - val_loss: 0.3915 - val_accuracy: 0.3243\n","Epoch 17/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2247 - accuracy: 0.6364 - val_loss: 0.3923 - val_accuracy: 0.3243\n","Epoch 18/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2238 - accuracy: 0.6364 - val_loss: 0.3866 - val_accuracy: 0.3243\n","Epoch 19/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1944 - accuracy: 0.6364 - val_loss: 0.3739 - val_accuracy: 0.3243\n","Epoch 20/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2166 - accuracy: 0.6364 - val_loss: 0.3572 - val_accuracy: 0.3243\n","Epoch 21/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2052 - accuracy: 0.6364 - val_loss: 0.3381 - val_accuracy: 0.3243\n","Epoch 22/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2184 - accuracy: 0.6364 - val_loss: 0.3231 - val_accuracy: 0.3243\n","Epoch 23/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1935 - accuracy: 0.8182 - val_loss: 0.3157 - val_accuracy: 0.3784\n","Epoch 24/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1958 - accuracy: 0.9091 - val_loss: 0.3179 - val_accuracy: 0.3514\n","Epoch 25/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2075 - accuracy: 0.8182 - val_loss: 0.3273 - val_accuracy: 0.3514\n","Epoch 26/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1808 - accuracy: 0.9091 - val_loss: 0.3390 - val_accuracy: 0.3784\n","Epoch 27/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.2015 - accuracy: 0.8182 - val_loss: 0.3516 - val_accuracy: 0.3514\n","Epoch 28/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1937 - accuracy: 0.8182 - val_loss: 0.3653 - val_accuracy: 0.3243\n","Epoch 29/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1989 - accuracy: 0.8182 - val_loss: 0.3759 - val_accuracy: 0.3243\n","Epoch 30/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1737 - accuracy: 0.7273 - val_loss: 0.3812 - val_accuracy: 0.3514\n","Epoch 31/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1540 - accuracy: 0.9091 - val_loss: 0.3871 - val_accuracy: 0.3784\n","Epoch 32/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1759 - accuracy: 0.8182 - val_loss: 0.3943 - val_accuracy: 0.3514\n","Epoch 33/130\n","1/1 [==============================] - 2s 2s/step - loss: 0.1730 - accuracy: 0.8182 - val_loss: 0.4085 - val_accuracy: 0.3784\n","Epoch 34/130\n","1/1 [==============================] - 2s 2s/step - loss: 0.1674 - accuracy: 0.8182 - val_loss: 0.4321 - val_accuracy: 0.4054\n","Epoch 35/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1853 - accuracy: 0.7273 - val_loss: 0.4716 - val_accuracy: 0.4324\n","Epoch 36/130\n","1/1 [==============================] - 2s 2s/step - loss: 0.1584 - accuracy: 0.8182 - val_loss: 0.4909 - val_accuracy: 0.4324\n","Epoch 37/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1628 - accuracy: 0.8182 - val_loss: 0.5045 - val_accuracy: 0.4054\n","Epoch 38/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1348 - accuracy: 0.8182 - val_loss: 0.5037 - val_accuracy: 0.3784\n","Epoch 39/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1514 - accuracy: 0.9091 - val_loss: 0.5188 - val_accuracy: 0.3514\n","Epoch 40/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1443 - accuracy: 0.8182 - val_loss: 0.5630 - val_accuracy: 0.3784\n","Epoch 41/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1216 - accuracy: 0.9091 - val_loss: 0.6478 - val_accuracy: 0.4054\n","Epoch 42/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1730 - accuracy: 0.7273 - val_loss: 0.7765 - val_accuracy: 0.4324\n","Epoch 43/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1254 - accuracy: 0.8182 - val_loss: 1.1087 - val_accuracy: 0.4595\n","Epoch 44/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1348 - accuracy: 0.8182 - val_loss: 1.1587 - val_accuracy: 0.4595\n","Epoch 45/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1717 - accuracy: 0.7273 - val_loss: 1.0478 - val_accuracy: 0.4324\n","Epoch 46/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1552 - accuracy: 0.8182 - val_loss: 0.9142 - val_accuracy: 0.4054\n","Epoch 47/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1234 - accuracy: 0.9091 - val_loss: 0.9265 - val_accuracy: 0.4054\n","Epoch 48/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1003 - accuracy: 0.9091 - val_loss: 0.8988 - val_accuracy: 0.4054\n","Epoch 49/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1847 - accuracy: 0.8182 - val_loss: 0.7547 - val_accuracy: 0.3784\n","Epoch 50/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1830 - accuracy: 0.7273 - val_loss: 0.7286 - val_accuracy: 0.3784\n","Epoch 51/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1469 - accuracy: 0.8182 - val_loss: 0.7542 - val_accuracy: 0.4054\n","Epoch 52/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1856 - accuracy: 0.8182 - val_loss: 0.6659 - val_accuracy: 0.3784\n","Epoch 53/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1943 - accuracy: 0.7273 - val_loss: 0.6303 - val_accuracy: 0.3784\n","Epoch 54/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1762 - accuracy: 0.7273 - val_loss: 0.6313 - val_accuracy: 0.3784\n","Epoch 55/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1341 - accuracy: 0.8182 - val_loss: 0.6662 - val_accuracy: 0.4054\n","Epoch 56/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1399 - accuracy: 0.8182 - val_loss: 0.7343 - val_accuracy: 0.4324\n","Epoch 57/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1428 - accuracy: 0.8182 - val_loss: 0.8294 - val_accuracy: 0.4595\n","Epoch 58/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1057 - accuracy: 0.9091 - val_loss: 0.9319 - val_accuracy: 0.4865\n","Epoch 59/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1221 - accuracy: 0.9091 - val_loss: 0.9417 - val_accuracy: 0.4865\n","Epoch 60/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1287 - accuracy: 0.9091 - val_loss: 0.8295 - val_accuracy: 0.4865\n","Epoch 61/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1520 - accuracy: 0.8182 - val_loss: 0.6612 - val_accuracy: 0.4324\n","Epoch 62/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1381 - accuracy: 0.8182 - val_loss: 0.5654 - val_accuracy: 0.4054\n","Epoch 63/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1466 - accuracy: 0.7273 - val_loss: 0.5170 - val_accuracy: 0.3784\n","Epoch 64/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1373 - accuracy: 0.8182 - val_loss: 0.4992 - val_accuracy: 0.3784\n","Epoch 65/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1980 - accuracy: 0.7273 - val_loss: 0.4898 - val_accuracy: 0.3514\n","Epoch 66/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1646 - accuracy: 0.7273 - val_loss: 0.4894 - val_accuracy: 0.3514\n","Epoch 67/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1600 - accuracy: 0.8182 - val_loss: 0.4977 - val_accuracy: 0.3784\n","Epoch 68/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1504 - accuracy: 0.8182 - val_loss: 0.5207 - val_accuracy: 0.4054\n","Epoch 69/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1315 - accuracy: 0.8182 - val_loss: 0.5550 - val_accuracy: 0.4324\n","Epoch 70/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1600 - accuracy: 0.8182 - val_loss: 0.6190 - val_accuracy: 0.4595\n","Epoch 71/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1105 - accuracy: 0.9091 - val_loss: 0.6798 - val_accuracy: 0.4595\n","Epoch 72/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1539 - accuracy: 0.8182 - val_loss: 0.7466 - val_accuracy: 0.4865\n","Epoch 73/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1759 - accuracy: 0.8182 - val_loss: 0.7148 - val_accuracy: 0.4595\n","Epoch 74/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1702 - accuracy: 0.7273 - val_loss: 0.6587 - val_accuracy: 0.4595\n","Epoch 75/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1465 - accuracy: 0.9091 - val_loss: 0.6121 - val_accuracy: 0.4324\n","Epoch 76/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1331 - accuracy: 0.8182 - val_loss: 0.5729 - val_accuracy: 0.4324\n","Epoch 77/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1129 - accuracy: 0.9091 - val_loss: 0.5590 - val_accuracy: 0.4324\n","Epoch 78/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1504 - accuracy: 0.7273 - val_loss: 0.5601 - val_accuracy: 0.4324\n","Epoch 79/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1123 - accuracy: 0.9091 - val_loss: 0.5703 - val_accuracy: 0.4324\n","Epoch 80/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1205 - accuracy: 0.8182 - val_loss: 0.5863 - val_accuracy: 0.4324\n","Epoch 81/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1391 - accuracy: 0.9091 - val_loss: 0.6231 - val_accuracy: 0.4324\n","Epoch 82/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1573 - accuracy: 0.7273 - val_loss: 0.6736 - val_accuracy: 0.4595\n","Epoch 83/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1224 - accuracy: 0.8182 - val_loss: 0.7623 - val_accuracy: 0.4595\n","Epoch 84/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1180 - accuracy: 0.9091 - val_loss: 0.8345 - val_accuracy: 0.4595\n","Epoch 85/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1459 - accuracy: 0.8182 - val_loss: 0.8897 - val_accuracy: 0.4865\n","Epoch 86/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1269 - accuracy: 0.9091 - val_loss: 0.9423 - val_accuracy: 0.4865\n","Epoch 87/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1004 - accuracy: 0.9091 - val_loss: 0.9995 - val_accuracy: 0.4865\n","Epoch 88/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1340 - accuracy: 0.8182 - val_loss: 0.9515 - val_accuracy: 0.4865\n","Epoch 89/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1671 - accuracy: 0.8182 - val_loss: 0.8392 - val_accuracy: 0.4595\n","Epoch 90/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.0985 - accuracy: 0.9091 - val_loss: 0.7413 - val_accuracy: 0.4595\n","Epoch 91/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1249 - accuracy: 0.8182 - val_loss: 0.6776 - val_accuracy: 0.4324\n","Epoch 92/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1154 - accuracy: 0.9091 - val_loss: 0.6423 - val_accuracy: 0.4324\n","Epoch 93/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1166 - accuracy: 0.8182 - val_loss: 0.6105 - val_accuracy: 0.4324\n","Epoch 94/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1258 - accuracy: 0.8182 - val_loss: 0.6088 - val_accuracy: 0.4324\n","Epoch 95/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1653 - accuracy: 0.7273 - val_loss: 0.6152 - val_accuracy: 0.4324\n","Epoch 96/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1646 - accuracy: 0.7273 - val_loss: 0.6304 - val_accuracy: 0.4324\n","Epoch 97/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1078 - accuracy: 0.9091 - val_loss: 0.6634 - val_accuracy: 0.4324\n","Epoch 98/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1245 - accuracy: 0.9091 - val_loss: 0.7163 - val_accuracy: 0.4595\n","Epoch 99/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1472 - accuracy: 0.8182 - val_loss: 0.7617 - val_accuracy: 0.4595\n","Epoch 100/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1090 - accuracy: 0.9091 - val_loss: 0.7874 - val_accuracy: 0.4595\n","Epoch 101/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1238 - accuracy: 0.9091 - val_loss: 0.8171 - val_accuracy: 0.4865\n","Epoch 102/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1017 - accuracy: 0.9091 - val_loss: 0.8400 - val_accuracy: 0.4865\n","Epoch 103/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1396 - accuracy: 0.8182 - val_loss: 0.8933 - val_accuracy: 0.4865\n","Epoch 104/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1444 - accuracy: 0.9091 - val_loss: 0.8900 - val_accuracy: 0.4865\n","Epoch 105/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1179 - accuracy: 0.8182 - val_loss: 0.8434 - val_accuracy: 0.4865\n","Epoch 106/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1227 - accuracy: 0.9091 - val_loss: 0.7606 - val_accuracy: 0.4595\n","Epoch 107/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1413 - accuracy: 0.7273 - val_loss: 0.7094 - val_accuracy: 0.4595\n","Epoch 108/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1189 - accuracy: 0.8182 - val_loss: 0.6753 - val_accuracy: 0.4595\n","Epoch 109/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.0914 - accuracy: 0.9091 - val_loss: 0.6657 - val_accuracy: 0.4595\n","Epoch 110/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1306 - accuracy: 0.8182 - val_loss: 0.6835 - val_accuracy: 0.4595\n","Epoch 111/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1478 - accuracy: 0.8182 - val_loss: 0.7250 - val_accuracy: 0.4595\n","Epoch 112/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1112 - accuracy: 0.8182 - val_loss: 0.7955 - val_accuracy: 0.4865\n","Epoch 113/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1189 - accuracy: 0.8182 - val_loss: 0.8547 - val_accuracy: 0.4865\n","Epoch 114/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1204 - accuracy: 0.9091 - val_loss: 0.9043 - val_accuracy: 0.4865\n","Epoch 115/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.0991 - accuracy: 0.9091 - val_loss: 0.9394 - val_accuracy: 0.4865\n","Epoch 116/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1385 - accuracy: 0.8182 - val_loss: 0.9386 - val_accuracy: 0.4865\n","Epoch 117/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1858 - accuracy: 0.8182 - val_loss: 0.8639 - val_accuracy: 0.4865\n","Epoch 118/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1639 - accuracy: 0.9091 - val_loss: 0.7402 - val_accuracy: 0.4595\n","Epoch 119/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1105 - accuracy: 0.9091 - val_loss: 0.6807 - val_accuracy: 0.4595\n","Epoch 120/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1008 - accuracy: 0.9091 - val_loss: 0.6408 - val_accuracy: 0.4595\n","Epoch 121/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1452 - accuracy: 0.8182 - val_loss: 0.6360 - val_accuracy: 0.4595\n","Epoch 122/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1217 - accuracy: 0.9091 - val_loss: 0.6472 - val_accuracy: 0.4595\n","Epoch 123/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1333 - accuracy: 0.8182 - val_loss: 0.6933 - val_accuracy: 0.4595\n","Epoch 124/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1095 - accuracy: 0.9091 - val_loss: 0.7617 - val_accuracy: 0.4865\n","Epoch 125/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1369 - accuracy: 0.9091 - val_loss: 0.8664 - val_accuracy: 0.4865\n","Epoch 126/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1143 - accuracy: 0.9091 - val_loss: 0.9549 - val_accuracy: 0.4865\n","Epoch 127/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1356 - accuracy: 0.8182 - val_loss: 0.9891 - val_accuracy: 0.5135\n","Epoch 128/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1460 - accuracy: 0.8182 - val_loss: 0.9643 - val_accuracy: 0.5135\n","Epoch 129/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1119 - accuracy: 0.9091 - val_loss: 0.9675 - val_accuracy: 0.5135\n","Epoch 130/130\n","1/1 [==============================] - 1s 1s/step - loss: 0.1172 - accuracy: 0.9091 - val_loss: 0.9091 - val_accuracy: 0.4865\n","2/2 [==============================] - 0s 120ms/step - loss: 0.9091 - accuracy: 0.4865\n","loss :  0.4864864945411682\n","total_loss :  9.972973018884659\n","num :  20\n"]},{"output_type":"display_data","data":{"text/html":["<br/>Waiting for W&B process to finish, PID 305<br/>Program ended successfully."],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a9d755ee4c3d4c9c847529dca2f83bb8","version_minor":0,"version_major":2},"text/plain":["VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"]},"metadata":{}},{"output_type":"display_data","data":{"text/html":["Find user logs for this run at: <code>/content/wandb/run-20210904_131018-kx6gav3k/logs/debug.log</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"display_data","data":{"text/html":["Find internal logs for this run at: <code>/content/wandb/run-20210904_131018-kx6gav3k/logs/debug-internal.log</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"display_data","data":{"text/html":["<h3>Run summary:</h3><br/><style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n","    </style><table class=\"wandb\">\n","<tr><td>ACCURACY</td><td>0.49865</td></tr><tr><td>_runtime</td><td>4151</td></tr><tr><td>_timestamp</td><td>1630765169</td></tr><tr><td>_step</td><td>0</td></tr></table>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"display_data","data":{"text/html":["<h3>Run history:</h3><br/><style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n","    </style><table class=\"wandb\">\n","<tr><td>ACCURACY</td><td>▁</td></tr><tr><td>_runtime</td><td>▁</td></tr><tr><td>_timestamp</td><td>▁</td></tr><tr><td>_step</td><td>▁</td></tr></table><br/>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"display_data","data":{"text/html":["Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"display_data","data":{"text/html":["\n","                    <br/>Synced <strong style=\"color:#cdcd00\">peachy-sweep-1</strong>: <a href=\"https://wandb.ai/yeongu/index_predict_news_gru_deep_accuracy_dropX_300_COVIDX_sliding_drop_colab/runs/kx6gav3k\" target=\"_blank\">https://wandb.ai/yeongu/index_predict_news_gru_deep_accuracy_dropX_300_COVIDX_sliding_drop_colab/runs/kx6gav3k</a><br/>\n","                "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: yis2aqgz with config:\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 41\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.7827330947711023\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 245\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tfeature: 3\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tnodes: 89\n","\u001b[34m\u001b[1mwandb\u001b[0m: \ttest_size: 26\n","\u001b[34m\u001b[1mwandb\u001b[0m: \ttrain_size: 64\n","\u001b[34m\u001b[1mwandb\u001b[0m: \twindow_size: 52\n"]},{"output_type":"display_data","data":{"text/html":["\n","                Tracking run with wandb version 0.12.1<br/>\n","                Syncing run <strong style=\"color:#cdcd00\">rural-sweep-2</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n","                Project page: <a href=\"https://wandb.ai/yeongu/index_predict_news_gru_deep_accuracy_dropX_300_COVIDX_sliding_drop_colab\" target=\"_blank\">https://wandb.ai/yeongu/index_predict_news_gru_deep_accuracy_dropX_300_COVIDX_sliding_drop_colab</a><br/>\n","                Sweep page: <a href=\"https://wandb.ai/yeongu/index_predict_news_gru_deep_accuracy_dropX_300_COVIDX_sliding_drop_colab/sweeps/oll8rllg\" target=\"_blank\">https://wandb.ai/yeongu/index_predict_news_gru_deep_accuracy_dropX_300_COVIDX_sliding_drop_colab/sweeps/oll8rllg</a><br/>\n","Run page: <a href=\"https://wandb.ai/yeongu/index_predict_news_gru_deep_accuracy_dropX_300_COVIDX_sliding_drop_colab/runs/yis2aqgz\" target=\"_blank\">https://wandb.ai/yeongu/index_predict_news_gru_deep_accuracy_dropX_300_COVIDX_sliding_drop_colab/runs/yis2aqgz</a><br/>\n","                Run data is saved locally in <code>/content/wandb/run-20210904_141936-yis2aqgz</code><br/><br/>\n","            "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["WARNING:tensorflow:Layer gru will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","WARNING:tensorflow:Layer gru_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","WARNING:tensorflow:Layer gru_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","WARNING:tensorflow:Layer gru_3 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","WARNING:tensorflow:Layer gru_4 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","Epoch 1/245\n","2/2 [==============================] - 13s 2s/step - loss: 0.5404 - accuracy: 0.4375 - val_loss: 0.3338 - val_accuracy: 0.6154\n","Epoch 2/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.4039 - accuracy: 0.4375 - val_loss: 0.2836 - val_accuracy: 0.6154\n","Epoch 3/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2767 - accuracy: 0.4531 - val_loss: 0.2485 - val_accuracy: 0.6154\n","Epoch 4/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.3210 - accuracy: 0.5000 - val_loss: 0.2501 - val_accuracy: 0.6154\n","Epoch 5/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2661 - accuracy: 0.5469 - val_loss: 0.2657 - val_accuracy: 0.6154\n","Epoch 6/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2473 - accuracy: 0.5312 - val_loss: 0.2780 - val_accuracy: 0.6154\n","Epoch 7/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2575 - accuracy: 0.5000 - val_loss: 0.2823 - val_accuracy: 0.6154\n","Epoch 8/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2737 - accuracy: 0.4844 - val_loss: 0.2798 - val_accuracy: 0.6154\n","Epoch 9/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2640 - accuracy: 0.4688 - val_loss: 0.2726 - val_accuracy: 0.6154\n","Epoch 10/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2454 - accuracy: 0.5312 - val_loss: 0.2641 - val_accuracy: 0.6154\n","Epoch 11/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2576 - accuracy: 0.4844 - val_loss: 0.2590 - val_accuracy: 0.6154\n","Epoch 12/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2392 - accuracy: 0.5938 - val_loss: 0.2579 - val_accuracy: 0.6154\n","Epoch 13/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2408 - accuracy: 0.5781 - val_loss: 0.2609 - val_accuracy: 0.6154\n","Epoch 14/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2639 - accuracy: 0.5000 - val_loss: 0.2650 - val_accuracy: 0.6154\n","Epoch 15/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2455 - accuracy: 0.5312 - val_loss: 0.2676 - val_accuracy: 0.6154\n","Epoch 16/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2513 - accuracy: 0.5469 - val_loss: 0.2678 - val_accuracy: 0.6154\n","Epoch 17/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2486 - accuracy: 0.5156 - val_loss: 0.2662 - val_accuracy: 0.6154\n","Epoch 18/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2442 - accuracy: 0.5000 - val_loss: 0.2632 - val_accuracy: 0.6154\n","Epoch 19/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2514 - accuracy: 0.5156 - val_loss: 0.2595 - val_accuracy: 0.6154\n","Epoch 20/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2650 - accuracy: 0.5000 - val_loss: 0.2572 - val_accuracy: 0.6154\n","Epoch 21/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2623 - accuracy: 0.5156 - val_loss: 0.2572 - val_accuracy: 0.6154\n","Epoch 22/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2443 - accuracy: 0.5625 - val_loss: 0.2585 - val_accuracy: 0.6154\n","Epoch 23/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2273 - accuracy: 0.5938 - val_loss: 0.2592 - val_accuracy: 0.6154\n","Epoch 24/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2414 - accuracy: 0.6562 - val_loss: 0.2590 - val_accuracy: 0.6154\n","Epoch 25/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2532 - accuracy: 0.5469 - val_loss: 0.2594 - val_accuracy: 0.6154\n","Epoch 26/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2603 - accuracy: 0.4844 - val_loss: 0.2597 - val_accuracy: 0.6154\n","Epoch 27/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2533 - accuracy: 0.5312 - val_loss: 0.2607 - val_accuracy: 0.6154\n","Epoch 28/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2414 - accuracy: 0.6719 - val_loss: 0.2611 - val_accuracy: 0.6154\n","Epoch 29/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2425 - accuracy: 0.6094 - val_loss: 0.2614 - val_accuracy: 0.6154\n","Epoch 30/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2414 - accuracy: 0.5312 - val_loss: 0.2607 - val_accuracy: 0.6154\n","Epoch 31/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2707 - accuracy: 0.4688 - val_loss: 0.2617 - val_accuracy: 0.6154\n","Epoch 32/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2316 - accuracy: 0.6250 - val_loss: 0.2621 - val_accuracy: 0.6154\n","Epoch 33/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2485 - accuracy: 0.5625 - val_loss: 0.2613 - val_accuracy: 0.6154\n","Epoch 34/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2435 - accuracy: 0.6094 - val_loss: 0.2592 - val_accuracy: 0.6154\n","Epoch 35/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2562 - accuracy: 0.5000 - val_loss: 0.2581 - val_accuracy: 0.6154\n","Epoch 36/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2371 - accuracy: 0.5781 - val_loss: 0.2575 - val_accuracy: 0.6154\n","Epoch 37/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2307 - accuracy: 0.6406 - val_loss: 0.2571 - val_accuracy: 0.6154\n","Epoch 38/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2401 - accuracy: 0.5625 - val_loss: 0.2573 - val_accuracy: 0.6154\n","Epoch 39/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2460 - accuracy: 0.5312 - val_loss: 0.2580 - val_accuracy: 0.6154\n","Epoch 40/245\n","2/2 [==============================] - 3s 2s/step - loss: 0.2364 - accuracy: 0.5938 - val_loss: 0.2584 - val_accuracy: 0.6154\n","Epoch 41/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2434 - accuracy: 0.4844 - val_loss: 0.2584 - val_accuracy: 0.6154\n","Epoch 42/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2249 - accuracy: 0.6094 - val_loss: 0.2580 - val_accuracy: 0.6154\n","Epoch 43/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2234 - accuracy: 0.6406 - val_loss: 0.2569 - val_accuracy: 0.6154\n","Epoch 44/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2437 - accuracy: 0.5625 - val_loss: 0.2579 - val_accuracy: 0.6154\n","Epoch 45/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2533 - accuracy: 0.5156 - val_loss: 0.2618 - val_accuracy: 0.6154\n","Epoch 46/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2450 - accuracy: 0.5312 - val_loss: 0.2645 - val_accuracy: 0.6154\n","Epoch 47/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2393 - accuracy: 0.5625 - val_loss: 0.2644 - val_accuracy: 0.6154\n","Epoch 48/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2583 - accuracy: 0.4844 - val_loss: 0.2622 - val_accuracy: 0.6154\n","Epoch 49/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2214 - accuracy: 0.6406 - val_loss: 0.2594 - val_accuracy: 0.6154\n","Epoch 50/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2330 - accuracy: 0.6406 - val_loss: 0.2577 - val_accuracy: 0.6154\n","Epoch 51/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2437 - accuracy: 0.5625 - val_loss: 0.2588 - val_accuracy: 0.6154\n","Epoch 52/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2355 - accuracy: 0.5625 - val_loss: 0.2604 - val_accuracy: 0.6154\n","Epoch 53/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2600 - accuracy: 0.5781 - val_loss: 0.2626 - val_accuracy: 0.6154\n","Epoch 54/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2508 - accuracy: 0.5000 - val_loss: 0.2625 - val_accuracy: 0.6154\n","Epoch 55/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2631 - accuracy: 0.4531 - val_loss: 0.2601 - val_accuracy: 0.6154\n","Epoch 56/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2567 - accuracy: 0.5000 - val_loss: 0.2566 - val_accuracy: 0.6154\n","Epoch 57/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2436 - accuracy: 0.6406 - val_loss: 0.2525 - val_accuracy: 0.6154\n","Epoch 58/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2462 - accuracy: 0.5312 - val_loss: 0.2488 - val_accuracy: 0.6154\n","Epoch 59/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2346 - accuracy: 0.6250 - val_loss: 0.2464 - val_accuracy: 0.6154\n","Epoch 60/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2596 - accuracy: 0.6406 - val_loss: 0.2470 - val_accuracy: 0.6154\n","Epoch 61/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2336 - accuracy: 0.6875 - val_loss: 0.2480 - val_accuracy: 0.6154\n","Epoch 62/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2500 - accuracy: 0.5000 - val_loss: 0.2485 - val_accuracy: 0.6154\n","Epoch 63/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2454 - accuracy: 0.5938 - val_loss: 0.2480 - val_accuracy: 0.6154\n","Epoch 64/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2321 - accuracy: 0.6250 - val_loss: 0.2462 - val_accuracy: 0.6154\n","Epoch 65/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2444 - accuracy: 0.6094 - val_loss: 0.2447 - val_accuracy: 0.6154\n","Epoch 66/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2528 - accuracy: 0.6094 - val_loss: 0.2440 - val_accuracy: 0.6154\n","Epoch 67/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2384 - accuracy: 0.5781 - val_loss: 0.2445 - val_accuracy: 0.6154\n","Epoch 68/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2383 - accuracy: 0.5781 - val_loss: 0.2451 - val_accuracy: 0.6154\n","Epoch 69/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2388 - accuracy: 0.5625 - val_loss: 0.2447 - val_accuracy: 0.6154\n","Epoch 70/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2347 - accuracy: 0.6094 - val_loss: 0.2452 - val_accuracy: 0.6154\n","Epoch 71/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2281 - accuracy: 0.5625 - val_loss: 0.2453 - val_accuracy: 0.6154\n","Epoch 72/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2351 - accuracy: 0.6250 - val_loss: 0.2454 - val_accuracy: 0.6154\n","Epoch 73/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2350 - accuracy: 0.6406 - val_loss: 0.2455 - val_accuracy: 0.6154\n","Epoch 74/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2478 - accuracy: 0.6094 - val_loss: 0.2458 - val_accuracy: 0.6154\n","Epoch 75/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2217 - accuracy: 0.6250 - val_loss: 0.2454 - val_accuracy: 0.6154\n","Epoch 76/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2310 - accuracy: 0.6094 - val_loss: 0.2452 - val_accuracy: 0.6154\n","Epoch 77/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2212 - accuracy: 0.6406 - val_loss: 0.2449 - val_accuracy: 0.6154\n","Epoch 78/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2310 - accuracy: 0.6094 - val_loss: 0.2454 - val_accuracy: 0.6154\n","Epoch 79/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2274 - accuracy: 0.6562 - val_loss: 0.2461 - val_accuracy: 0.6154\n","Epoch 80/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2340 - accuracy: 0.5625 - val_loss: 0.2470 - val_accuracy: 0.6154\n","Epoch 81/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2519 - accuracy: 0.5781 - val_loss: 0.2494 - val_accuracy: 0.6154\n","Epoch 82/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2254 - accuracy: 0.6250 - val_loss: 0.2492 - val_accuracy: 0.6154\n","Epoch 83/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2454 - accuracy: 0.5625 - val_loss: 0.2468 - val_accuracy: 0.6154\n","Epoch 84/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2256 - accuracy: 0.6562 - val_loss: 0.2452 - val_accuracy: 0.6154\n","Epoch 85/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2445 - accuracy: 0.5938 - val_loss: 0.2470 - val_accuracy: 0.6154\n","Epoch 86/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2299 - accuracy: 0.6562 - val_loss: 0.2501 - val_accuracy: 0.6154\n","Epoch 87/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2408 - accuracy: 0.6719 - val_loss: 0.2512 - val_accuracy: 0.6154\n","Epoch 88/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2399 - accuracy: 0.5938 - val_loss: 0.2495 - val_accuracy: 0.6154\n","Epoch 89/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2302 - accuracy: 0.6719 - val_loss: 0.2477 - val_accuracy: 0.6154\n","Epoch 90/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2364 - accuracy: 0.6406 - val_loss: 0.2473 - val_accuracy: 0.6154\n","Epoch 91/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2481 - accuracy: 0.6094 - val_loss: 0.2502 - val_accuracy: 0.6154\n","Epoch 92/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2241 - accuracy: 0.6094 - val_loss: 0.2513 - val_accuracy: 0.6154\n","Epoch 93/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2236 - accuracy: 0.6406 - val_loss: 0.2493 - val_accuracy: 0.6154\n","Epoch 94/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2389 - accuracy: 0.5938 - val_loss: 0.2473 - val_accuracy: 0.6154\n","Epoch 95/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2217 - accuracy: 0.5781 - val_loss: 0.2474 - val_accuracy: 0.6154\n","Epoch 96/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2477 - accuracy: 0.5938 - val_loss: 0.2489 - val_accuracy: 0.6154\n","Epoch 97/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2310 - accuracy: 0.6094 - val_loss: 0.2495 - val_accuracy: 0.6154\n","Epoch 98/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2385 - accuracy: 0.5625 - val_loss: 0.2495 - val_accuracy: 0.6154\n","Epoch 99/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2307 - accuracy: 0.6406 - val_loss: 0.2485 - val_accuracy: 0.6154\n","Epoch 100/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2265 - accuracy: 0.5938 - val_loss: 0.2473 - val_accuracy: 0.6154\n","Epoch 101/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2173 - accuracy: 0.6250 - val_loss: 0.2481 - val_accuracy: 0.6154\n","Epoch 102/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2466 - accuracy: 0.5625 - val_loss: 0.2508 - val_accuracy: 0.6154\n","Epoch 103/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2508 - accuracy: 0.5625 - val_loss: 0.2546 - val_accuracy: 0.6154\n","Epoch 104/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2231 - accuracy: 0.6094 - val_loss: 0.2539 - val_accuracy: 0.6154\n","Epoch 105/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2434 - accuracy: 0.5312 - val_loss: 0.2502 - val_accuracy: 0.6154\n","Epoch 106/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2264 - accuracy: 0.6406 - val_loss: 0.2477 - val_accuracy: 0.6154\n","Epoch 107/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2415 - accuracy: 0.5625 - val_loss: 0.2475 - val_accuracy: 0.6154\n","Epoch 108/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2172 - accuracy: 0.5938 - val_loss: 0.2487 - val_accuracy: 0.6154\n","Epoch 109/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2561 - accuracy: 0.5781 - val_loss: 0.2535 - val_accuracy: 0.6154\n","Epoch 110/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2544 - accuracy: 0.5781 - val_loss: 0.2557 - val_accuracy: 0.6154\n","Epoch 111/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2479 - accuracy: 0.5312 - val_loss: 0.2526 - val_accuracy: 0.6154\n","Epoch 112/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2187 - accuracy: 0.5625 - val_loss: 0.2467 - val_accuracy: 0.6154\n","Epoch 113/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2341 - accuracy: 0.6094 - val_loss: 0.2446 - val_accuracy: 0.6154\n","Epoch 114/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2427 - accuracy: 0.6094 - val_loss: 0.2452 - val_accuracy: 0.6154\n","Epoch 115/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2327 - accuracy: 0.6250 - val_loss: 0.2472 - val_accuracy: 0.6154\n","Epoch 116/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2461 - accuracy: 0.5312 - val_loss: 0.2502 - val_accuracy: 0.6154\n","Epoch 117/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2322 - accuracy: 0.6562 - val_loss: 0.2485 - val_accuracy: 0.6154\n","Epoch 118/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2487 - accuracy: 0.5781 - val_loss: 0.2451 - val_accuracy: 0.6154\n","Epoch 119/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2370 - accuracy: 0.5156 - val_loss: 0.2438 - val_accuracy: 0.6154\n","Epoch 120/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2435 - accuracy: 0.5625 - val_loss: 0.2443 - val_accuracy: 0.6154\n","Epoch 121/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2547 - accuracy: 0.5469 - val_loss: 0.2459 - val_accuracy: 0.6154\n","Epoch 122/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2234 - accuracy: 0.6406 - val_loss: 0.2459 - val_accuracy: 0.6154\n","Epoch 123/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2225 - accuracy: 0.6406 - val_loss: 0.2439 - val_accuracy: 0.6154\n","Epoch 124/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2308 - accuracy: 0.5938 - val_loss: 0.2428 - val_accuracy: 0.6154\n","Epoch 125/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2486 - accuracy: 0.5469 - val_loss: 0.2428 - val_accuracy: 0.6154\n","Epoch 126/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2236 - accuracy: 0.6094 - val_loss: 0.2437 - val_accuracy: 0.6154\n","Epoch 127/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2494 - accuracy: 0.5938 - val_loss: 0.2443 - val_accuracy: 0.6154\n","Epoch 128/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2343 - accuracy: 0.5781 - val_loss: 0.2434 - val_accuracy: 0.6154\n","Epoch 129/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2242 - accuracy: 0.6250 - val_loss: 0.2422 - val_accuracy: 0.6154\n","Epoch 130/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2271 - accuracy: 0.6094 - val_loss: 0.2418 - val_accuracy: 0.6154\n","Epoch 131/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2396 - accuracy: 0.5312 - val_loss: 0.2420 - val_accuracy: 0.6154\n","Epoch 132/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2224 - accuracy: 0.6719 - val_loss: 0.2429 - val_accuracy: 0.6154\n","Epoch 133/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2365 - accuracy: 0.6250 - val_loss: 0.2439 - val_accuracy: 0.6154\n","Epoch 134/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2290 - accuracy: 0.5781 - val_loss: 0.2443 - val_accuracy: 0.6154\n","Epoch 135/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2238 - accuracy: 0.6562 - val_loss: 0.2441 - val_accuracy: 0.6154\n","Epoch 136/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2349 - accuracy: 0.5781 - val_loss: 0.2438 - val_accuracy: 0.6154\n","Epoch 137/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2234 - accuracy: 0.6406 - val_loss: 0.2438 - val_accuracy: 0.6154\n","Epoch 138/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2331 - accuracy: 0.6094 - val_loss: 0.2443 - val_accuracy: 0.6154\n","Epoch 139/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2293 - accuracy: 0.6094 - val_loss: 0.2445 - val_accuracy: 0.6154\n","Epoch 140/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2336 - accuracy: 0.6719 - val_loss: 0.2445 - val_accuracy: 0.6154\n","Epoch 141/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2294 - accuracy: 0.6094 - val_loss: 0.2442 - val_accuracy: 0.6154\n","Epoch 142/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2342 - accuracy: 0.5938 - val_loss: 0.2438 - val_accuracy: 0.6154\n","Epoch 143/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2218 - accuracy: 0.6250 - val_loss: 0.2434 - val_accuracy: 0.6154\n","Epoch 144/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2350 - accuracy: 0.6094 - val_loss: 0.2440 - val_accuracy: 0.6154\n","Epoch 145/245\n","2/2 [==============================] - 3s 2s/step - loss: 0.2330 - accuracy: 0.5625 - val_loss: 0.2442 - val_accuracy: 0.6154\n","Epoch 146/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2366 - accuracy: 0.6406 - val_loss: 0.2445 - val_accuracy: 0.6154\n","Epoch 147/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2344 - accuracy: 0.6094 - val_loss: 0.2443 - val_accuracy: 0.6154\n","Epoch 148/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2379 - accuracy: 0.6094 - val_loss: 0.2436 - val_accuracy: 0.6154\n","Epoch 149/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2293 - accuracy: 0.6094 - val_loss: 0.2432 - val_accuracy: 0.6154\n","Epoch 150/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2286 - accuracy: 0.5781 - val_loss: 0.2431 - val_accuracy: 0.6154\n","Epoch 151/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2275 - accuracy: 0.6719 - val_loss: 0.2436 - val_accuracy: 0.6154\n","Epoch 152/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2177 - accuracy: 0.6406 - val_loss: 0.2447 - val_accuracy: 0.6154\n","Epoch 153/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2462 - accuracy: 0.6094 - val_loss: 0.2456 - val_accuracy: 0.6154\n","Epoch 154/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2370 - accuracy: 0.5781 - val_loss: 0.2463 - val_accuracy: 0.6154\n","Epoch 155/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2440 - accuracy: 0.5625 - val_loss: 0.2462 - val_accuracy: 0.6154\n","Epoch 156/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2081 - accuracy: 0.6719 - val_loss: 0.2456 - val_accuracy: 0.6154\n","Epoch 157/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2447 - accuracy: 0.6094 - val_loss: 0.2449 - val_accuracy: 0.6154\n","Epoch 158/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2253 - accuracy: 0.5938 - val_loss: 0.2440 - val_accuracy: 0.6154\n","Epoch 159/245\n","2/2 [==============================] - 3s 2s/step - loss: 0.2513 - accuracy: 0.5625 - val_loss: 0.2429 - val_accuracy: 0.6154\n","Epoch 160/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2330 - accuracy: 0.6406 - val_loss: 0.2419 - val_accuracy: 0.6154\n","Epoch 161/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2443 - accuracy: 0.5781 - val_loss: 0.2414 - val_accuracy: 0.6154\n","Epoch 162/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2190 - accuracy: 0.7031 - val_loss: 0.2415 - val_accuracy: 0.6154\n","Epoch 163/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2422 - accuracy: 0.5625 - val_loss: 0.2416 - val_accuracy: 0.6154\n","Epoch 164/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2225 - accuracy: 0.6094 - val_loss: 0.2417 - val_accuracy: 0.6154\n","Epoch 165/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2227 - accuracy: 0.6562 - val_loss: 0.2421 - val_accuracy: 0.6154\n","Epoch 166/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2456 - accuracy: 0.6250 - val_loss: 0.2424 - val_accuracy: 0.6154\n","Epoch 167/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2285 - accuracy: 0.6094 - val_loss: 0.2426 - val_accuracy: 0.6154\n","Epoch 168/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2452 - accuracy: 0.5938 - val_loss: 0.2425 - val_accuracy: 0.6154\n","Epoch 169/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2373 - accuracy: 0.5938 - val_loss: 0.2423 - val_accuracy: 0.6154\n","Epoch 170/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2242 - accuracy: 0.6250 - val_loss: 0.2424 - val_accuracy: 0.6154\n","Epoch 171/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2295 - accuracy: 0.5781 - val_loss: 0.2425 - val_accuracy: 0.6154\n","Epoch 172/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2317 - accuracy: 0.5469 - val_loss: 0.2425 - val_accuracy: 0.6154\n","Epoch 173/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2319 - accuracy: 0.6250 - val_loss: 0.2420 - val_accuracy: 0.6154\n","Epoch 174/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2287 - accuracy: 0.6094 - val_loss: 0.2418 - val_accuracy: 0.6154\n","Epoch 175/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2209 - accuracy: 0.6250 - val_loss: 0.2416 - val_accuracy: 0.6154\n","Epoch 176/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2220 - accuracy: 0.6562 - val_loss: 0.2418 - val_accuracy: 0.6154\n","Epoch 177/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2281 - accuracy: 0.6094 - val_loss: 0.2424 - val_accuracy: 0.6154\n","Epoch 178/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2163 - accuracy: 0.6562 - val_loss: 0.2431 - val_accuracy: 0.6154\n","Epoch 179/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2255 - accuracy: 0.5781 - val_loss: 0.2440 - val_accuracy: 0.5769\n","Epoch 180/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2329 - accuracy: 0.5781 - val_loss: 0.2435 - val_accuracy: 0.6154\n","Epoch 181/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2356 - accuracy: 0.5938 - val_loss: 0.2441 - val_accuracy: 0.6154\n","Epoch 182/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2335 - accuracy: 0.6250 - val_loss: 0.2442 - val_accuracy: 0.6154\n","Epoch 183/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2250 - accuracy: 0.6406 - val_loss: 0.2444 - val_accuracy: 0.6154\n","Epoch 184/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2202 - accuracy: 0.6250 - val_loss: 0.2454 - val_accuracy: 0.5769\n","Epoch 185/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2438 - accuracy: 0.6250 - val_loss: 0.2439 - val_accuracy: 0.6154\n","Epoch 186/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2284 - accuracy: 0.6094 - val_loss: 0.2432 - val_accuracy: 0.6154\n","Epoch 187/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2311 - accuracy: 0.5938 - val_loss: 0.2427 - val_accuracy: 0.6154\n","Epoch 188/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2188 - accuracy: 0.6406 - val_loss: 0.2428 - val_accuracy: 0.6154\n","Epoch 189/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2239 - accuracy: 0.6094 - val_loss: 0.2436 - val_accuracy: 0.5769\n","Epoch 190/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2190 - accuracy: 0.6719 - val_loss: 0.2435 - val_accuracy: 0.5769\n","Epoch 191/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2338 - accuracy: 0.6562 - val_loss: 0.2430 - val_accuracy: 0.6154\n","Epoch 192/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2255 - accuracy: 0.5938 - val_loss: 0.2424 - val_accuracy: 0.6154\n","Epoch 193/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2287 - accuracy: 0.6094 - val_loss: 0.2423 - val_accuracy: 0.6154\n","Epoch 194/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2327 - accuracy: 0.6094 - val_loss: 0.2420 - val_accuracy: 0.6154\n","Epoch 195/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2231 - accuracy: 0.7031 - val_loss: 0.2424 - val_accuracy: 0.6154\n","Epoch 196/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2218 - accuracy: 0.5938 - val_loss: 0.2432 - val_accuracy: 0.5769\n","Epoch 197/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2283 - accuracy: 0.5469 - val_loss: 0.2427 - val_accuracy: 0.6154\n","Epoch 198/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2309 - accuracy: 0.6406 - val_loss: 0.2421 - val_accuracy: 0.6154\n","Epoch 199/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2252 - accuracy: 0.6094 - val_loss: 0.2423 - val_accuracy: 0.6154\n","Epoch 200/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2245 - accuracy: 0.6719 - val_loss: 0.2427 - val_accuracy: 0.6154\n","Epoch 201/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2321 - accuracy: 0.5938 - val_loss: 0.2429 - val_accuracy: 0.6154\n","Epoch 202/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2293 - accuracy: 0.6094 - val_loss: 0.2431 - val_accuracy: 0.6154\n","Epoch 203/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2211 - accuracy: 0.6562 - val_loss: 0.2431 - val_accuracy: 0.6154\n","Epoch 204/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2287 - accuracy: 0.5625 - val_loss: 0.2429 - val_accuracy: 0.6154\n","Epoch 205/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2389 - accuracy: 0.5781 - val_loss: 0.2424 - val_accuracy: 0.6154\n","Epoch 206/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2399 - accuracy: 0.6094 - val_loss: 0.2422 - val_accuracy: 0.6154\n","Epoch 207/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2307 - accuracy: 0.6562 - val_loss: 0.2423 - val_accuracy: 0.6154\n","Epoch 208/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2292 - accuracy: 0.5781 - val_loss: 0.2428 - val_accuracy: 0.6154\n","Epoch 209/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2385 - accuracy: 0.5781 - val_loss: 0.2430 - val_accuracy: 0.6154\n","Epoch 210/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2205 - accuracy: 0.6250 - val_loss: 0.2426 - val_accuracy: 0.6154\n","Epoch 211/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2222 - accuracy: 0.6719 - val_loss: 0.2429 - val_accuracy: 0.6154\n","Epoch 212/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2350 - accuracy: 0.6719 - val_loss: 0.2432 - val_accuracy: 0.5769\n","Epoch 213/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2269 - accuracy: 0.6250 - val_loss: 0.2437 - val_accuracy: 0.5769\n","Epoch 214/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2322 - accuracy: 0.5625 - val_loss: 0.2432 - val_accuracy: 0.6154\n","Epoch 215/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2266 - accuracy: 0.6094 - val_loss: 0.2431 - val_accuracy: 0.6154\n","Epoch 216/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2265 - accuracy: 0.6406 - val_loss: 0.2439 - val_accuracy: 0.5769\n","Epoch 217/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2220 - accuracy: 0.6250 - val_loss: 0.2456 - val_accuracy: 0.6154\n","Epoch 218/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2394 - accuracy: 0.6250 - val_loss: 0.2458 - val_accuracy: 0.6154\n","Epoch 219/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2270 - accuracy: 0.6875 - val_loss: 0.2450 - val_accuracy: 0.6154\n","Epoch 220/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2126 - accuracy: 0.6562 - val_loss: 0.2449 - val_accuracy: 0.6154\n","Epoch 221/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2147 - accuracy: 0.6406 - val_loss: 0.2452 - val_accuracy: 0.6154\n","Epoch 222/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2216 - accuracy: 0.5938 - val_loss: 0.2458 - val_accuracy: 0.6154\n","Epoch 223/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2231 - accuracy: 0.6406 - val_loss: 0.2463 - val_accuracy: 0.6154\n","Epoch 224/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2255 - accuracy: 0.5938 - val_loss: 0.2461 - val_accuracy: 0.6154\n","Epoch 225/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2302 - accuracy: 0.5625 - val_loss: 0.2460 - val_accuracy: 0.5769\n","Epoch 226/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2236 - accuracy: 0.5938 - val_loss: 0.2461 - val_accuracy: 0.5769\n","Epoch 227/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2125 - accuracy: 0.5781 - val_loss: 0.2480 - val_accuracy: 0.6154\n","Epoch 228/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2143 - accuracy: 0.6406 - val_loss: 0.2526 - val_accuracy: 0.5385\n","Epoch 229/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2250 - accuracy: 0.6250 - val_loss: 0.2513 - val_accuracy: 0.5769\n","Epoch 230/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2389 - accuracy: 0.6094 - val_loss: 0.2483 - val_accuracy: 0.6154\n","Epoch 231/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2235 - accuracy: 0.6562 - val_loss: 0.2478 - val_accuracy: 0.6154\n","Epoch 232/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2256 - accuracy: 0.6406 - val_loss: 0.2476 - val_accuracy: 0.5769\n","Epoch 233/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2129 - accuracy: 0.6562 - val_loss: 0.2515 - val_accuracy: 0.5385\n","Epoch 234/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2458 - accuracy: 0.5781 - val_loss: 0.2513 - val_accuracy: 0.5385\n","Epoch 235/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2420 - accuracy: 0.5938 - val_loss: 0.2475 - val_accuracy: 0.5769\n","Epoch 236/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2225 - accuracy: 0.6562 - val_loss: 0.2467 - val_accuracy: 0.6154\n","Epoch 237/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2184 - accuracy: 0.6719 - val_loss: 0.2465 - val_accuracy: 0.6154\n","Epoch 238/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2252 - accuracy: 0.6250 - val_loss: 0.2477 - val_accuracy: 0.6154\n","Epoch 239/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2331 - accuracy: 0.6406 - val_loss: 0.2495 - val_accuracy: 0.5769\n","Epoch 240/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2335 - accuracy: 0.5781 - val_loss: 0.2495 - val_accuracy: 0.5769\n","Epoch 241/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2324 - accuracy: 0.6094 - val_loss: 0.2490 - val_accuracy: 0.6154\n","Epoch 242/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2310 - accuracy: 0.5781 - val_loss: 0.2491 - val_accuracy: 0.6154\n","Epoch 243/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2307 - accuracy: 0.6406 - val_loss: 0.2499 - val_accuracy: 0.5769\n","Epoch 244/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2265 - accuracy: 0.6250 - val_loss: 0.2520 - val_accuracy: 0.5769\n","Epoch 245/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2223 - accuracy: 0.5938 - val_loss: 0.2542 - val_accuracy: 0.5385\n","1/1 [==============================] - 0s 96ms/step - loss: 0.2542 - accuracy: 0.5385\n","loss :  0.5384615659713745\n","total_loss :  0.5384615659713745\n","num :  1\n","WARNING:tensorflow:Layer gru_5 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","WARNING:tensorflow:Layer gru_6 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","WARNING:tensorflow:Layer gru_7 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","WARNING:tensorflow:Layer gru_8 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","WARNING:tensorflow:Layer gru_9 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","Epoch 1/245\n","2/2 [==============================] - 12s 2s/step - loss: 0.3745 - accuracy: 0.5625 - val_loss: 0.4231 - val_accuracy: 0.5000\n","Epoch 2/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2865 - accuracy: 0.5000 - val_loss: 0.3536 - val_accuracy: 0.5000\n","Epoch 3/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2786 - accuracy: 0.4062 - val_loss: 0.3450 - val_accuracy: 0.5000\n","Epoch 4/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2599 - accuracy: 0.4688 - val_loss: 0.3646 - val_accuracy: 0.5000\n","Epoch 5/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2468 - accuracy: 0.5625 - val_loss: 0.3771 - val_accuracy: 0.5000\n","Epoch 6/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2714 - accuracy: 0.5156 - val_loss: 0.3777 - val_accuracy: 0.5000\n","Epoch 7/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2633 - accuracy: 0.5625 - val_loss: 0.3692 - val_accuracy: 0.5000\n","Epoch 8/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2576 - accuracy: 0.5781 - val_loss: 0.3534 - val_accuracy: 0.5000\n","Epoch 9/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2448 - accuracy: 0.5625 - val_loss: 0.3335 - val_accuracy: 0.5000\n","Epoch 10/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2444 - accuracy: 0.5938 - val_loss: 0.3171 - val_accuracy: 0.5000\n","Epoch 11/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2501 - accuracy: 0.5000 - val_loss: 0.3156 - val_accuracy: 0.5000\n","Epoch 12/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2592 - accuracy: 0.4844 - val_loss: 0.3229 - val_accuracy: 0.5000\n","Epoch 13/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2487 - accuracy: 0.5625 - val_loss: 0.3294 - val_accuracy: 0.5000\n","Epoch 14/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2545 - accuracy: 0.5625 - val_loss: 0.3317 - val_accuracy: 0.5000\n","Epoch 15/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2600 - accuracy: 0.5156 - val_loss: 0.3300 - val_accuracy: 0.5000\n","Epoch 16/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2363 - accuracy: 0.5938 - val_loss: 0.3217 - val_accuracy: 0.5000\n","Epoch 17/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2419 - accuracy: 0.5469 - val_loss: 0.3111 - val_accuracy: 0.5000\n","Epoch 18/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2319 - accuracy: 0.6406 - val_loss: 0.3003 - val_accuracy: 0.5000\n","Epoch 19/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2635 - accuracy: 0.5156 - val_loss: 0.2994 - val_accuracy: 0.5000\n","Epoch 20/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2444 - accuracy: 0.5781 - val_loss: 0.3060 - val_accuracy: 0.5000\n","Epoch 21/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2581 - accuracy: 0.5156 - val_loss: 0.3127 - val_accuracy: 0.5000\n","Epoch 22/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2531 - accuracy: 0.5625 - val_loss: 0.3147 - val_accuracy: 0.5000\n","Epoch 23/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2561 - accuracy: 0.5781 - val_loss: 0.3130 - val_accuracy: 0.5000\n","Epoch 24/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2506 - accuracy: 0.5625 - val_loss: 0.3055 - val_accuracy: 0.5000\n","Epoch 25/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2573 - accuracy: 0.5156 - val_loss: 0.2985 - val_accuracy: 0.5000\n","Epoch 26/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2527 - accuracy: 0.4844 - val_loss: 0.2954 - val_accuracy: 0.5000\n","Epoch 27/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2322 - accuracy: 0.6250 - val_loss: 0.2915 - val_accuracy: 0.5000\n","Epoch 28/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2363 - accuracy: 0.5938 - val_loss: 0.2862 - val_accuracy: 0.5000\n","Epoch 29/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2324 - accuracy: 0.6719 - val_loss: 0.2841 - val_accuracy: 0.5000\n","Epoch 30/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2488 - accuracy: 0.5000 - val_loss: 0.2869 - val_accuracy: 0.5000\n","Epoch 31/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2348 - accuracy: 0.5625 - val_loss: 0.2916 - val_accuracy: 0.5000\n","Epoch 32/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2341 - accuracy: 0.6562 - val_loss: 0.2921 - val_accuracy: 0.5000\n","Epoch 33/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2612 - accuracy: 0.5000 - val_loss: 0.2910 - val_accuracy: 0.5000\n","Epoch 34/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2379 - accuracy: 0.5781 - val_loss: 0.2868 - val_accuracy: 0.5000\n","Epoch 35/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2346 - accuracy: 0.5781 - val_loss: 0.2805 - val_accuracy: 0.5000\n","Epoch 36/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2400 - accuracy: 0.5781 - val_loss: 0.2801 - val_accuracy: 0.5000\n","Epoch 37/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2433 - accuracy: 0.5781 - val_loss: 0.2836 - val_accuracy: 0.5000\n","Epoch 38/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2412 - accuracy: 0.5469 - val_loss: 0.2868 - val_accuracy: 0.5000\n","Epoch 39/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2472 - accuracy: 0.5781 - val_loss: 0.2879 - val_accuracy: 0.5000\n","Epoch 40/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2420 - accuracy: 0.6250 - val_loss: 0.2879 - val_accuracy: 0.5000\n","Epoch 41/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2395 - accuracy: 0.5312 - val_loss: 0.2838 - val_accuracy: 0.5000\n","Epoch 42/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2302 - accuracy: 0.6250 - val_loss: 0.2745 - val_accuracy: 0.5000\n","Epoch 43/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2458 - accuracy: 0.5312 - val_loss: 0.2730 - val_accuracy: 0.5000\n","Epoch 44/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2444 - accuracy: 0.5469 - val_loss: 0.2813 - val_accuracy: 0.5000\n","Epoch 45/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2426 - accuracy: 0.6094 - val_loss: 0.2891 - val_accuracy: 0.5000\n","Epoch 46/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2368 - accuracy: 0.6250 - val_loss: 0.2853 - val_accuracy: 0.5000\n","Epoch 47/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2413 - accuracy: 0.6719 - val_loss: 0.2758 - val_accuracy: 0.5000\n","Epoch 48/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2353 - accuracy: 0.6094 - val_loss: 0.2690 - val_accuracy: 0.5000\n","Epoch 49/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2456 - accuracy: 0.6094 - val_loss: 0.2698 - val_accuracy: 0.5000\n","Epoch 50/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2448 - accuracy: 0.5625 - val_loss: 0.2743 - val_accuracy: 0.5000\n","Epoch 51/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2520 - accuracy: 0.5469 - val_loss: 0.2788 - val_accuracy: 0.5000\n","Epoch 52/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2470 - accuracy: 0.5625 - val_loss: 0.2756 - val_accuracy: 0.5000\n","Epoch 53/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2398 - accuracy: 0.6094 - val_loss: 0.2693 - val_accuracy: 0.5000\n","Epoch 54/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2180 - accuracy: 0.7188 - val_loss: 0.2639 - val_accuracy: 0.5000\n","Epoch 55/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2283 - accuracy: 0.5625 - val_loss: 0.2640 - val_accuracy: 0.5000\n","Epoch 56/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2542 - accuracy: 0.5781 - val_loss: 0.2726 - val_accuracy: 0.5000\n","Epoch 57/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2429 - accuracy: 0.5781 - val_loss: 0.2762 - val_accuracy: 0.5000\n","Epoch 58/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2462 - accuracy: 0.5625 - val_loss: 0.2723 - val_accuracy: 0.5000\n","Epoch 59/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2307 - accuracy: 0.6406 - val_loss: 0.2638 - val_accuracy: 0.5000\n","Epoch 60/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2474 - accuracy: 0.5156 - val_loss: 0.2631 - val_accuracy: 0.5000\n","Epoch 61/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2292 - accuracy: 0.6719 - val_loss: 0.2639 - val_accuracy: 0.5000\n","Epoch 62/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2113 - accuracy: 0.6719 - val_loss: 0.2644 - val_accuracy: 0.5000\n","Epoch 63/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2540 - accuracy: 0.5156 - val_loss: 0.2649 - val_accuracy: 0.5000\n","Epoch 64/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2210 - accuracy: 0.6094 - val_loss: 0.2623 - val_accuracy: 0.5000\n","Epoch 65/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2505 - accuracy: 0.5781 - val_loss: 0.2643 - val_accuracy: 0.5000\n","Epoch 66/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2486 - accuracy: 0.5625 - val_loss: 0.2661 - val_accuracy: 0.5000\n","Epoch 67/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2345 - accuracy: 0.6406 - val_loss: 0.2670 - val_accuracy: 0.5000\n","Epoch 68/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2403 - accuracy: 0.5625 - val_loss: 0.2630 - val_accuracy: 0.5000\n","Epoch 69/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2424 - accuracy: 0.6406 - val_loss: 0.2617 - val_accuracy: 0.5000\n","Epoch 70/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2458 - accuracy: 0.5781 - val_loss: 0.2639 - val_accuracy: 0.5000\n","Epoch 71/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2451 - accuracy: 0.5625 - val_loss: 0.2707 - val_accuracy: 0.5000\n","Epoch 72/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2412 - accuracy: 0.5938 - val_loss: 0.2760 - val_accuracy: 0.5000\n","Epoch 73/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2483 - accuracy: 0.5781 - val_loss: 0.2738 - val_accuracy: 0.5000\n","Epoch 74/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2406 - accuracy: 0.5781 - val_loss: 0.2695 - val_accuracy: 0.5000\n","Epoch 75/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2377 - accuracy: 0.5469 - val_loss: 0.2645 - val_accuracy: 0.4615\n","Epoch 76/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2403 - accuracy: 0.5312 - val_loss: 0.2643 - val_accuracy: 0.4231\n","Epoch 77/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2349 - accuracy: 0.6406 - val_loss: 0.2681 - val_accuracy: 0.5000\n","Epoch 78/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2481 - accuracy: 0.6094 - val_loss: 0.2720 - val_accuracy: 0.5000\n","Epoch 79/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2279 - accuracy: 0.5938 - val_loss: 0.2691 - val_accuracy: 0.5000\n","Epoch 80/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2261 - accuracy: 0.6094 - val_loss: 0.2639 - val_accuracy: 0.5000\n","Epoch 81/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2458 - accuracy: 0.4531 - val_loss: 0.2624 - val_accuracy: 0.3846\n","Epoch 82/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2310 - accuracy: 0.6719 - val_loss: 0.2631 - val_accuracy: 0.3462\n","Epoch 83/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2572 - accuracy: 0.5625 - val_loss: 0.2665 - val_accuracy: 0.5000\n","Epoch 84/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2477 - accuracy: 0.5781 - val_loss: 0.2682 - val_accuracy: 0.5000\n","Epoch 85/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2231 - accuracy: 0.5781 - val_loss: 0.2655 - val_accuracy: 0.5000\n","Epoch 86/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2296 - accuracy: 0.6250 - val_loss: 0.2647 - val_accuracy: 0.3846\n","Epoch 87/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2464 - accuracy: 0.6250 - val_loss: 0.2650 - val_accuracy: 0.3846\n","Epoch 88/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2389 - accuracy: 0.6094 - val_loss: 0.2653 - val_accuracy: 0.4615\n","Epoch 89/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2338 - accuracy: 0.6406 - val_loss: 0.2654 - val_accuracy: 0.4231\n","Epoch 90/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2376 - accuracy: 0.5625 - val_loss: 0.2646 - val_accuracy: 0.3846\n","Epoch 91/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2446 - accuracy: 0.5625 - val_loss: 0.2644 - val_accuracy: 0.3846\n","Epoch 92/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2338 - accuracy: 0.5469 - val_loss: 0.2643 - val_accuracy: 0.3846\n","Epoch 93/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2455 - accuracy: 0.5938 - val_loss: 0.2642 - val_accuracy: 0.3846\n","Epoch 94/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2372 - accuracy: 0.5781 - val_loss: 0.2644 - val_accuracy: 0.3846\n","Epoch 95/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2342 - accuracy: 0.6094 - val_loss: 0.2638 - val_accuracy: 0.4231\n","Epoch 96/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2296 - accuracy: 0.6250 - val_loss: 0.2647 - val_accuracy: 0.5000\n","Epoch 97/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2266 - accuracy: 0.6719 - val_loss: 0.2664 - val_accuracy: 0.4231\n","Epoch 98/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2253 - accuracy: 0.6094 - val_loss: 0.2681 - val_accuracy: 0.4231\n","Epoch 99/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2386 - accuracy: 0.6250 - val_loss: 0.2691 - val_accuracy: 0.4615\n","Epoch 100/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2423 - accuracy: 0.5312 - val_loss: 0.2696 - val_accuracy: 0.4231\n","Epoch 101/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2256 - accuracy: 0.6562 - val_loss: 0.2712 - val_accuracy: 0.4615\n","Epoch 102/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2507 - accuracy: 0.5781 - val_loss: 0.2717 - val_accuracy: 0.4231\n","Epoch 103/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2272 - accuracy: 0.6562 - val_loss: 0.2697 - val_accuracy: 0.3462\n","Epoch 104/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2375 - accuracy: 0.6250 - val_loss: 0.2706 - val_accuracy: 0.4231\n","Epoch 105/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2389 - accuracy: 0.5781 - val_loss: 0.2697 - val_accuracy: 0.4231\n","Epoch 106/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2203 - accuracy: 0.6719 - val_loss: 0.2710 - val_accuracy: 0.4615\n","Epoch 107/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2365 - accuracy: 0.6094 - val_loss: 0.2725 - val_accuracy: 0.4231\n","Epoch 108/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2573 - accuracy: 0.5156 - val_loss: 0.2700 - val_accuracy: 0.4615\n","Epoch 109/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2318 - accuracy: 0.6250 - val_loss: 0.2692 - val_accuracy: 0.4231\n","Epoch 110/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2244 - accuracy: 0.6719 - val_loss: 0.2690 - val_accuracy: 0.4231\n","Epoch 111/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2523 - accuracy: 0.5312 - val_loss: 0.2709 - val_accuracy: 0.4615\n","Epoch 112/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2300 - accuracy: 0.5938 - val_loss: 0.2735 - val_accuracy: 0.4615\n","Epoch 113/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2314 - accuracy: 0.6406 - val_loss: 0.2751 - val_accuracy: 0.4615\n","Epoch 114/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2068 - accuracy: 0.6719 - val_loss: 0.2773 - val_accuracy: 0.4615\n","Epoch 115/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2270 - accuracy: 0.6250 - val_loss: 0.2818 - val_accuracy: 0.4231\n","Epoch 116/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2406 - accuracy: 0.5938 - val_loss: 0.2827 - val_accuracy: 0.4231\n","Epoch 117/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2295 - accuracy: 0.6094 - val_loss: 0.2875 - val_accuracy: 0.4231\n","Epoch 118/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2397 - accuracy: 0.6250 - val_loss: 0.2887 - val_accuracy: 0.4231\n","Epoch 119/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2484 - accuracy: 0.5625 - val_loss: 0.2814 - val_accuracy: 0.4231\n","Epoch 120/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2372 - accuracy: 0.5938 - val_loss: 0.2783 - val_accuracy: 0.3846\n","Epoch 121/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2322 - accuracy: 0.6094 - val_loss: 0.2813 - val_accuracy: 0.4231\n","Epoch 122/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2511 - accuracy: 0.6094 - val_loss: 0.2837 - val_accuracy: 0.4615\n","Epoch 123/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2333 - accuracy: 0.6094 - val_loss: 0.2813 - val_accuracy: 0.4231\n","Epoch 124/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2276 - accuracy: 0.6875 - val_loss: 0.2820 - val_accuracy: 0.4615\n","Epoch 125/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2133 - accuracy: 0.6875 - val_loss: 0.2853 - val_accuracy: 0.4231\n","Epoch 126/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2436 - accuracy: 0.5938 - val_loss: 0.2815 - val_accuracy: 0.3846\n","Epoch 127/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2307 - accuracy: 0.6406 - val_loss: 0.2801 - val_accuracy: 0.3846\n","Epoch 128/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2347 - accuracy: 0.5312 - val_loss: 0.2817 - val_accuracy: 0.4231\n","Epoch 129/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2328 - accuracy: 0.6250 - val_loss: 0.2847 - val_accuracy: 0.4615\n","Epoch 130/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2353 - accuracy: 0.6406 - val_loss: 0.2872 - val_accuracy: 0.4615\n","Epoch 131/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2312 - accuracy: 0.6562 - val_loss: 0.2849 - val_accuracy: 0.4231\n","Epoch 132/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2474 - accuracy: 0.6094 - val_loss: 0.2766 - val_accuracy: 0.4231\n","Epoch 133/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2305 - accuracy: 0.6406 - val_loss: 0.2745 - val_accuracy: 0.3846\n","Epoch 134/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2368 - accuracy: 0.5469 - val_loss: 0.2738 - val_accuracy: 0.3846\n","Epoch 135/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2309 - accuracy: 0.6562 - val_loss: 0.2762 - val_accuracy: 0.4231\n","Epoch 136/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2181 - accuracy: 0.6250 - val_loss: 0.2804 - val_accuracy: 0.4231\n","Epoch 137/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2497 - accuracy: 0.5781 - val_loss: 0.2744 - val_accuracy: 0.4231\n","Epoch 138/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2356 - accuracy: 0.6094 - val_loss: 0.2731 - val_accuracy: 0.4231\n","Epoch 139/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2388 - accuracy: 0.5781 - val_loss: 0.2720 - val_accuracy: 0.3462\n","Epoch 140/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2205 - accuracy: 0.6406 - val_loss: 0.2739 - val_accuracy: 0.4231\n","Epoch 141/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2243 - accuracy: 0.6250 - val_loss: 0.2758 - val_accuracy: 0.4615\n","Epoch 142/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2192 - accuracy: 0.6562 - val_loss: 0.2772 - val_accuracy: 0.4615\n","Epoch 143/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2170 - accuracy: 0.7344 - val_loss: 0.2776 - val_accuracy: 0.4231\n","Epoch 144/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2342 - accuracy: 0.5938 - val_loss: 0.2759 - val_accuracy: 0.3462\n","Epoch 145/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2354 - accuracy: 0.5938 - val_loss: 0.2760 - val_accuracy: 0.3846\n","Epoch 146/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2316 - accuracy: 0.6562 - val_loss: 0.2752 - val_accuracy: 0.3846\n","Epoch 147/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2483 - accuracy: 0.5469 - val_loss: 0.2743 - val_accuracy: 0.3462\n","Epoch 148/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2289 - accuracy: 0.6562 - val_loss: 0.2735 - val_accuracy: 0.3846\n","Epoch 149/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2161 - accuracy: 0.6562 - val_loss: 0.2740 - val_accuracy: 0.3846\n","Epoch 150/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2422 - accuracy: 0.5781 - val_loss: 0.2713 - val_accuracy: 0.4231\n","Epoch 151/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2187 - accuracy: 0.6562 - val_loss: 0.2703 - val_accuracy: 0.4231\n","Epoch 152/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2274 - accuracy: 0.6875 - val_loss: 0.2718 - val_accuracy: 0.3846\n","Epoch 153/245\n","2/2 [==============================] - 3s 2s/step - loss: 0.2252 - accuracy: 0.6719 - val_loss: 0.2777 - val_accuracy: 0.4615\n","Epoch 154/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2269 - accuracy: 0.6250 - val_loss: 0.2777 - val_accuracy: 0.4615\n","Epoch 155/245\n","2/2 [==============================] - 3s 2s/step - loss: 0.2414 - accuracy: 0.5781 - val_loss: 0.2767 - val_accuracy: 0.4231\n","Epoch 156/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2238 - accuracy: 0.6406 - val_loss: 0.2788 - val_accuracy: 0.4231\n","Epoch 157/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2259 - accuracy: 0.6406 - val_loss: 0.2892 - val_accuracy: 0.4231\n","Epoch 158/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2303 - accuracy: 0.6719 - val_loss: 0.2967 - val_accuracy: 0.4231\n","Epoch 159/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2148 - accuracy: 0.6562 - val_loss: 0.2982 - val_accuracy: 0.4615\n","Epoch 160/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2469 - accuracy: 0.5938 - val_loss: 0.2925 - val_accuracy: 0.4231\n","Epoch 161/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2208 - accuracy: 0.7031 - val_loss: 0.2950 - val_accuracy: 0.4231\n","Epoch 162/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2280 - accuracy: 0.6406 - val_loss: 0.2919 - val_accuracy: 0.3846\n","Epoch 163/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2090 - accuracy: 0.6562 - val_loss: 0.2921 - val_accuracy: 0.4231\n","Epoch 164/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2527 - accuracy: 0.5625 - val_loss: 0.2848 - val_accuracy: 0.3846\n","Epoch 165/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2067 - accuracy: 0.6562 - val_loss: 0.2846 - val_accuracy: 0.3462\n","Epoch 166/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2339 - accuracy: 0.7031 - val_loss: 0.2874 - val_accuracy: 0.3846\n","Epoch 167/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2389 - accuracy: 0.5938 - val_loss: 0.2875 - val_accuracy: 0.3846\n","Epoch 168/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2390 - accuracy: 0.5312 - val_loss: 0.2868 - val_accuracy: 0.3846\n","Epoch 169/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2168 - accuracy: 0.6719 - val_loss: 0.2879 - val_accuracy: 0.3846\n","Epoch 170/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2258 - accuracy: 0.6250 - val_loss: 0.2939 - val_accuracy: 0.3846\n","Epoch 171/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2212 - accuracy: 0.6094 - val_loss: 0.2933 - val_accuracy: 0.3846\n","Epoch 172/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2203 - accuracy: 0.6719 - val_loss: 0.2851 - val_accuracy: 0.3846\n","Epoch 173/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2268 - accuracy: 0.6406 - val_loss: 0.2829 - val_accuracy: 0.3462\n","Epoch 174/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2240 - accuracy: 0.6406 - val_loss: 0.2833 - val_accuracy: 0.3846\n","Epoch 175/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2252 - accuracy: 0.6094 - val_loss: 0.2906 - val_accuracy: 0.3846\n","Epoch 176/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2394 - accuracy: 0.5938 - val_loss: 0.2924 - val_accuracy: 0.4231\n","Epoch 177/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2375 - accuracy: 0.6250 - val_loss: 0.2866 - val_accuracy: 0.4231\n","Epoch 178/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2030 - accuracy: 0.6406 - val_loss: 0.2847 - val_accuracy: 0.3846\n","Epoch 179/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2370 - accuracy: 0.6250 - val_loss: 0.2858 - val_accuracy: 0.3846\n","Epoch 180/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2301 - accuracy: 0.6094 - val_loss: 0.2872 - val_accuracy: 0.4231\n","Epoch 181/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2341 - accuracy: 0.6094 - val_loss: 0.2838 - val_accuracy: 0.3846\n","Epoch 182/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2384 - accuracy: 0.6719 - val_loss: 0.2779 - val_accuracy: 0.3846\n","Epoch 183/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2169 - accuracy: 0.6719 - val_loss: 0.2771 - val_accuracy: 0.4231\n","Epoch 184/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2595 - accuracy: 0.5469 - val_loss: 0.2753 - val_accuracy: 0.3846\n","Epoch 185/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2447 - accuracy: 0.5938 - val_loss: 0.2740 - val_accuracy: 0.3846\n","Epoch 186/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2350 - accuracy: 0.5938 - val_loss: 0.2770 - val_accuracy: 0.3462\n","Epoch 187/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2339 - accuracy: 0.6250 - val_loss: 0.2770 - val_accuracy: 0.4231\n","Epoch 188/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2270 - accuracy: 0.6406 - val_loss: 0.2764 - val_accuracy: 0.3846\n","Epoch 189/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2275 - accuracy: 0.5938 - val_loss: 0.2775 - val_accuracy: 0.3462\n","Epoch 190/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2413 - accuracy: 0.5938 - val_loss: 0.2773 - val_accuracy: 0.3462\n","Epoch 191/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2291 - accuracy: 0.6094 - val_loss: 0.2758 - val_accuracy: 0.3462\n","Epoch 192/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2272 - accuracy: 0.6250 - val_loss: 0.2749 - val_accuracy: 0.3846\n","Epoch 193/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2385 - accuracy: 0.5938 - val_loss: 0.2743 - val_accuracy: 0.4231\n","Epoch 194/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2300 - accuracy: 0.6406 - val_loss: 0.2734 - val_accuracy: 0.3846\n","Epoch 195/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2316 - accuracy: 0.6406 - val_loss: 0.2737 - val_accuracy: 0.3462\n","Epoch 196/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2244 - accuracy: 0.6094 - val_loss: 0.2744 - val_accuracy: 0.3462\n","Epoch 197/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2314 - accuracy: 0.6094 - val_loss: 0.2750 - val_accuracy: 0.3846\n","Epoch 198/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2281 - accuracy: 0.6719 - val_loss: 0.2759 - val_accuracy: 0.3846\n","Epoch 199/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2388 - accuracy: 0.6094 - val_loss: 0.2733 - val_accuracy: 0.4231\n","Epoch 200/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2254 - accuracy: 0.6562 - val_loss: 0.2719 - val_accuracy: 0.3462\n","Epoch 201/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2296 - accuracy: 0.6250 - val_loss: 0.2717 - val_accuracy: 0.3462\n","Epoch 202/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2253 - accuracy: 0.6250 - val_loss: 0.2728 - val_accuracy: 0.4231\n","Epoch 203/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2353 - accuracy: 0.6562 - val_loss: 0.2751 - val_accuracy: 0.3846\n","Epoch 204/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2378 - accuracy: 0.5625 - val_loss: 0.2759 - val_accuracy: 0.3846\n","Epoch 205/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2284 - accuracy: 0.6719 - val_loss: 0.2751 - val_accuracy: 0.4231\n","Epoch 206/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2529 - accuracy: 0.5625 - val_loss: 0.2752 - val_accuracy: 0.3846\n","Epoch 207/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2405 - accuracy: 0.5781 - val_loss: 0.2758 - val_accuracy: 0.3846\n","Epoch 208/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2292 - accuracy: 0.6094 - val_loss: 0.2766 - val_accuracy: 0.3846\n","Epoch 209/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2330 - accuracy: 0.6094 - val_loss: 0.2786 - val_accuracy: 0.4231\n","Epoch 210/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2213 - accuracy: 0.6875 - val_loss: 0.2803 - val_accuracy: 0.3846\n","Epoch 211/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2232 - accuracy: 0.6406 - val_loss: 0.2796 - val_accuracy: 0.4231\n","Epoch 212/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2320 - accuracy: 0.6406 - val_loss: 0.2795 - val_accuracy: 0.3846\n","Epoch 213/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2214 - accuracy: 0.6406 - val_loss: 0.2806 - val_accuracy: 0.3846\n","Epoch 214/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2361 - accuracy: 0.5781 - val_loss: 0.2821 - val_accuracy: 0.4231\n","Epoch 215/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2416 - accuracy: 0.6094 - val_loss: 0.2808 - val_accuracy: 0.4231\n","Epoch 216/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2364 - accuracy: 0.6250 - val_loss: 0.2781 - val_accuracy: 0.4231\n","Epoch 217/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2232 - accuracy: 0.6094 - val_loss: 0.2770 - val_accuracy: 0.4231\n","Epoch 218/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2309 - accuracy: 0.6719 - val_loss: 0.2771 - val_accuracy: 0.4231\n","Epoch 219/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2336 - accuracy: 0.6250 - val_loss: 0.2757 - val_accuracy: 0.4231\n","Epoch 220/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2265 - accuracy: 0.6406 - val_loss: 0.2754 - val_accuracy: 0.3846\n","Epoch 221/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2368 - accuracy: 0.5625 - val_loss: 0.2756 - val_accuracy: 0.4231\n","Epoch 222/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2273 - accuracy: 0.6406 - val_loss: 0.2778 - val_accuracy: 0.4231\n","Epoch 223/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2327 - accuracy: 0.6094 - val_loss: 0.2770 - val_accuracy: 0.4615\n","Epoch 224/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2265 - accuracy: 0.5625 - val_loss: 0.2759 - val_accuracy: 0.4615\n","Epoch 225/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2298 - accuracy: 0.6406 - val_loss: 0.2777 - val_accuracy: 0.4231\n","Epoch 226/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2254 - accuracy: 0.6406 - val_loss: 0.2794 - val_accuracy: 0.4615\n","Epoch 227/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2413 - accuracy: 0.5781 - val_loss: 0.2786 - val_accuracy: 0.4231\n","Epoch 228/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2515 - accuracy: 0.5781 - val_loss: 0.2807 - val_accuracy: 0.4231\n","Epoch 229/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2411 - accuracy: 0.5781 - val_loss: 0.2834 - val_accuracy: 0.3846\n","Epoch 230/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2285 - accuracy: 0.6406 - val_loss: 0.2887 - val_accuracy: 0.4615\n","Epoch 231/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2246 - accuracy: 0.6250 - val_loss: 0.2910 - val_accuracy: 0.4615\n","Epoch 232/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2244 - accuracy: 0.6406 - val_loss: 0.2869 - val_accuracy: 0.4615\n","Epoch 233/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2327 - accuracy: 0.6875 - val_loss: 0.2803 - val_accuracy: 0.3846\n","Epoch 234/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2197 - accuracy: 0.6719 - val_loss: 0.2790 - val_accuracy: 0.4231\n","Epoch 235/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2218 - accuracy: 0.6719 - val_loss: 0.2809 - val_accuracy: 0.4231\n","Epoch 236/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2172 - accuracy: 0.6875 - val_loss: 0.2866 - val_accuracy: 0.4231\n","Epoch 237/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.1961 - accuracy: 0.7656 - val_loss: 0.3028 - val_accuracy: 0.4231\n","Epoch 238/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2104 - accuracy: 0.7500 - val_loss: 0.3174 - val_accuracy: 0.4231\n","Epoch 239/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2215 - accuracy: 0.6562 - val_loss: 0.3134 - val_accuracy: 0.4231\n","Epoch 240/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2345 - accuracy: 0.5938 - val_loss: 0.3033 - val_accuracy: 0.4615\n","Epoch 241/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2392 - accuracy: 0.6406 - val_loss: 0.2958 - val_accuracy: 0.3846\n","Epoch 242/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2206 - accuracy: 0.6094 - val_loss: 0.2948 - val_accuracy: 0.4231\n","Epoch 243/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2318 - accuracy: 0.6094 - val_loss: 0.3005 - val_accuracy: 0.4615\n","Epoch 244/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2290 - accuracy: 0.5781 - val_loss: 0.3088 - val_accuracy: 0.4231\n","Epoch 245/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2241 - accuracy: 0.6094 - val_loss: 0.3095 - val_accuracy: 0.4231\n","1/1 [==============================] - 0s 107ms/step - loss: 0.3095 - accuracy: 0.4231\n","loss :  0.42307692766189575\n","total_loss :  0.9615384936332703\n","num :  2\n","WARNING:tensorflow:Layer gru_10 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","WARNING:tensorflow:Layer gru_11 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","WARNING:tensorflow:Layer gru_12 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","WARNING:tensorflow:Layer gru_13 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","WARNING:tensorflow:Layer gru_14 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","Epoch 1/245\n","2/2 [==============================] - 13s 2s/step - loss: 0.4678 - accuracy: 0.5000 - val_loss: 0.2954 - val_accuracy: 0.6538\n","Epoch 2/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.3218 - accuracy: 0.5000 - val_loss: 0.2439 - val_accuracy: 0.6538\n","Epoch 3/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2570 - accuracy: 0.5938 - val_loss: 0.2287 - val_accuracy: 0.6538\n","Epoch 4/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.3028 - accuracy: 0.4844 - val_loss: 0.2342 - val_accuracy: 0.6538\n","Epoch 5/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2865 - accuracy: 0.3750 - val_loss: 0.2479 - val_accuracy: 0.6538\n","Epoch 6/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2590 - accuracy: 0.5156 - val_loss: 0.2572 - val_accuracy: 0.6538\n","Epoch 7/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2767 - accuracy: 0.4688 - val_loss: 0.2582 - val_accuracy: 0.6538\n","Epoch 8/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2633 - accuracy: 0.4844 - val_loss: 0.2533 - val_accuracy: 0.6538\n","Epoch 9/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2544 - accuracy: 0.5156 - val_loss: 0.2450 - val_accuracy: 0.6538\n","Epoch 10/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2467 - accuracy: 0.5156 - val_loss: 0.2372 - val_accuracy: 0.6538\n","Epoch 11/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2527 - accuracy: 0.5781 - val_loss: 0.2333 - val_accuracy: 0.6538\n","Epoch 12/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2520 - accuracy: 0.5781 - val_loss: 0.2323 - val_accuracy: 0.6538\n","Epoch 13/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2495 - accuracy: 0.5781 - val_loss: 0.2330 - val_accuracy: 0.6538\n","Epoch 14/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2389 - accuracy: 0.5469 - val_loss: 0.2353 - val_accuracy: 0.6538\n","Epoch 15/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2535 - accuracy: 0.5469 - val_loss: 0.2377 - val_accuracy: 0.6538\n","Epoch 16/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2460 - accuracy: 0.5781 - val_loss: 0.2383 - val_accuracy: 0.6538\n","Epoch 17/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2618 - accuracy: 0.4375 - val_loss: 0.2376 - val_accuracy: 0.6538\n","Epoch 18/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2449 - accuracy: 0.5156 - val_loss: 0.2363 - val_accuracy: 0.6538\n","Epoch 19/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2498 - accuracy: 0.5000 - val_loss: 0.2351 - val_accuracy: 0.6538\n","Epoch 20/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2535 - accuracy: 0.5156 - val_loss: 0.2337 - val_accuracy: 0.6538\n","Epoch 21/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2556 - accuracy: 0.4844 - val_loss: 0.2334 - val_accuracy: 0.6538\n","Epoch 22/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2532 - accuracy: 0.5312 - val_loss: 0.2328 - val_accuracy: 0.6538\n","Epoch 23/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2336 - accuracy: 0.5312 - val_loss: 0.2326 - val_accuracy: 0.6538\n","Epoch 24/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2582 - accuracy: 0.4688 - val_loss: 0.2334 - val_accuracy: 0.6538\n","Epoch 25/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2296 - accuracy: 0.6875 - val_loss: 0.2341 - val_accuracy: 0.6538\n","Epoch 26/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2430 - accuracy: 0.5625 - val_loss: 0.2344 - val_accuracy: 0.6538\n","Epoch 27/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2427 - accuracy: 0.5000 - val_loss: 0.2336 - val_accuracy: 0.6538\n","Epoch 28/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2618 - accuracy: 0.4375 - val_loss: 0.2327 - val_accuracy: 0.6538\n","Epoch 29/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2497 - accuracy: 0.5625 - val_loss: 0.2325 - val_accuracy: 0.6538\n","Epoch 30/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2625 - accuracy: 0.4375 - val_loss: 0.2327 - val_accuracy: 0.6538\n","Epoch 31/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2512 - accuracy: 0.4844 - val_loss: 0.2338 - val_accuracy: 0.6538\n","Epoch 32/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2291 - accuracy: 0.6406 - val_loss: 0.2335 - val_accuracy: 0.6538\n","Epoch 33/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2499 - accuracy: 0.5000 - val_loss: 0.2323 - val_accuracy: 0.6538\n","Epoch 34/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2567 - accuracy: 0.5312 - val_loss: 0.2316 - val_accuracy: 0.6538\n","Epoch 35/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2332 - accuracy: 0.6094 - val_loss: 0.2319 - val_accuracy: 0.6538\n","Epoch 36/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2528 - accuracy: 0.5156 - val_loss: 0.2336 - val_accuracy: 0.6538\n","Epoch 37/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2414 - accuracy: 0.5625 - val_loss: 0.2334 - val_accuracy: 0.6538\n","Epoch 38/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2490 - accuracy: 0.5000 - val_loss: 0.2321 - val_accuracy: 0.6538\n","Epoch 39/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2596 - accuracy: 0.5469 - val_loss: 0.2311 - val_accuracy: 0.6538\n","Epoch 40/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2512 - accuracy: 0.5469 - val_loss: 0.2309 - val_accuracy: 0.6538\n","Epoch 41/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2477 - accuracy: 0.5625 - val_loss: 0.2311 - val_accuracy: 0.6538\n","Epoch 42/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2413 - accuracy: 0.6094 - val_loss: 0.2298 - val_accuracy: 0.6538\n","Epoch 43/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2671 - accuracy: 0.5156 - val_loss: 0.2306 - val_accuracy: 0.6538\n","Epoch 44/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2468 - accuracy: 0.5781 - val_loss: 0.2327 - val_accuracy: 0.6538\n","Epoch 45/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2442 - accuracy: 0.6094 - val_loss: 0.2334 - val_accuracy: 0.6538\n","Epoch 46/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2401 - accuracy: 0.5938 - val_loss: 0.2324 - val_accuracy: 0.6538\n","Epoch 47/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2311 - accuracy: 0.6562 - val_loss: 0.2304 - val_accuracy: 0.6538\n","Epoch 48/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2432 - accuracy: 0.5938 - val_loss: 0.2284 - val_accuracy: 0.6538\n","Epoch 49/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2440 - accuracy: 0.5938 - val_loss: 0.2278 - val_accuracy: 0.6538\n","Epoch 50/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2650 - accuracy: 0.5000 - val_loss: 0.2297 - val_accuracy: 0.6538\n","Epoch 51/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2537 - accuracy: 0.5000 - val_loss: 0.2321 - val_accuracy: 0.6538\n","Epoch 52/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2366 - accuracy: 0.5781 - val_loss: 0.2323 - val_accuracy: 0.6538\n","Epoch 53/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2584 - accuracy: 0.5312 - val_loss: 0.2315 - val_accuracy: 0.6538\n","Epoch 54/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2301 - accuracy: 0.6562 - val_loss: 0.2293 - val_accuracy: 0.6538\n","Epoch 55/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2432 - accuracy: 0.5625 - val_loss: 0.2273 - val_accuracy: 0.6538\n","Epoch 56/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2583 - accuracy: 0.5000 - val_loss: 0.2272 - val_accuracy: 0.6538\n","Epoch 57/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2430 - accuracy: 0.6406 - val_loss: 0.2269 - val_accuracy: 0.6538\n","Epoch 58/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2484 - accuracy: 0.5625 - val_loss: 0.2273 - val_accuracy: 0.6538\n","Epoch 59/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2360 - accuracy: 0.5625 - val_loss: 0.2285 - val_accuracy: 0.6538\n","Epoch 60/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2386 - accuracy: 0.6406 - val_loss: 0.2306 - val_accuracy: 0.6538\n","Epoch 61/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2433 - accuracy: 0.5156 - val_loss: 0.2308 - val_accuracy: 0.6538\n","Epoch 62/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2556 - accuracy: 0.5000 - val_loss: 0.2287 - val_accuracy: 0.6538\n","Epoch 63/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2413 - accuracy: 0.5312 - val_loss: 0.2257 - val_accuracy: 0.6538\n","Epoch 64/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2464 - accuracy: 0.5312 - val_loss: 0.2245 - val_accuracy: 0.6538\n","Epoch 65/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2439 - accuracy: 0.5625 - val_loss: 0.2256 - val_accuracy: 0.6538\n","Epoch 66/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2531 - accuracy: 0.4688 - val_loss: 0.2270 - val_accuracy: 0.6538\n","Epoch 67/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2531 - accuracy: 0.5000 - val_loss: 0.2268 - val_accuracy: 0.6538\n","Epoch 68/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2500 - accuracy: 0.5938 - val_loss: 0.2261 - val_accuracy: 0.6538\n","Epoch 69/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2449 - accuracy: 0.5781 - val_loss: 0.2247 - val_accuracy: 0.6538\n","Epoch 70/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2367 - accuracy: 0.5781 - val_loss: 0.2223 - val_accuracy: 0.6538\n","Epoch 71/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2382 - accuracy: 0.6094 - val_loss: 0.2208 - val_accuracy: 0.6538\n","Epoch 72/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2477 - accuracy: 0.5156 - val_loss: 0.2215 - val_accuracy: 0.6538\n","Epoch 73/245\n","2/2 [==============================] - 3s 2s/step - loss: 0.2425 - accuracy: 0.5000 - val_loss: 0.2234 - val_accuracy: 0.6538\n","Epoch 74/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2431 - accuracy: 0.5156 - val_loss: 0.2245 - val_accuracy: 0.6538\n","Epoch 75/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2492 - accuracy: 0.5000 - val_loss: 0.2244 - val_accuracy: 0.6538\n","Epoch 76/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2636 - accuracy: 0.5000 - val_loss: 0.2241 - val_accuracy: 0.6538\n","Epoch 77/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2363 - accuracy: 0.6406 - val_loss: 0.2233 - val_accuracy: 0.6538\n","Epoch 78/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2588 - accuracy: 0.4844 - val_loss: 0.2232 - val_accuracy: 0.6538\n","Epoch 79/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2641 - accuracy: 0.4375 - val_loss: 0.2233 - val_accuracy: 0.6538\n","Epoch 80/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2611 - accuracy: 0.5000 - val_loss: 0.2224 - val_accuracy: 0.6538\n","Epoch 81/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2584 - accuracy: 0.5625 - val_loss: 0.2218 - val_accuracy: 0.6538\n","Epoch 82/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2386 - accuracy: 0.5625 - val_loss: 0.2209 - val_accuracy: 0.6538\n","Epoch 83/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2436 - accuracy: 0.5781 - val_loss: 0.2205 - val_accuracy: 0.6538\n","Epoch 84/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2349 - accuracy: 0.6094 - val_loss: 0.2206 - val_accuracy: 0.6538\n","Epoch 85/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2341 - accuracy: 0.6719 - val_loss: 0.2204 - val_accuracy: 0.6538\n","Epoch 86/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2372 - accuracy: 0.6875 - val_loss: 0.2198 - val_accuracy: 0.6538\n","Epoch 87/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2508 - accuracy: 0.5625 - val_loss: 0.2198 - val_accuracy: 0.6538\n","Epoch 88/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2513 - accuracy: 0.5000 - val_loss: 0.2205 - val_accuracy: 0.6538\n","Epoch 89/245\n","2/2 [==============================] - 3s 2s/step - loss: 0.2450 - accuracy: 0.5000 - val_loss: 0.2213 - val_accuracy: 0.6538\n","Epoch 90/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2518 - accuracy: 0.4688 - val_loss: 0.2216 - val_accuracy: 0.6538\n","Epoch 91/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2383 - accuracy: 0.6250 - val_loss: 0.2208 - val_accuracy: 0.6538\n","Epoch 92/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2217 - accuracy: 0.6562 - val_loss: 0.2196 - val_accuracy: 0.6538\n","Epoch 93/245\n","2/2 [==============================] - 3s 2s/step - loss: 0.2333 - accuracy: 0.5625 - val_loss: 0.2196 - val_accuracy: 0.6538\n","Epoch 94/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2395 - accuracy: 0.5625 - val_loss: 0.2202 - val_accuracy: 0.6538\n","Epoch 95/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2460 - accuracy: 0.5625 - val_loss: 0.2212 - val_accuracy: 0.6538\n","Epoch 96/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2330 - accuracy: 0.5938 - val_loss: 0.2217 - val_accuracy: 0.6538\n","Epoch 97/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2500 - accuracy: 0.5469 - val_loss: 0.2220 - val_accuracy: 0.6538\n","Epoch 98/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2522 - accuracy: 0.4531 - val_loss: 0.2223 - val_accuracy: 0.6538\n","Epoch 99/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2430 - accuracy: 0.5938 - val_loss: 0.2213 - val_accuracy: 0.6538\n","Epoch 100/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2564 - accuracy: 0.5312 - val_loss: 0.2210 - val_accuracy: 0.6538\n","Epoch 101/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2614 - accuracy: 0.6094 - val_loss: 0.2212 - val_accuracy: 0.6538\n","Epoch 102/245\n","2/2 [==============================] - 3s 2s/step - loss: 0.2470 - accuracy: 0.5781 - val_loss: 0.2207 - val_accuracy: 0.6538\n","Epoch 103/245\n","2/2 [==============================] - 3s 2s/step - loss: 0.2349 - accuracy: 0.6094 - val_loss: 0.2190 - val_accuracy: 0.6538\n","Epoch 104/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2529 - accuracy: 0.6094 - val_loss: 0.2184 - val_accuracy: 0.6538\n","Epoch 105/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2404 - accuracy: 0.6562 - val_loss: 0.2186 - val_accuracy: 0.6538\n","Epoch 106/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2244 - accuracy: 0.6562 - val_loss: 0.2186 - val_accuracy: 0.6538\n","Epoch 107/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2419 - accuracy: 0.5156 - val_loss: 0.2185 - val_accuracy: 0.6538\n","Epoch 108/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2441 - accuracy: 0.5469 - val_loss: 0.2185 - val_accuracy: 0.6538\n","Epoch 109/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2376 - accuracy: 0.6250 - val_loss: 0.2183 - val_accuracy: 0.6538\n","Epoch 110/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2434 - accuracy: 0.5469 - val_loss: 0.2181 - val_accuracy: 0.6538\n","Epoch 111/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2373 - accuracy: 0.5469 - val_loss: 0.2184 - val_accuracy: 0.6538\n","Epoch 112/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2510 - accuracy: 0.5312 - val_loss: 0.2187 - val_accuracy: 0.6538\n","Epoch 113/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2440 - accuracy: 0.5625 - val_loss: 0.2186 - val_accuracy: 0.6538\n","Epoch 114/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2289 - accuracy: 0.6250 - val_loss: 0.2180 - val_accuracy: 0.6538\n","Epoch 115/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2468 - accuracy: 0.4844 - val_loss: 0.2178 - val_accuracy: 0.6538\n","Epoch 116/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2526 - accuracy: 0.5781 - val_loss: 0.2181 - val_accuracy: 0.6538\n","Epoch 117/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2560 - accuracy: 0.5312 - val_loss: 0.2183 - val_accuracy: 0.6538\n","Epoch 118/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2346 - accuracy: 0.6250 - val_loss: 0.2179 - val_accuracy: 0.6538\n","Epoch 119/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2333 - accuracy: 0.6250 - val_loss: 0.2175 - val_accuracy: 0.6538\n","Epoch 120/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2352 - accuracy: 0.5312 - val_loss: 0.2173 - val_accuracy: 0.6538\n","Epoch 121/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2240 - accuracy: 0.5938 - val_loss: 0.2168 - val_accuracy: 0.6538\n","Epoch 122/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2406 - accuracy: 0.6719 - val_loss: 0.2164 - val_accuracy: 0.6538\n","Epoch 123/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2526 - accuracy: 0.4531 - val_loss: 0.2165 - val_accuracy: 0.6538\n","Epoch 124/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2521 - accuracy: 0.5781 - val_loss: 0.2166 - val_accuracy: 0.6538\n","Epoch 125/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2428 - accuracy: 0.5625 - val_loss: 0.2165 - val_accuracy: 0.6538\n","Epoch 126/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2290 - accuracy: 0.6406 - val_loss: 0.2171 - val_accuracy: 0.6923\n","Epoch 127/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2609 - accuracy: 0.5000 - val_loss: 0.2167 - val_accuracy: 0.6538\n","Epoch 128/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2418 - accuracy: 0.5938 - val_loss: 0.2164 - val_accuracy: 0.6538\n","Epoch 129/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2569 - accuracy: 0.5156 - val_loss: 0.2179 - val_accuracy: 0.6538\n","Epoch 130/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2521 - accuracy: 0.5625 - val_loss: 0.2179 - val_accuracy: 0.6538\n","Epoch 131/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2467 - accuracy: 0.5781 - val_loss: 0.2175 - val_accuracy: 0.6538\n","Epoch 132/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2345 - accuracy: 0.6094 - val_loss: 0.2177 - val_accuracy: 0.6538\n","Epoch 133/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2400 - accuracy: 0.4844 - val_loss: 0.2177 - val_accuracy: 0.6538\n","Epoch 134/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2344 - accuracy: 0.6250 - val_loss: 0.2178 - val_accuracy: 0.6538\n","Epoch 135/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2538 - accuracy: 0.5625 - val_loss: 0.2181 - val_accuracy: 0.6538\n","Epoch 136/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2500 - accuracy: 0.5312 - val_loss: 0.2184 - val_accuracy: 0.6538\n","Epoch 137/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2400 - accuracy: 0.5938 - val_loss: 0.2181 - val_accuracy: 0.6538\n","Epoch 138/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2417 - accuracy: 0.5781 - val_loss: 0.2184 - val_accuracy: 0.6538\n","Epoch 139/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2542 - accuracy: 0.5625 - val_loss: 0.2189 - val_accuracy: 0.6538\n","Epoch 140/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2674 - accuracy: 0.4844 - val_loss: 0.2181 - val_accuracy: 0.6538\n","Epoch 141/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2395 - accuracy: 0.6094 - val_loss: 0.2188 - val_accuracy: 0.6538\n","Epoch 142/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2474 - accuracy: 0.5625 - val_loss: 0.2192 - val_accuracy: 0.6538\n","Epoch 143/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2387 - accuracy: 0.5781 - val_loss: 0.2188 - val_accuracy: 0.6538\n","Epoch 144/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2356 - accuracy: 0.6406 - val_loss: 0.2191 - val_accuracy: 0.6538\n","Epoch 145/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2427 - accuracy: 0.6250 - val_loss: 0.2201 - val_accuracy: 0.6538\n","Epoch 146/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2282 - accuracy: 0.5625 - val_loss: 0.2197 - val_accuracy: 0.6538\n","Epoch 147/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2387 - accuracy: 0.6094 - val_loss: 0.2185 - val_accuracy: 0.6538\n","Epoch 148/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2368 - accuracy: 0.6094 - val_loss: 0.2179 - val_accuracy: 0.6538\n","Epoch 149/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2387 - accuracy: 0.5469 - val_loss: 0.2176 - val_accuracy: 0.6538\n","Epoch 150/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2435 - accuracy: 0.5469 - val_loss: 0.2172 - val_accuracy: 0.6538\n","Epoch 151/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2315 - accuracy: 0.5938 - val_loss: 0.2171 - val_accuracy: 0.6538\n","Epoch 152/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2314 - accuracy: 0.6406 - val_loss: 0.2164 - val_accuracy: 0.6538\n","Epoch 153/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2447 - accuracy: 0.5156 - val_loss: 0.2163 - val_accuracy: 0.6538\n","Epoch 154/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2390 - accuracy: 0.5625 - val_loss: 0.2175 - val_accuracy: 0.6538\n","Epoch 155/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2404 - accuracy: 0.5781 - val_loss: 0.2181 - val_accuracy: 0.6538\n","Epoch 156/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2425 - accuracy: 0.6250 - val_loss: 0.2172 - val_accuracy: 0.6538\n","Epoch 157/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2327 - accuracy: 0.5469 - val_loss: 0.2165 - val_accuracy: 0.6538\n","Epoch 158/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2393 - accuracy: 0.5938 - val_loss: 0.2167 - val_accuracy: 0.6538\n","Epoch 159/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2355 - accuracy: 0.5625 - val_loss: 0.2168 - val_accuracy: 0.6538\n","Epoch 160/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2360 - accuracy: 0.5938 - val_loss: 0.2168 - val_accuracy: 0.6538\n","Epoch 161/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2521 - accuracy: 0.5156 - val_loss: 0.2177 - val_accuracy: 0.6538\n","Epoch 162/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2407 - accuracy: 0.6094 - val_loss: 0.2195 - val_accuracy: 0.6538\n","Epoch 163/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2418 - accuracy: 0.5000 - val_loss: 0.2205 - val_accuracy: 0.6538\n","Epoch 164/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2528 - accuracy: 0.5469 - val_loss: 0.2199 - val_accuracy: 0.6538\n","Epoch 165/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2370 - accuracy: 0.6094 - val_loss: 0.2197 - val_accuracy: 0.6538\n","Epoch 166/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2423 - accuracy: 0.5938 - val_loss: 0.2204 - val_accuracy: 0.6538\n","Epoch 167/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2526 - accuracy: 0.5312 - val_loss: 0.2206 - val_accuracy: 0.6538\n","Epoch 168/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2310 - accuracy: 0.6562 - val_loss: 0.2202 - val_accuracy: 0.6538\n","Epoch 169/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2437 - accuracy: 0.5625 - val_loss: 0.2195 - val_accuracy: 0.6538\n","Epoch 170/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2424 - accuracy: 0.5469 - val_loss: 0.2186 - val_accuracy: 0.6538\n","Epoch 171/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2308 - accuracy: 0.6562 - val_loss: 0.2175 - val_accuracy: 0.6538\n","Epoch 172/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2491 - accuracy: 0.4688 - val_loss: 0.2170 - val_accuracy: 0.6538\n","Epoch 173/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2420 - accuracy: 0.5625 - val_loss: 0.2165 - val_accuracy: 0.6538\n","Epoch 174/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2516 - accuracy: 0.5938 - val_loss: 0.2163 - val_accuracy: 0.6538\n","Epoch 175/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2390 - accuracy: 0.5781 - val_loss: 0.2165 - val_accuracy: 0.6538\n","Epoch 176/245\n","2/2 [==============================] - 3s 2s/step - loss: 0.2519 - accuracy: 0.5781 - val_loss: 0.2167 - val_accuracy: 0.6538\n","Epoch 177/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2461 - accuracy: 0.5469 - val_loss: 0.2167 - val_accuracy: 0.6538\n","Epoch 178/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2263 - accuracy: 0.6719 - val_loss: 0.2195 - val_accuracy: 0.7308\n","Epoch 179/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2530 - accuracy: 0.5156 - val_loss: 0.2213 - val_accuracy: 0.6538\n","Epoch 180/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2400 - accuracy: 0.5781 - val_loss: 0.2221 - val_accuracy: 0.6538\n","Epoch 181/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2508 - accuracy: 0.5312 - val_loss: 0.2208 - val_accuracy: 0.6923\n","Epoch 182/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2446 - accuracy: 0.5469 - val_loss: 0.2200 - val_accuracy: 0.7308\n","Epoch 183/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2432 - accuracy: 0.5469 - val_loss: 0.2201 - val_accuracy: 0.7308\n","Epoch 184/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2443 - accuracy: 0.5625 - val_loss: 0.2203 - val_accuracy: 0.6923\n","Epoch 185/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2525 - accuracy: 0.5156 - val_loss: 0.2201 - val_accuracy: 0.7308\n","Epoch 186/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2323 - accuracy: 0.5781 - val_loss: 0.2211 - val_accuracy: 0.6923\n","Epoch 187/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2273 - accuracy: 0.6250 - val_loss: 0.2217 - val_accuracy: 0.6538\n","Epoch 188/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2390 - accuracy: 0.5938 - val_loss: 0.2212 - val_accuracy: 0.6538\n","Epoch 189/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2394 - accuracy: 0.5000 - val_loss: 0.2183 - val_accuracy: 0.7308\n","Epoch 190/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2411 - accuracy: 0.5469 - val_loss: 0.2167 - val_accuracy: 0.6923\n","Epoch 191/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2467 - accuracy: 0.5156 - val_loss: 0.2163 - val_accuracy: 0.6923\n","Epoch 192/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2606 - accuracy: 0.5625 - val_loss: 0.2171 - val_accuracy: 0.7308\n","Epoch 193/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2463 - accuracy: 0.5938 - val_loss: 0.2178 - val_accuracy: 0.7308\n","Epoch 194/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2500 - accuracy: 0.5469 - val_loss: 0.2180 - val_accuracy: 0.7308\n","Epoch 195/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2372 - accuracy: 0.5781 - val_loss: 0.2200 - val_accuracy: 0.6923\n","Epoch 196/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2287 - accuracy: 0.5469 - val_loss: 0.2220 - val_accuracy: 0.6538\n","Epoch 197/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2506 - accuracy: 0.5156 - val_loss: 0.2202 - val_accuracy: 0.6923\n","Epoch 198/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2499 - accuracy: 0.5000 - val_loss: 0.2173 - val_accuracy: 0.7308\n","Epoch 199/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2562 - accuracy: 0.5781 - val_loss: 0.2165 - val_accuracy: 0.6923\n","Epoch 200/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2350 - accuracy: 0.5781 - val_loss: 0.2167 - val_accuracy: 0.7308\n","Epoch 201/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2365 - accuracy: 0.5781 - val_loss: 0.2189 - val_accuracy: 0.6923\n","Epoch 202/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2414 - accuracy: 0.5781 - val_loss: 0.2218 - val_accuracy: 0.6923\n","Epoch 203/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2394 - accuracy: 0.6094 - val_loss: 0.2197 - val_accuracy: 0.6538\n","Epoch 204/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2530 - accuracy: 0.5625 - val_loss: 0.2157 - val_accuracy: 0.7308\n","Epoch 205/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2373 - accuracy: 0.6406 - val_loss: 0.2153 - val_accuracy: 0.7308\n","Epoch 206/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2362 - accuracy: 0.5625 - val_loss: 0.2173 - val_accuracy: 0.6538\n","Epoch 207/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2410 - accuracy: 0.6094 - val_loss: 0.2228 - val_accuracy: 0.6538\n","Epoch 208/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2479 - accuracy: 0.5000 - val_loss: 0.2253 - val_accuracy: 0.6538\n","Epoch 209/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2446 - accuracy: 0.5312 - val_loss: 0.2196 - val_accuracy: 0.6538\n","Epoch 210/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2463 - accuracy: 0.5938 - val_loss: 0.2170 - val_accuracy: 0.6923\n","Epoch 211/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2463 - accuracy: 0.5312 - val_loss: 0.2164 - val_accuracy: 0.7308\n","Epoch 212/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2462 - accuracy: 0.5469 - val_loss: 0.2183 - val_accuracy: 0.6923\n","Epoch 213/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2374 - accuracy: 0.5625 - val_loss: 0.2218 - val_accuracy: 0.6923\n","Epoch 214/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2400 - accuracy: 0.5312 - val_loss: 0.2254 - val_accuracy: 0.6538\n","Epoch 215/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2386 - accuracy: 0.5469 - val_loss: 0.2237 - val_accuracy: 0.6923\n","Epoch 216/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2326 - accuracy: 0.5938 - val_loss: 0.2209 - val_accuracy: 0.6923\n","Epoch 217/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2476 - accuracy: 0.5000 - val_loss: 0.2193 - val_accuracy: 0.7308\n","Epoch 218/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2362 - accuracy: 0.5781 - val_loss: 0.2190 - val_accuracy: 0.7308\n","Epoch 219/245\n","2/2 [==============================] - 3s 2s/step - loss: 0.2414 - accuracy: 0.5469 - val_loss: 0.2207 - val_accuracy: 0.6923\n","Epoch 220/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2348 - accuracy: 0.6094 - val_loss: 0.2254 - val_accuracy: 0.6923\n","Epoch 221/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2314 - accuracy: 0.6250 - val_loss: 0.2297 - val_accuracy: 0.6538\n","Epoch 222/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2568 - accuracy: 0.5781 - val_loss: 0.2235 - val_accuracy: 0.6923\n","Epoch 223/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2351 - accuracy: 0.5625 - val_loss: 0.2176 - val_accuracy: 0.6923\n","Epoch 224/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2438 - accuracy: 0.6094 - val_loss: 0.2160 - val_accuracy: 0.7308\n","Epoch 225/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2413 - accuracy: 0.5938 - val_loss: 0.2174 - val_accuracy: 0.6923\n","Epoch 226/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2375 - accuracy: 0.6406 - val_loss: 0.2230 - val_accuracy: 0.6923\n","Epoch 227/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2375 - accuracy: 0.6406 - val_loss: 0.2335 - val_accuracy: 0.5769\n","Epoch 228/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2426 - accuracy: 0.5938 - val_loss: 0.2352 - val_accuracy: 0.5769\n","Epoch 229/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2248 - accuracy: 0.6875 - val_loss: 0.2313 - val_accuracy: 0.6154\n","Epoch 230/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2487 - accuracy: 0.5781 - val_loss: 0.2277 - val_accuracy: 0.6154\n","Epoch 231/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2346 - accuracy: 0.6250 - val_loss: 0.2265 - val_accuracy: 0.6154\n","Epoch 232/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2464 - accuracy: 0.5625 - val_loss: 0.2290 - val_accuracy: 0.6154\n","Epoch 233/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2342 - accuracy: 0.6094 - val_loss: 0.2446 - val_accuracy: 0.6154\n","Epoch 234/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2405 - accuracy: 0.6250 - val_loss: 0.2581 - val_accuracy: 0.6154\n","Epoch 235/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2493 - accuracy: 0.5469 - val_loss: 0.2480 - val_accuracy: 0.5769\n","Epoch 236/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2407 - accuracy: 0.5781 - val_loss: 0.2358 - val_accuracy: 0.5769\n","Epoch 237/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2431 - accuracy: 0.5312 - val_loss: 0.2308 - val_accuracy: 0.6154\n","Epoch 238/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2352 - accuracy: 0.5938 - val_loss: 0.2301 - val_accuracy: 0.6154\n","Epoch 239/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2390 - accuracy: 0.5781 - val_loss: 0.2338 - val_accuracy: 0.5769\n","Epoch 240/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2343 - accuracy: 0.5938 - val_loss: 0.2304 - val_accuracy: 0.6154\n","Epoch 241/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2404 - accuracy: 0.5938 - val_loss: 0.2255 - val_accuracy: 0.6538\n","Epoch 242/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2391 - accuracy: 0.6094 - val_loss: 0.2223 - val_accuracy: 0.6538\n","Epoch 243/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2452 - accuracy: 0.5469 - val_loss: 0.2187 - val_accuracy: 0.6923\n","Epoch 244/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2517 - accuracy: 0.5781 - val_loss: 0.2166 - val_accuracy: 0.6538\n","Epoch 245/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2505 - accuracy: 0.5625 - val_loss: 0.2197 - val_accuracy: 0.6538\n","1/1 [==============================] - 0s 95ms/step - loss: 0.2197 - accuracy: 0.6538\n","loss :  0.6538461446762085\n","total_loss :  1.6153846383094788\n","num :  3\n","WARNING:tensorflow:Layer gru_15 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","WARNING:tensorflow:Layer gru_16 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","WARNING:tensorflow:Layer gru_17 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","WARNING:tensorflow:Layer gru_18 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","WARNING:tensorflow:Layer gru_19 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","Epoch 1/245\n","2/2 [==============================] - 12s 2s/step - loss: 0.4955 - accuracy: 0.5000 - val_loss: 0.4210 - val_accuracy: 0.5000\n","Epoch 2/245\n","2/2 [==============================] - 3s 2s/step - loss: 0.3356 - accuracy: 0.5000 - val_loss: 0.3336 - val_accuracy: 0.5000\n","Epoch 3/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2782 - accuracy: 0.4062 - val_loss: 0.2970 - val_accuracy: 0.5000\n","Epoch 4/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.3230 - accuracy: 0.5000 - val_loss: 0.3181 - val_accuracy: 0.5000\n","Epoch 5/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2846 - accuracy: 0.4844 - val_loss: 0.3454 - val_accuracy: 0.5000\n","Epoch 6/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2750 - accuracy: 0.5000 - val_loss: 0.3595 - val_accuracy: 0.5000\n","Epoch 7/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2627 - accuracy: 0.5000 - val_loss: 0.3595 - val_accuracy: 0.5000\n","Epoch 8/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2570 - accuracy: 0.5156 - val_loss: 0.3479 - val_accuracy: 0.5000\n","Epoch 9/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2572 - accuracy: 0.4688 - val_loss: 0.3294 - val_accuracy: 0.5000\n","Epoch 10/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2343 - accuracy: 0.6562 - val_loss: 0.3094 - val_accuracy: 0.5000\n","Epoch 11/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2590 - accuracy: 0.5156 - val_loss: 0.2979 - val_accuracy: 0.5000\n","Epoch 12/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2656 - accuracy: 0.5156 - val_loss: 0.2973 - val_accuracy: 0.5000\n","Epoch 13/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2494 - accuracy: 0.5469 - val_loss: 0.3022 - val_accuracy: 0.5000\n","Epoch 14/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2716 - accuracy: 0.4219 - val_loss: 0.3108 - val_accuracy: 0.5000\n","Epoch 15/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2476 - accuracy: 0.5625 - val_loss: 0.3173 - val_accuracy: 0.5000\n","Epoch 16/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2764 - accuracy: 0.3750 - val_loss: 0.3204 - val_accuracy: 0.5000\n","Epoch 17/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2407 - accuracy: 0.5625 - val_loss: 0.3155 - val_accuracy: 0.5000\n","Epoch 18/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2664 - accuracy: 0.5469 - val_loss: 0.3054 - val_accuracy: 0.5000\n","Epoch 19/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2479 - accuracy: 0.5000 - val_loss: 0.2937 - val_accuracy: 0.5000\n","Epoch 20/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2576 - accuracy: 0.5000 - val_loss: 0.2863 - val_accuracy: 0.5000\n","Epoch 21/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2582 - accuracy: 0.5625 - val_loss: 0.2866 - val_accuracy: 0.5000\n","Epoch 22/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2397 - accuracy: 0.5625 - val_loss: 0.2894 - val_accuracy: 0.5000\n","Epoch 23/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2483 - accuracy: 0.5156 - val_loss: 0.2921 - val_accuracy: 0.5000\n","Epoch 24/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2510 - accuracy: 0.5469 - val_loss: 0.2928 - val_accuracy: 0.5000\n","Epoch 25/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2729 - accuracy: 0.4219 - val_loss: 0.2943 - val_accuracy: 0.5000\n","Epoch 26/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2478 - accuracy: 0.5938 - val_loss: 0.2941 - val_accuracy: 0.5000\n","Epoch 27/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2412 - accuracy: 0.5312 - val_loss: 0.2911 - val_accuracy: 0.5000\n","Epoch 28/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2604 - accuracy: 0.4375 - val_loss: 0.2876 - val_accuracy: 0.5000\n","Epoch 29/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2297 - accuracy: 0.6250 - val_loss: 0.2830 - val_accuracy: 0.5000\n","Epoch 30/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2535 - accuracy: 0.5781 - val_loss: 0.2802 - val_accuracy: 0.5000\n","Epoch 31/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2362 - accuracy: 0.5469 - val_loss: 0.2815 - val_accuracy: 0.5000\n","Epoch 32/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2349 - accuracy: 0.6250 - val_loss: 0.2814 - val_accuracy: 0.5000\n","Epoch 33/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2271 - accuracy: 0.6094 - val_loss: 0.2807 - val_accuracy: 0.5000\n","Epoch 34/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2416 - accuracy: 0.5938 - val_loss: 0.2790 - val_accuracy: 0.5000\n","Epoch 35/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2594 - accuracy: 0.5469 - val_loss: 0.2798 - val_accuracy: 0.5000\n","Epoch 36/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2479 - accuracy: 0.5000 - val_loss: 0.2828 - val_accuracy: 0.5000\n","Epoch 37/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2415 - accuracy: 0.6406 - val_loss: 0.2836 - val_accuracy: 0.5000\n","Epoch 38/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2366 - accuracy: 0.6250 - val_loss: 0.2820 - val_accuracy: 0.5000\n","Epoch 39/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2439 - accuracy: 0.5625 - val_loss: 0.2766 - val_accuracy: 0.5000\n","Epoch 40/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2537 - accuracy: 0.5781 - val_loss: 0.2743 - val_accuracy: 0.5000\n","Epoch 41/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2377 - accuracy: 0.5469 - val_loss: 0.2741 - val_accuracy: 0.5000\n","Epoch 42/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2316 - accuracy: 0.6250 - val_loss: 0.2742 - val_accuracy: 0.5000\n","Epoch 43/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2513 - accuracy: 0.5781 - val_loss: 0.2785 - val_accuracy: 0.5000\n","Epoch 44/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2355 - accuracy: 0.5781 - val_loss: 0.2803 - val_accuracy: 0.5000\n","Epoch 45/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2466 - accuracy: 0.4844 - val_loss: 0.2796 - val_accuracy: 0.5000\n","Epoch 46/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2531 - accuracy: 0.4844 - val_loss: 0.2759 - val_accuracy: 0.5000\n","Epoch 47/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2382 - accuracy: 0.5938 - val_loss: 0.2687 - val_accuracy: 0.5000\n","Epoch 48/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2447 - accuracy: 0.5312 - val_loss: 0.2672 - val_accuracy: 0.5000\n","Epoch 49/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2462 - accuracy: 0.5156 - val_loss: 0.2674 - val_accuracy: 0.5000\n","Epoch 50/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2373 - accuracy: 0.6250 - val_loss: 0.2652 - val_accuracy: 0.5000\n","Epoch 51/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2711 - accuracy: 0.4531 - val_loss: 0.2673 - val_accuracy: 0.5000\n","Epoch 52/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2596 - accuracy: 0.5156 - val_loss: 0.2675 - val_accuracy: 0.5000\n","Epoch 53/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2224 - accuracy: 0.7031 - val_loss: 0.2657 - val_accuracy: 0.5000\n","Epoch 54/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2396 - accuracy: 0.5781 - val_loss: 0.2608 - val_accuracy: 0.5000\n","Epoch 55/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2551 - accuracy: 0.6562 - val_loss: 0.2595 - val_accuracy: 0.5000\n","Epoch 56/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2469 - accuracy: 0.5781 - val_loss: 0.2613 - val_accuracy: 0.5000\n","Epoch 57/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2445 - accuracy: 0.6250 - val_loss: 0.2628 - val_accuracy: 0.5000\n","Epoch 58/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2415 - accuracy: 0.6406 - val_loss: 0.2627 - val_accuracy: 0.5000\n","Epoch 59/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2372 - accuracy: 0.6250 - val_loss: 0.2592 - val_accuracy: 0.5000\n","Epoch 60/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2464 - accuracy: 0.5156 - val_loss: 0.2560 - val_accuracy: 0.5000\n","Epoch 61/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2532 - accuracy: 0.5469 - val_loss: 0.2537 - val_accuracy: 0.5000\n","Epoch 62/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2198 - accuracy: 0.6250 - val_loss: 0.2508 - val_accuracy: 0.5000\n","Epoch 63/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2293 - accuracy: 0.6719 - val_loss: 0.2494 - val_accuracy: 0.5769\n","Epoch 64/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2594 - accuracy: 0.5000 - val_loss: 0.2507 - val_accuracy: 0.5000\n","Epoch 65/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2269 - accuracy: 0.5781 - val_loss: 0.2547 - val_accuracy: 0.5000\n","Epoch 66/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2412 - accuracy: 0.5938 - val_loss: 0.2582 - val_accuracy: 0.5000\n","Epoch 67/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2339 - accuracy: 0.5938 - val_loss: 0.2579 - val_accuracy: 0.5000\n","Epoch 68/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2423 - accuracy: 0.5781 - val_loss: 0.2565 - val_accuracy: 0.5000\n","Epoch 69/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2535 - accuracy: 0.5312 - val_loss: 0.2541 - val_accuracy: 0.5000\n","Epoch 70/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2418 - accuracy: 0.5781 - val_loss: 0.2518 - val_accuracy: 0.5000\n","Epoch 71/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2307 - accuracy: 0.6250 - val_loss: 0.2489 - val_accuracy: 0.5000\n","Epoch 72/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2261 - accuracy: 0.6562 - val_loss: 0.2467 - val_accuracy: 0.5385\n","Epoch 73/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2174 - accuracy: 0.5938 - val_loss: 0.2460 - val_accuracy: 0.5385\n","Epoch 74/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2346 - accuracy: 0.6406 - val_loss: 0.2458 - val_accuracy: 0.5385\n","Epoch 75/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2087 - accuracy: 0.7031 - val_loss: 0.2457 - val_accuracy: 0.5385\n","Epoch 76/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2345 - accuracy: 0.6094 - val_loss: 0.2465 - val_accuracy: 0.5385\n","Epoch 77/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2453 - accuracy: 0.6094 - val_loss: 0.2486 - val_accuracy: 0.5000\n","Epoch 78/245\n","2/2 [==============================] - 3s 2s/step - loss: 0.2370 - accuracy: 0.5938 - val_loss: 0.2492 - val_accuracy: 0.5000\n","Epoch 79/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2390 - accuracy: 0.5938 - val_loss: 0.2466 - val_accuracy: 0.5769\n","Epoch 80/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2214 - accuracy: 0.6250 - val_loss: 0.2460 - val_accuracy: 0.5769\n","Epoch 81/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2073 - accuracy: 0.6875 - val_loss: 0.2509 - val_accuracy: 0.5769\n","Epoch 82/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2136 - accuracy: 0.6875 - val_loss: 0.2529 - val_accuracy: 0.5769\n","Epoch 83/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2565 - accuracy: 0.5781 - val_loss: 0.2462 - val_accuracy: 0.5385\n","Epoch 84/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2419 - accuracy: 0.5625 - val_loss: 0.2568 - val_accuracy: 0.5000\n","Epoch 85/245\n","2/2 [==============================] - 3s 2s/step - loss: 0.2433 - accuracy: 0.5312 - val_loss: 0.2630 - val_accuracy: 0.5000\n","Epoch 86/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2517 - accuracy: 0.5625 - val_loss: 0.2598 - val_accuracy: 0.5000\n","Epoch 87/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2334 - accuracy: 0.5781 - val_loss: 0.2542 - val_accuracy: 0.5385\n","Epoch 88/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2476 - accuracy: 0.5938 - val_loss: 0.2517 - val_accuracy: 0.5769\n","Epoch 89/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2276 - accuracy: 0.6094 - val_loss: 0.2487 - val_accuracy: 0.5000\n","Epoch 90/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2418 - accuracy: 0.6094 - val_loss: 0.2458 - val_accuracy: 0.5385\n","Epoch 91/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2313 - accuracy: 0.6406 - val_loss: 0.2455 - val_accuracy: 0.5385\n","Epoch 92/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2093 - accuracy: 0.6719 - val_loss: 0.2469 - val_accuracy: 0.5385\n","Epoch 93/245\n","2/2 [==============================] - 3s 2s/step - loss: 0.2384 - accuracy: 0.5781 - val_loss: 0.2464 - val_accuracy: 0.5385\n","Epoch 94/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2532 - accuracy: 0.5781 - val_loss: 0.2464 - val_accuracy: 0.5385\n","Epoch 95/245\n","2/2 [==============================] - 3s 2s/step - loss: 0.2251 - accuracy: 0.6094 - val_loss: 0.2486 - val_accuracy: 0.5000\n","Epoch 96/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2502 - accuracy: 0.5625 - val_loss: 0.2475 - val_accuracy: 0.5385\n","Epoch 97/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2500 - accuracy: 0.5000 - val_loss: 0.2459 - val_accuracy: 0.5769\n","Epoch 98/245\n","2/2 [==============================] - 3s 2s/step - loss: 0.2363 - accuracy: 0.6406 - val_loss: 0.2458 - val_accuracy: 0.5385\n","Epoch 99/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2441 - accuracy: 0.5625 - val_loss: 0.2465 - val_accuracy: 0.5385\n","Epoch 100/245\n","2/2 [==============================] - 3s 2s/step - loss: 0.2316 - accuracy: 0.6094 - val_loss: 0.2458 - val_accuracy: 0.5385\n","Epoch 101/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2536 - accuracy: 0.5312 - val_loss: 0.2468 - val_accuracy: 0.5385\n","Epoch 102/245\n","2/2 [==============================] - 3s 2s/step - loss: 0.2227 - accuracy: 0.5938 - val_loss: 0.2498 - val_accuracy: 0.5000\n","Epoch 103/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2410 - accuracy: 0.5625 - val_loss: 0.2489 - val_accuracy: 0.5000\n","Epoch 104/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2381 - accuracy: 0.5625 - val_loss: 0.2459 - val_accuracy: 0.5385\n","Epoch 105/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2260 - accuracy: 0.6875 - val_loss: 0.2464 - val_accuracy: 0.5385\n","Epoch 106/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2382 - accuracy: 0.5938 - val_loss: 0.2486 - val_accuracy: 0.5769\n","Epoch 107/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2366 - accuracy: 0.5625 - val_loss: 0.2469 - val_accuracy: 0.5385\n","Epoch 108/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2211 - accuracy: 0.6719 - val_loss: 0.2457 - val_accuracy: 0.5769\n","Epoch 109/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2158 - accuracy: 0.7031 - val_loss: 0.2464 - val_accuracy: 0.5385\n","Epoch 110/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2352 - accuracy: 0.5938 - val_loss: 0.2467 - val_accuracy: 0.5385\n","Epoch 111/245\n","2/2 [==============================] - 3s 2s/step - loss: 0.2230 - accuracy: 0.6562 - val_loss: 0.2464 - val_accuracy: 0.5385\n","Epoch 112/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2368 - accuracy: 0.6094 - val_loss: 0.2461 - val_accuracy: 0.5769\n","Epoch 113/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2446 - accuracy: 0.5781 - val_loss: 0.2464 - val_accuracy: 0.5385\n","Epoch 114/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2193 - accuracy: 0.5938 - val_loss: 0.2473 - val_accuracy: 0.5385\n","Epoch 115/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2313 - accuracy: 0.7031 - val_loss: 0.2464 - val_accuracy: 0.5769\n","Epoch 116/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2436 - accuracy: 0.5938 - val_loss: 0.2474 - val_accuracy: 0.5385\n","Epoch 117/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2170 - accuracy: 0.6719 - val_loss: 0.2486 - val_accuracy: 0.5000\n","Epoch 118/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2439 - accuracy: 0.5781 - val_loss: 0.2486 - val_accuracy: 0.5000\n","Epoch 119/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2421 - accuracy: 0.6250 - val_loss: 0.2481 - val_accuracy: 0.5000\n","Epoch 120/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2184 - accuracy: 0.6719 - val_loss: 0.2466 - val_accuracy: 0.5385\n","Epoch 121/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2276 - accuracy: 0.6250 - val_loss: 0.2464 - val_accuracy: 0.5769\n","Epoch 122/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2359 - accuracy: 0.5000 - val_loss: 0.2464 - val_accuracy: 0.5769\n","Epoch 123/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2687 - accuracy: 0.5312 - val_loss: 0.2469 - val_accuracy: 0.5385\n","Epoch 124/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2547 - accuracy: 0.5938 - val_loss: 0.2484 - val_accuracy: 0.4615\n","Epoch 125/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2110 - accuracy: 0.7031 - val_loss: 0.2492 - val_accuracy: 0.5385\n","Epoch 126/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2284 - accuracy: 0.6562 - val_loss: 0.2482 - val_accuracy: 0.4615\n","Epoch 127/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2318 - accuracy: 0.6562 - val_loss: 0.2471 - val_accuracy: 0.5385\n","Epoch 128/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2469 - accuracy: 0.5312 - val_loss: 0.2470 - val_accuracy: 0.5769\n","Epoch 129/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2320 - accuracy: 0.5625 - val_loss: 0.2476 - val_accuracy: 0.5385\n","Epoch 130/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2306 - accuracy: 0.6562 - val_loss: 0.2474 - val_accuracy: 0.5769\n","Epoch 131/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2585 - accuracy: 0.5469 - val_loss: 0.2472 - val_accuracy: 0.5769\n","Epoch 132/245\n","2/2 [==============================] - 3s 2s/step - loss: 0.2470 - accuracy: 0.5938 - val_loss: 0.2474 - val_accuracy: 0.5385\n","Epoch 133/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2310 - accuracy: 0.6094 - val_loss: 0.2477 - val_accuracy: 0.5385\n","Epoch 134/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2362 - accuracy: 0.6094 - val_loss: 0.2476 - val_accuracy: 0.5385\n","Epoch 135/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2319 - accuracy: 0.5625 - val_loss: 0.2473 - val_accuracy: 0.5769\n","Epoch 136/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2332 - accuracy: 0.6094 - val_loss: 0.2480 - val_accuracy: 0.5769\n","Epoch 137/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2245 - accuracy: 0.6094 - val_loss: 0.2482 - val_accuracy: 0.5385\n","Epoch 138/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2228 - accuracy: 0.7188 - val_loss: 0.2478 - val_accuracy: 0.5769\n","Epoch 139/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2428 - accuracy: 0.5625 - val_loss: 0.2480 - val_accuracy: 0.5769\n","Epoch 140/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2411 - accuracy: 0.6094 - val_loss: 0.2496 - val_accuracy: 0.5769\n","Epoch 141/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2414 - accuracy: 0.6094 - val_loss: 0.2526 - val_accuracy: 0.5769\n","Epoch 142/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2315 - accuracy: 0.5781 - val_loss: 0.2520 - val_accuracy: 0.5385\n","Epoch 143/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2456 - accuracy: 0.5938 - val_loss: 0.2495 - val_accuracy: 0.5385\n","Epoch 144/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2318 - accuracy: 0.6406 - val_loss: 0.2496 - val_accuracy: 0.5385\n","Epoch 145/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2427 - accuracy: 0.5938 - val_loss: 0.2510 - val_accuracy: 0.5769\n","Epoch 146/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2278 - accuracy: 0.6562 - val_loss: 0.2537 - val_accuracy: 0.5769\n","Epoch 147/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2558 - accuracy: 0.5625 - val_loss: 0.2583 - val_accuracy: 0.5769\n","Epoch 148/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2342 - accuracy: 0.5781 - val_loss: 0.2670 - val_accuracy: 0.5769\n","Epoch 149/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2176 - accuracy: 0.6562 - val_loss: 0.2676 - val_accuracy: 0.5769\n","Epoch 150/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2106 - accuracy: 0.6406 - val_loss: 0.2596 - val_accuracy: 0.5385\n","Epoch 151/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2139 - accuracy: 0.6406 - val_loss: 0.2562 - val_accuracy: 0.5769\n","Epoch 152/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2464 - accuracy: 0.5625 - val_loss: 0.2544 - val_accuracy: 0.5769\n","Epoch 153/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2402 - accuracy: 0.6250 - val_loss: 0.2562 - val_accuracy: 0.5769\n","Epoch 154/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2468 - accuracy: 0.5156 - val_loss: 0.2582 - val_accuracy: 0.5769\n","Epoch 155/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2424 - accuracy: 0.6094 - val_loss: 0.2535 - val_accuracy: 0.5769\n","Epoch 156/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2278 - accuracy: 0.6094 - val_loss: 0.2507 - val_accuracy: 0.5385\n","Epoch 157/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2601 - accuracy: 0.5781 - val_loss: 0.2485 - val_accuracy: 0.5385\n","Epoch 158/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2438 - accuracy: 0.5625 - val_loss: 0.2488 - val_accuracy: 0.5769\n","Epoch 159/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2300 - accuracy: 0.5625 - val_loss: 0.2512 - val_accuracy: 0.5769\n","Epoch 160/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2124 - accuracy: 0.7031 - val_loss: 0.2515 - val_accuracy: 0.5769\n","Epoch 161/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2474 - accuracy: 0.5625 - val_loss: 0.2485 - val_accuracy: 0.5385\n","Epoch 162/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2247 - accuracy: 0.5625 - val_loss: 0.2472 - val_accuracy: 0.5385\n","Epoch 163/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2242 - accuracy: 0.6406 - val_loss: 0.2467 - val_accuracy: 0.5385\n","Epoch 164/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2418 - accuracy: 0.5781 - val_loss: 0.2463 - val_accuracy: 0.5385\n","Epoch 165/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2269 - accuracy: 0.6406 - val_loss: 0.2460 - val_accuracy: 0.5000\n","Epoch 166/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2127 - accuracy: 0.7031 - val_loss: 0.2462 - val_accuracy: 0.5385\n","Epoch 167/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2270 - accuracy: 0.6562 - val_loss: 0.2463 - val_accuracy: 0.5385\n","Epoch 168/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2312 - accuracy: 0.6250 - val_loss: 0.2458 - val_accuracy: 0.5385\n","Epoch 169/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2177 - accuracy: 0.7188 - val_loss: 0.2454 - val_accuracy: 0.5000\n","Epoch 170/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2065 - accuracy: 0.6875 - val_loss: 0.2456 - val_accuracy: 0.5385\n","Epoch 171/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2491 - accuracy: 0.5625 - val_loss: 0.2465 - val_accuracy: 0.5385\n","Epoch 172/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2320 - accuracy: 0.6250 - val_loss: 0.2485 - val_accuracy: 0.5385\n","Epoch 173/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2344 - accuracy: 0.5781 - val_loss: 0.2492 - val_accuracy: 0.5385\n","Epoch 174/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2231 - accuracy: 0.6406 - val_loss: 0.2463 - val_accuracy: 0.5385\n","Epoch 175/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2170 - accuracy: 0.6406 - val_loss: 0.2514 - val_accuracy: 0.5769\n","Epoch 176/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2092 - accuracy: 0.6562 - val_loss: 0.2616 - val_accuracy: 0.6154\n","Epoch 177/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2115 - accuracy: 0.6406 - val_loss: 0.2608 - val_accuracy: 0.6154\n","Epoch 178/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2078 - accuracy: 0.6875 - val_loss: 0.2535 - val_accuracy: 0.5769\n","Epoch 179/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2254 - accuracy: 0.6250 - val_loss: 0.2501 - val_accuracy: 0.5385\n","Epoch 180/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2330 - accuracy: 0.6094 - val_loss: 0.2519 - val_accuracy: 0.5769\n","Epoch 181/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2151 - accuracy: 0.6406 - val_loss: 0.2536 - val_accuracy: 0.5769\n","Epoch 182/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2089 - accuracy: 0.6719 - val_loss: 0.2525 - val_accuracy: 0.5769\n","Epoch 183/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2378 - accuracy: 0.5625 - val_loss: 0.2507 - val_accuracy: 0.5769\n","Epoch 184/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2128 - accuracy: 0.6562 - val_loss: 0.2536 - val_accuracy: 0.5769\n","Epoch 185/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2392 - accuracy: 0.5625 - val_loss: 0.2624 - val_accuracy: 0.5769\n","Epoch 186/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2093 - accuracy: 0.6250 - val_loss: 0.2914 - val_accuracy: 0.5385\n","Epoch 187/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2315 - accuracy: 0.5938 - val_loss: 0.2935 - val_accuracy: 0.5385\n","Epoch 188/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2064 - accuracy: 0.7500 - val_loss: 0.2597 - val_accuracy: 0.5769\n","Epoch 189/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2316 - accuracy: 0.6406 - val_loss: 0.2491 - val_accuracy: 0.6154\n","Epoch 190/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2543 - accuracy: 0.5625 - val_loss: 0.2486 - val_accuracy: 0.6154\n","Epoch 191/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2250 - accuracy: 0.6250 - val_loss: 0.2521 - val_accuracy: 0.5769\n","Epoch 192/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2023 - accuracy: 0.6719 - val_loss: 0.2657 - val_accuracy: 0.5769\n","Epoch 193/245\n","2/2 [==============================] - 3s 2s/step - loss: 0.2425 - accuracy: 0.6250 - val_loss: 0.2690 - val_accuracy: 0.5769\n","Epoch 194/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2400 - accuracy: 0.6094 - val_loss: 0.2501 - val_accuracy: 0.5769\n","Epoch 195/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2226 - accuracy: 0.6250 - val_loss: 0.2470 - val_accuracy: 0.6154\n","Epoch 196/245\n","2/2 [==============================] - 3s 2s/step - loss: 0.2099 - accuracy: 0.7031 - val_loss: 0.2471 - val_accuracy: 0.6154\n","Epoch 197/245\n","2/2 [==============================] - 3s 2s/step - loss: 0.2023 - accuracy: 0.7188 - val_loss: 0.2484 - val_accuracy: 0.6154\n","Epoch 198/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2209 - accuracy: 0.6875 - val_loss: 0.2497 - val_accuracy: 0.6154\n","Epoch 199/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2119 - accuracy: 0.6562 - val_loss: 0.2493 - val_accuracy: 0.5769\n","Epoch 200/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.1997 - accuracy: 0.6875 - val_loss: 0.2543 - val_accuracy: 0.5769\n","Epoch 201/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2317 - accuracy: 0.5625 - val_loss: 0.2613 - val_accuracy: 0.5769\n","Epoch 202/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2154 - accuracy: 0.6875 - val_loss: 0.2516 - val_accuracy: 0.5769\n","Epoch 203/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2147 - accuracy: 0.6094 - val_loss: 0.2551 - val_accuracy: 0.5769\n","Epoch 204/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.1974 - accuracy: 0.7344 - val_loss: 0.2544 - val_accuracy: 0.5769\n","Epoch 205/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.1965 - accuracy: 0.7188 - val_loss: 0.2569 - val_accuracy: 0.5769\n","Epoch 206/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2337 - accuracy: 0.6094 - val_loss: 0.2555 - val_accuracy: 0.5769\n","Epoch 207/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2040 - accuracy: 0.6562 - val_loss: 0.2684 - val_accuracy: 0.6154\n","Epoch 208/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2245 - accuracy: 0.6406 - val_loss: 0.2904 - val_accuracy: 0.6154\n","Epoch 209/245\n","2/2 [==============================] - 3s 2s/step - loss: 0.2219 - accuracy: 0.6094 - val_loss: 0.2666 - val_accuracy: 0.6154\n","Epoch 210/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2023 - accuracy: 0.6406 - val_loss: 0.2652 - val_accuracy: 0.5769\n","Epoch 211/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2363 - accuracy: 0.6406 - val_loss: 0.3105 - val_accuracy: 0.5385\n","Epoch 212/245\n","2/2 [==============================] - 3s 2s/step - loss: 0.2427 - accuracy: 0.5625 - val_loss: 0.2982 - val_accuracy: 0.5385\n","Epoch 213/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2165 - accuracy: 0.5938 - val_loss: 0.2695 - val_accuracy: 0.5385\n","Epoch 214/245\n","2/2 [==============================] - 3s 2s/step - loss: 0.2162 - accuracy: 0.6875 - val_loss: 0.2632 - val_accuracy: 0.5385\n","Epoch 215/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.1999 - accuracy: 0.6562 - val_loss: 0.2700 - val_accuracy: 0.5385\n","Epoch 216/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2149 - accuracy: 0.6094 - val_loss: 0.2824 - val_accuracy: 0.5385\n","Epoch 217/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2161 - accuracy: 0.6562 - val_loss: 0.2901 - val_accuracy: 0.5000\n","Epoch 218/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.1933 - accuracy: 0.7344 - val_loss: 0.2793 - val_accuracy: 0.5385\n","Epoch 219/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.1881 - accuracy: 0.6562 - val_loss: 0.2656 - val_accuracy: 0.5769\n","Epoch 220/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2209 - accuracy: 0.5938 - val_loss: 0.2713 - val_accuracy: 0.5385\n","Epoch 221/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2158 - accuracy: 0.6562 - val_loss: 0.2734 - val_accuracy: 0.5385\n","Epoch 222/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2089 - accuracy: 0.7500 - val_loss: 0.2733 - val_accuracy: 0.5769\n","Epoch 223/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2331 - accuracy: 0.5781 - val_loss: 0.2683 - val_accuracy: 0.5000\n","Epoch 224/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2437 - accuracy: 0.5938 - val_loss: 0.2560 - val_accuracy: 0.5385\n","Epoch 225/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2021 - accuracy: 0.6875 - val_loss: 0.2554 - val_accuracy: 0.5769\n","Epoch 226/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2273 - accuracy: 0.6250 - val_loss: 0.2559 - val_accuracy: 0.5769\n","Epoch 227/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2349 - accuracy: 0.5938 - val_loss: 0.2603 - val_accuracy: 0.6538\n","Epoch 228/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2261 - accuracy: 0.5938 - val_loss: 0.2603 - val_accuracy: 0.6538\n","Epoch 229/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2160 - accuracy: 0.6875 - val_loss: 0.2580 - val_accuracy: 0.6538\n","Epoch 230/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2074 - accuracy: 0.6719 - val_loss: 0.2633 - val_accuracy: 0.6538\n","Epoch 231/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2266 - accuracy: 0.5625 - val_loss: 0.3026 - val_accuracy: 0.4615\n","Epoch 232/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2080 - accuracy: 0.6406 - val_loss: 0.3183 - val_accuracy: 0.4615\n","Epoch 233/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2205 - accuracy: 0.6562 - val_loss: 0.2692 - val_accuracy: 0.5769\n","Epoch 234/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2143 - accuracy: 0.6094 - val_loss: 0.2494 - val_accuracy: 0.6154\n","Epoch 235/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2047 - accuracy: 0.6875 - val_loss: 0.2488 - val_accuracy: 0.5769\n","Epoch 236/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2125 - accuracy: 0.6406 - val_loss: 0.2513 - val_accuracy: 0.6154\n","Epoch 237/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2144 - accuracy: 0.7031 - val_loss: 0.2587 - val_accuracy: 0.6538\n","Epoch 238/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2271 - accuracy: 0.6875 - val_loss: 0.2586 - val_accuracy: 0.6538\n","Epoch 239/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.1951 - accuracy: 0.7500 - val_loss: 0.2534 - val_accuracy: 0.6154\n","Epoch 240/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2161 - accuracy: 0.7031 - val_loss: 0.2525 - val_accuracy: 0.5385\n","Epoch 241/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2333 - accuracy: 0.5469 - val_loss: 0.2564 - val_accuracy: 0.5769\n","Epoch 242/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2263 - accuracy: 0.5625 - val_loss: 0.2616 - val_accuracy: 0.5769\n","Epoch 243/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2201 - accuracy: 0.6562 - val_loss: 0.2629 - val_accuracy: 0.5769\n","Epoch 244/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2117 - accuracy: 0.5938 - val_loss: 0.2555 - val_accuracy: 0.5385\n","Epoch 245/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2004 - accuracy: 0.6719 - val_loss: 0.2538 - val_accuracy: 0.5385\n","1/1 [==============================] - 0s 97ms/step - loss: 0.2538 - accuracy: 0.5385\n","loss :  0.5384615659713745\n","total_loss :  2.1538462042808533\n","num :  4\n","WARNING:tensorflow:Layer gru_20 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","WARNING:tensorflow:Layer gru_21 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","WARNING:tensorflow:Layer gru_22 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","WARNING:tensorflow:Layer gru_23 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","WARNING:tensorflow:Layer gru_24 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","Epoch 1/245\n","2/2 [==============================] - 12s 2s/step - loss: 0.4044 - accuracy: 0.5469 - val_loss: 0.4704 - val_accuracy: 0.4231\n","Epoch 2/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2768 - accuracy: 0.5625 - val_loss: 0.3541 - val_accuracy: 0.4231\n","Epoch 3/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.3048 - accuracy: 0.4219 - val_loss: 0.3627 - val_accuracy: 0.4231\n","Epoch 4/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2721 - accuracy: 0.4531 - val_loss: 0.4047 - val_accuracy: 0.4231\n","Epoch 5/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2591 - accuracy: 0.5469 - val_loss: 0.4315 - val_accuracy: 0.4231\n","Epoch 6/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2477 - accuracy: 0.5625 - val_loss: 0.4369 - val_accuracy: 0.4231\n","Epoch 7/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2554 - accuracy: 0.5781 - val_loss: 0.4257 - val_accuracy: 0.4231\n","Epoch 8/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2594 - accuracy: 0.5312 - val_loss: 0.4049 - val_accuracy: 0.4231\n","Epoch 9/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2550 - accuracy: 0.5312 - val_loss: 0.3856 - val_accuracy: 0.4231\n","Epoch 10/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2636 - accuracy: 0.4531 - val_loss: 0.3741 - val_accuracy: 0.4231\n","Epoch 11/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2505 - accuracy: 0.5469 - val_loss: 0.3766 - val_accuracy: 0.4231\n","Epoch 12/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2550 - accuracy: 0.5781 - val_loss: 0.3823 - val_accuracy: 0.4231\n","Epoch 13/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2516 - accuracy: 0.5781 - val_loss: 0.3865 - val_accuracy: 0.4231\n","Epoch 14/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2358 - accuracy: 0.6406 - val_loss: 0.3856 - val_accuracy: 0.4231\n","Epoch 15/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2615 - accuracy: 0.5156 - val_loss: 0.3837 - val_accuracy: 0.4231\n","Epoch 16/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2468 - accuracy: 0.5781 - val_loss: 0.3783 - val_accuracy: 0.4231\n","Epoch 17/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2528 - accuracy: 0.5312 - val_loss: 0.3723 - val_accuracy: 0.4231\n","Epoch 18/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2569 - accuracy: 0.5000 - val_loss: 0.3676 - val_accuracy: 0.4231\n","Epoch 19/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2381 - accuracy: 0.5469 - val_loss: 0.3659 - val_accuracy: 0.4231\n","Epoch 20/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2498 - accuracy: 0.4688 - val_loss: 0.3716 - val_accuracy: 0.4231\n","Epoch 21/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2624 - accuracy: 0.5000 - val_loss: 0.3743 - val_accuracy: 0.4231\n","Epoch 22/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2562 - accuracy: 0.5625 - val_loss: 0.3742 - val_accuracy: 0.4231\n","Epoch 23/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2525 - accuracy: 0.5469 - val_loss: 0.3716 - val_accuracy: 0.4231\n","Epoch 24/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2424 - accuracy: 0.5938 - val_loss: 0.3703 - val_accuracy: 0.4231\n","Epoch 25/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2358 - accuracy: 0.5625 - val_loss: 0.3686 - val_accuracy: 0.4231\n","Epoch 26/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2728 - accuracy: 0.4375 - val_loss: 0.3734 - val_accuracy: 0.4231\n","Epoch 27/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2420 - accuracy: 0.5938 - val_loss: 0.3776 - val_accuracy: 0.4231\n","Epoch 28/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2529 - accuracy: 0.5625 - val_loss: 0.3774 - val_accuracy: 0.4231\n","Epoch 29/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2523 - accuracy: 0.5156 - val_loss: 0.3765 - val_accuracy: 0.4231\n","Epoch 30/245\n","2/2 [==============================] - 3s 2s/step - loss: 0.2433 - accuracy: 0.5781 - val_loss: 0.3753 - val_accuracy: 0.4231\n","Epoch 31/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2693 - accuracy: 0.5000 - val_loss: 0.3744 - val_accuracy: 0.4231\n","Epoch 32/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2462 - accuracy: 0.5000 - val_loss: 0.3704 - val_accuracy: 0.4231\n","Epoch 33/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2629 - accuracy: 0.5000 - val_loss: 0.3680 - val_accuracy: 0.4231\n","Epoch 34/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2445 - accuracy: 0.5000 - val_loss: 0.3633 - val_accuracy: 0.4231\n","Epoch 35/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2609 - accuracy: 0.5156 - val_loss: 0.3607 - val_accuracy: 0.4231\n","Epoch 36/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2495 - accuracy: 0.5312 - val_loss: 0.3596 - val_accuracy: 0.4231\n","Epoch 37/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2499 - accuracy: 0.5469 - val_loss: 0.3586 - val_accuracy: 0.4231\n","Epoch 38/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2436 - accuracy: 0.5625 - val_loss: 0.3559 - val_accuracy: 0.4231\n","Epoch 39/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2505 - accuracy: 0.5312 - val_loss: 0.3498 - val_accuracy: 0.4231\n","Epoch 40/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2429 - accuracy: 0.5000 - val_loss: 0.3472 - val_accuracy: 0.4231\n","Epoch 41/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2650 - accuracy: 0.4219 - val_loss: 0.3518 - val_accuracy: 0.4231\n","Epoch 42/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2532 - accuracy: 0.5156 - val_loss: 0.3568 - val_accuracy: 0.4231\n","Epoch 43/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2542 - accuracy: 0.5625 - val_loss: 0.3545 - val_accuracy: 0.4231\n","Epoch 44/245\n","2/2 [==============================] - 3s 2s/step - loss: 0.2385 - accuracy: 0.5938 - val_loss: 0.3476 - val_accuracy: 0.4231\n","Epoch 45/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2539 - accuracy: 0.5469 - val_loss: 0.3426 - val_accuracy: 0.4231\n","Epoch 46/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2458 - accuracy: 0.5312 - val_loss: 0.3417 - val_accuracy: 0.4231\n","Epoch 47/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2414 - accuracy: 0.5625 - val_loss: 0.3411 - val_accuracy: 0.4231\n","Epoch 48/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2436 - accuracy: 0.5938 - val_loss: 0.3444 - val_accuracy: 0.4231\n","Epoch 49/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2546 - accuracy: 0.4844 - val_loss: 0.3499 - val_accuracy: 0.4231\n","Epoch 50/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2336 - accuracy: 0.5312 - val_loss: 0.3500 - val_accuracy: 0.4231\n","Epoch 51/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2474 - accuracy: 0.5625 - val_loss: 0.3487 - val_accuracy: 0.4231\n","Epoch 52/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2439 - accuracy: 0.5938 - val_loss: 0.3446 - val_accuracy: 0.4231\n","Epoch 53/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2528 - accuracy: 0.5000 - val_loss: 0.3378 - val_accuracy: 0.4231\n","Epoch 54/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2555 - accuracy: 0.5312 - val_loss: 0.3318 - val_accuracy: 0.4231\n","Epoch 55/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2428 - accuracy: 0.6094 - val_loss: 0.3262 - val_accuracy: 0.4231\n","Epoch 56/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2502 - accuracy: 0.5781 - val_loss: 0.3274 - val_accuracy: 0.4231\n","Epoch 57/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2554 - accuracy: 0.5312 - val_loss: 0.3352 - val_accuracy: 0.4231\n","Epoch 58/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2321 - accuracy: 0.6094 - val_loss: 0.3373 - val_accuracy: 0.4231\n","Epoch 59/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2657 - accuracy: 0.5156 - val_loss: 0.3379 - val_accuracy: 0.4231\n","Epoch 60/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2449 - accuracy: 0.5625 - val_loss: 0.3340 - val_accuracy: 0.4231\n","Epoch 61/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2549 - accuracy: 0.5000 - val_loss: 0.3280 - val_accuracy: 0.4231\n","Epoch 62/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2444 - accuracy: 0.5469 - val_loss: 0.3206 - val_accuracy: 0.4231\n","Epoch 63/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2444 - accuracy: 0.5469 - val_loss: 0.3147 - val_accuracy: 0.4231\n","Epoch 64/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2630 - accuracy: 0.4219 - val_loss: 0.3136 - val_accuracy: 0.4231\n","Epoch 65/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2538 - accuracy: 0.4688 - val_loss: 0.3169 - val_accuracy: 0.4231\n","Epoch 66/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2502 - accuracy: 0.4531 - val_loss: 0.3232 - val_accuracy: 0.4231\n","Epoch 67/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2466 - accuracy: 0.5625 - val_loss: 0.3207 - val_accuracy: 0.4231\n","Epoch 68/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2378 - accuracy: 0.6094 - val_loss: 0.3107 - val_accuracy: 0.4231\n","Epoch 69/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2359 - accuracy: 0.6094 - val_loss: 0.2981 - val_accuracy: 0.4231\n","Epoch 70/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2384 - accuracy: 0.5781 - val_loss: 0.2883 - val_accuracy: 0.4231\n","Epoch 71/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2432 - accuracy: 0.5625 - val_loss: 0.2879 - val_accuracy: 0.4231\n","Epoch 72/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2492 - accuracy: 0.5625 - val_loss: 0.2941 - val_accuracy: 0.4231\n","Epoch 73/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2434 - accuracy: 0.6250 - val_loss: 0.3013 - val_accuracy: 0.4231\n","Epoch 74/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2428 - accuracy: 0.5000 - val_loss: 0.3045 - val_accuracy: 0.4231\n","Epoch 75/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2493 - accuracy: 0.5312 - val_loss: 0.3056 - val_accuracy: 0.4231\n","Epoch 76/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2430 - accuracy: 0.5625 - val_loss: 0.3025 - val_accuracy: 0.4231\n","Epoch 77/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2503 - accuracy: 0.5312 - val_loss: 0.2997 - val_accuracy: 0.4231\n","Epoch 78/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2438 - accuracy: 0.5625 - val_loss: 0.2984 - val_accuracy: 0.4231\n","Epoch 79/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2554 - accuracy: 0.4844 - val_loss: 0.3011 - val_accuracy: 0.4231\n","Epoch 80/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2606 - accuracy: 0.5000 - val_loss: 0.3062 - val_accuracy: 0.4231\n","Epoch 81/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2538 - accuracy: 0.5469 - val_loss: 0.3073 - val_accuracy: 0.4231\n","Epoch 82/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2441 - accuracy: 0.5156 - val_loss: 0.3036 - val_accuracy: 0.4231\n","Epoch 83/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2488 - accuracy: 0.5781 - val_loss: 0.2968 - val_accuracy: 0.4231\n","Epoch 84/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2430 - accuracy: 0.5938 - val_loss: 0.2909 - val_accuracy: 0.4231\n","Epoch 85/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2527 - accuracy: 0.4688 - val_loss: 0.2893 - val_accuracy: 0.4231\n","Epoch 86/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2493 - accuracy: 0.5156 - val_loss: 0.2928 - val_accuracy: 0.4231\n","Epoch 87/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2480 - accuracy: 0.5781 - val_loss: 0.2974 - val_accuracy: 0.4231\n","Epoch 88/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2564 - accuracy: 0.5156 - val_loss: 0.3012 - val_accuracy: 0.4231\n","Epoch 89/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2362 - accuracy: 0.6094 - val_loss: 0.3009 - val_accuracy: 0.4231\n","Epoch 90/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2523 - accuracy: 0.5156 - val_loss: 0.2982 - val_accuracy: 0.4231\n","Epoch 91/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2384 - accuracy: 0.6406 - val_loss: 0.2935 - val_accuracy: 0.4231\n","Epoch 92/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2429 - accuracy: 0.5625 - val_loss: 0.2888 - val_accuracy: 0.4231\n","Epoch 93/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2476 - accuracy: 0.5312 - val_loss: 0.2876 - val_accuracy: 0.4231\n","Epoch 94/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2459 - accuracy: 0.5156 - val_loss: 0.2892 - val_accuracy: 0.4231\n","Epoch 95/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2420 - accuracy: 0.5938 - val_loss: 0.2901 - val_accuracy: 0.4231\n","Epoch 96/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2393 - accuracy: 0.5625 - val_loss: 0.2912 - val_accuracy: 0.4231\n","Epoch 97/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2412 - accuracy: 0.5469 - val_loss: 0.2923 - val_accuracy: 0.4231\n","Epoch 98/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2432 - accuracy: 0.5469 - val_loss: 0.2933 - val_accuracy: 0.4231\n","Epoch 99/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2407 - accuracy: 0.5938 - val_loss: 0.2947 - val_accuracy: 0.4231\n","Epoch 100/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2470 - accuracy: 0.5469 - val_loss: 0.2956 - val_accuracy: 0.4231\n","Epoch 101/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2385 - accuracy: 0.6406 - val_loss: 0.2953 - val_accuracy: 0.4231\n","Epoch 102/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2475 - accuracy: 0.5938 - val_loss: 0.2965 - val_accuracy: 0.4231\n","Epoch 103/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2469 - accuracy: 0.5312 - val_loss: 0.2969 - val_accuracy: 0.4231\n","Epoch 104/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2562 - accuracy: 0.4844 - val_loss: 0.2989 - val_accuracy: 0.4231\n","Epoch 105/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2483 - accuracy: 0.5469 - val_loss: 0.3010 - val_accuracy: 0.4231\n","Epoch 106/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2487 - accuracy: 0.5312 - val_loss: 0.3011 - val_accuracy: 0.4231\n","Epoch 107/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2457 - accuracy: 0.5156 - val_loss: 0.3003 - val_accuracy: 0.4231\n","Epoch 108/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2439 - accuracy: 0.5469 - val_loss: 0.2962 - val_accuracy: 0.4231\n","Epoch 109/245\n","2/2 [==============================] - 3s 2s/step - loss: 0.2418 - accuracy: 0.5625 - val_loss: 0.2907 - val_accuracy: 0.4231\n","Epoch 110/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2465 - accuracy: 0.5469 - val_loss: 0.2895 - val_accuracy: 0.4231\n","Epoch 111/245\n","2/2 [==============================] - 3s 2s/step - loss: 0.2429 - accuracy: 0.5625 - val_loss: 0.2911 - val_accuracy: 0.4231\n","Epoch 112/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2515 - accuracy: 0.5625 - val_loss: 0.2954 - val_accuracy: 0.4231\n","Epoch 113/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2416 - accuracy: 0.6250 - val_loss: 0.2989 - val_accuracy: 0.4231\n","Epoch 114/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2476 - accuracy: 0.5469 - val_loss: 0.2986 - val_accuracy: 0.4231\n","Epoch 115/245\n","2/2 [==============================] - 3s 2s/step - loss: 0.2398 - accuracy: 0.5781 - val_loss: 0.2957 - val_accuracy: 0.4231\n","Epoch 116/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2376 - accuracy: 0.5938 - val_loss: 0.2914 - val_accuracy: 0.4231\n","Epoch 117/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2526 - accuracy: 0.5156 - val_loss: 0.2887 - val_accuracy: 0.4231\n","Epoch 118/245\n","2/2 [==============================] - 3s 2s/step - loss: 0.2446 - accuracy: 0.5938 - val_loss: 0.2882 - val_accuracy: 0.4231\n","Epoch 119/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2546 - accuracy: 0.4844 - val_loss: 0.2912 - val_accuracy: 0.4231\n","Epoch 120/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2538 - accuracy: 0.5469 - val_loss: 0.2947 - val_accuracy: 0.4231\n","Epoch 121/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2424 - accuracy: 0.5312 - val_loss: 0.2954 - val_accuracy: 0.4231\n","Epoch 122/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2477 - accuracy: 0.5156 - val_loss: 0.2939 - val_accuracy: 0.4231\n","Epoch 123/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2459 - accuracy: 0.5469 - val_loss: 0.2904 - val_accuracy: 0.4231\n","Epoch 124/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2415 - accuracy: 0.5938 - val_loss: 0.2872 - val_accuracy: 0.4231\n","Epoch 125/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2357 - accuracy: 0.6094 - val_loss: 0.2843 - val_accuracy: 0.4231\n","Epoch 126/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2358 - accuracy: 0.6250 - val_loss: 0.2830 - val_accuracy: 0.4231\n","Epoch 127/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2393 - accuracy: 0.5625 - val_loss: 0.2861 - val_accuracy: 0.4231\n","Epoch 128/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2392 - accuracy: 0.6250 - val_loss: 0.2924 - val_accuracy: 0.4231\n","Epoch 129/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2462 - accuracy: 0.5312 - val_loss: 0.2985 - val_accuracy: 0.4231\n","Epoch 130/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2523 - accuracy: 0.5156 - val_loss: 0.3030 - val_accuracy: 0.4231\n","Epoch 131/245\n","2/2 [==============================] - 3s 2s/step - loss: 0.2368 - accuracy: 0.6094 - val_loss: 0.3068 - val_accuracy: 0.4231\n","Epoch 132/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2390 - accuracy: 0.5938 - val_loss: 0.3071 - val_accuracy: 0.4231\n","Epoch 133/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2424 - accuracy: 0.5938 - val_loss: 0.3038 - val_accuracy: 0.4231\n","Epoch 134/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2449 - accuracy: 0.5781 - val_loss: 0.2992 - val_accuracy: 0.4231\n","Epoch 135/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2408 - accuracy: 0.5938 - val_loss: 0.2973 - val_accuracy: 0.4231\n","Epoch 136/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2490 - accuracy: 0.5312 - val_loss: 0.2989 - val_accuracy: 0.4231\n","Epoch 137/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2469 - accuracy: 0.5312 - val_loss: 0.3043 - val_accuracy: 0.4231\n","Epoch 138/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2377 - accuracy: 0.5938 - val_loss: 0.3092 - val_accuracy: 0.4231\n","Epoch 139/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2516 - accuracy: 0.5156 - val_loss: 0.3104 - val_accuracy: 0.4231\n","Epoch 140/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2559 - accuracy: 0.5156 - val_loss: 0.3082 - val_accuracy: 0.4231\n","Epoch 141/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2259 - accuracy: 0.6562 - val_loss: 0.3034 - val_accuracy: 0.4231\n","Epoch 142/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2359 - accuracy: 0.6406 - val_loss: 0.2964 - val_accuracy: 0.4231\n","Epoch 143/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2392 - accuracy: 0.6250 - val_loss: 0.2933 - val_accuracy: 0.4231\n","Epoch 144/245\n","2/2 [==============================] - 3s 2s/step - loss: 0.2327 - accuracy: 0.6094 - val_loss: 0.2963 - val_accuracy: 0.4231\n","Epoch 145/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2331 - accuracy: 0.5938 - val_loss: 0.3006 - val_accuracy: 0.4231\n","Epoch 146/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2473 - accuracy: 0.5000 - val_loss: 0.3056 - val_accuracy: 0.4231\n","Epoch 147/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2471 - accuracy: 0.5625 - val_loss: 0.3104 - val_accuracy: 0.4231\n","Epoch 148/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2467 - accuracy: 0.5938 - val_loss: 0.3151 - val_accuracy: 0.4231\n","Epoch 149/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2456 - accuracy: 0.5781 - val_loss: 0.3146 - val_accuracy: 0.4231\n","Epoch 150/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2501 - accuracy: 0.5625 - val_loss: 0.3105 - val_accuracy: 0.4231\n","Epoch 151/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2494 - accuracy: 0.4688 - val_loss: 0.3083 - val_accuracy: 0.4231\n","Epoch 152/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2385 - accuracy: 0.5938 - val_loss: 0.3041 - val_accuracy: 0.4231\n","Epoch 153/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2469 - accuracy: 0.5312 - val_loss: 0.2977 - val_accuracy: 0.4231\n","Epoch 154/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2326 - accuracy: 0.6094 - val_loss: 0.2928 - val_accuracy: 0.4231\n","Epoch 155/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2251 - accuracy: 0.6719 - val_loss: 0.2941 - val_accuracy: 0.4231\n","Epoch 156/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2243 - accuracy: 0.6562 - val_loss: 0.2987 - val_accuracy: 0.4231\n","Epoch 157/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2208 - accuracy: 0.6719 - val_loss: 0.3045 - val_accuracy: 0.4231\n","Epoch 158/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2475 - accuracy: 0.5469 - val_loss: 0.3093 - val_accuracy: 0.4231\n","Epoch 159/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2336 - accuracy: 0.5938 - val_loss: 0.3069 - val_accuracy: 0.4231\n","Epoch 160/245\n","2/2 [==============================] - 3s 2s/step - loss: 0.2362 - accuracy: 0.6250 - val_loss: 0.3017 - val_accuracy: 0.4231\n","Epoch 161/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2489 - accuracy: 0.5312 - val_loss: 0.3030 - val_accuracy: 0.4231\n","Epoch 162/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2556 - accuracy: 0.5781 - val_loss: 0.3164 - val_accuracy: 0.4231\n","Epoch 163/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2392 - accuracy: 0.5938 - val_loss: 0.3260 - val_accuracy: 0.4231\n","Epoch 164/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2555 - accuracy: 0.5156 - val_loss: 0.3256 - val_accuracy: 0.4231\n","Epoch 165/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2405 - accuracy: 0.5781 - val_loss: 0.3146 - val_accuracy: 0.4231\n","Epoch 166/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2550 - accuracy: 0.5000 - val_loss: 0.3019 - val_accuracy: 0.4231\n","Epoch 167/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2437 - accuracy: 0.5781 - val_loss: 0.2937 - val_accuracy: 0.4231\n","Epoch 168/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2395 - accuracy: 0.6719 - val_loss: 0.2928 - val_accuracy: 0.4231\n","Epoch 169/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2389 - accuracy: 0.6250 - val_loss: 0.2964 - val_accuracy: 0.4231\n","Epoch 170/245\n","2/2 [==============================] - 3s 2s/step - loss: 0.2463 - accuracy: 0.5312 - val_loss: 0.3018 - val_accuracy: 0.4231\n","Epoch 171/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2392 - accuracy: 0.6094 - val_loss: 0.3065 - val_accuracy: 0.4231\n","Epoch 172/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2341 - accuracy: 0.5938 - val_loss: 0.3068 - val_accuracy: 0.4231\n","Epoch 173/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2396 - accuracy: 0.5781 - val_loss: 0.3033 - val_accuracy: 0.4231\n","Epoch 174/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2442 - accuracy: 0.5781 - val_loss: 0.3026 - val_accuracy: 0.4231\n","Epoch 175/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2362 - accuracy: 0.5781 - val_loss: 0.3031 - val_accuracy: 0.4231\n","Epoch 176/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2446 - accuracy: 0.5469 - val_loss: 0.3049 - val_accuracy: 0.4231\n","Epoch 177/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2299 - accuracy: 0.6406 - val_loss: 0.3085 - val_accuracy: 0.4231\n","Epoch 178/245\n","2/2 [==============================] - 3s 2s/step - loss: 0.2481 - accuracy: 0.5000 - val_loss: 0.3110 - val_accuracy: 0.4231\n","Epoch 179/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2418 - accuracy: 0.5312 - val_loss: 0.3127 - val_accuracy: 0.4231\n","Epoch 180/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2426 - accuracy: 0.5469 - val_loss: 0.3128 - val_accuracy: 0.4231\n","Epoch 181/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2546 - accuracy: 0.5000 - val_loss: 0.3119 - val_accuracy: 0.4231\n","Epoch 182/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2359 - accuracy: 0.6250 - val_loss: 0.3094 - val_accuracy: 0.4231\n","Epoch 183/245\n","2/2 [==============================] - 3s 2s/step - loss: 0.2497 - accuracy: 0.5000 - val_loss: 0.3049 - val_accuracy: 0.4231\n","Epoch 184/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2436 - accuracy: 0.5469 - val_loss: 0.2992 - val_accuracy: 0.4231\n","Epoch 185/245\n","2/2 [==============================] - 3s 2s/step - loss: 0.2439 - accuracy: 0.5469 - val_loss: 0.2964 - val_accuracy: 0.4231\n","Epoch 186/245\n","2/2 [==============================] - 3s 2s/step - loss: 0.2364 - accuracy: 0.6406 - val_loss: 0.2957 - val_accuracy: 0.4231\n","Epoch 187/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2404 - accuracy: 0.5625 - val_loss: 0.2965 - val_accuracy: 0.4231\n","Epoch 188/245\n","2/2 [==============================] - 3s 2s/step - loss: 0.2283 - accuracy: 0.6250 - val_loss: 0.2988 - val_accuracy: 0.4231\n","Epoch 189/245\n","2/2 [==============================] - 3s 2s/step - loss: 0.2476 - accuracy: 0.5469 - val_loss: 0.3028 - val_accuracy: 0.4231\n","Epoch 190/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2417 - accuracy: 0.5781 - val_loss: 0.3058 - val_accuracy: 0.4231\n","Epoch 191/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2326 - accuracy: 0.6719 - val_loss: 0.3071 - val_accuracy: 0.4231\n","Epoch 192/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2310 - accuracy: 0.5781 - val_loss: 0.3073 - val_accuracy: 0.4231\n","Epoch 193/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2370 - accuracy: 0.5469 - val_loss: 0.3082 - val_accuracy: 0.4231\n","Epoch 194/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2311 - accuracy: 0.6094 - val_loss: 0.3093 - val_accuracy: 0.4231\n","Epoch 195/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2250 - accuracy: 0.5938 - val_loss: 0.3113 - val_accuracy: 0.4231\n","Epoch 196/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2519 - accuracy: 0.5156 - val_loss: 0.3159 - val_accuracy: 0.4231\n","Epoch 197/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2415 - accuracy: 0.6406 - val_loss: 0.3196 - val_accuracy: 0.4231\n","Epoch 198/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2388 - accuracy: 0.5469 - val_loss: 0.3174 - val_accuracy: 0.4231\n","Epoch 199/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2442 - accuracy: 0.5781 - val_loss: 0.3147 - val_accuracy: 0.4231\n","Epoch 200/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2343 - accuracy: 0.5781 - val_loss: 0.3133 - val_accuracy: 0.4231\n","Epoch 201/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2457 - accuracy: 0.5312 - val_loss: 0.3118 - val_accuracy: 0.4231\n","Epoch 202/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2380 - accuracy: 0.5938 - val_loss: 0.3137 - val_accuracy: 0.4231\n","Epoch 203/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2343 - accuracy: 0.5781 - val_loss: 0.3152 - val_accuracy: 0.4231\n","Epoch 204/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2303 - accuracy: 0.6094 - val_loss: 0.3127 - val_accuracy: 0.4231\n","Epoch 205/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2386 - accuracy: 0.6250 - val_loss: 0.3099 - val_accuracy: 0.4231\n","Epoch 206/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2372 - accuracy: 0.5625 - val_loss: 0.3056 - val_accuracy: 0.4231\n","Epoch 207/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2294 - accuracy: 0.6094 - val_loss: 0.3019 - val_accuracy: 0.4231\n","Epoch 208/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2405 - accuracy: 0.5312 - val_loss: 0.3046 - val_accuracy: 0.4231\n","Epoch 209/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2332 - accuracy: 0.5938 - val_loss: 0.3091 - val_accuracy: 0.4231\n","Epoch 210/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2414 - accuracy: 0.5469 - val_loss: 0.3153 - val_accuracy: 0.4231\n","Epoch 211/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2401 - accuracy: 0.6250 - val_loss: 0.3165 - val_accuracy: 0.4231\n","Epoch 212/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2391 - accuracy: 0.5938 - val_loss: 0.3109 - val_accuracy: 0.4231\n","Epoch 213/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2420 - accuracy: 0.5469 - val_loss: 0.3032 - val_accuracy: 0.4231\n","Epoch 214/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2392 - accuracy: 0.5469 - val_loss: 0.2991 - val_accuracy: 0.4231\n","Epoch 215/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2267 - accuracy: 0.6094 - val_loss: 0.3002 - val_accuracy: 0.4231\n","Epoch 216/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2380 - accuracy: 0.6094 - val_loss: 0.3054 - val_accuracy: 0.4231\n","Epoch 217/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2314 - accuracy: 0.6094 - val_loss: 0.3087 - val_accuracy: 0.4231\n","Epoch 218/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2419 - accuracy: 0.5625 - val_loss: 0.3094 - val_accuracy: 0.4231\n","Epoch 219/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2331 - accuracy: 0.5781 - val_loss: 0.3072 - val_accuracy: 0.4231\n","Epoch 220/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2176 - accuracy: 0.6719 - val_loss: 0.3043 - val_accuracy: 0.4231\n","Epoch 221/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2287 - accuracy: 0.6875 - val_loss: 0.3015 - val_accuracy: 0.4231\n","Epoch 222/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2551 - accuracy: 0.5156 - val_loss: 0.3024 - val_accuracy: 0.4231\n","Epoch 223/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2391 - accuracy: 0.6406 - val_loss: 0.3067 - val_accuracy: 0.4231\n","Epoch 224/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2428 - accuracy: 0.5625 - val_loss: 0.3135 - val_accuracy: 0.4231\n","Epoch 225/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2416 - accuracy: 0.5312 - val_loss: 0.3167 - val_accuracy: 0.4231\n","Epoch 226/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2352 - accuracy: 0.5938 - val_loss: 0.3127 - val_accuracy: 0.4231\n","Epoch 227/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2309 - accuracy: 0.6094 - val_loss: 0.3025 - val_accuracy: 0.4231\n","Epoch 228/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2385 - accuracy: 0.5781 - val_loss: 0.2943 - val_accuracy: 0.4231\n","Epoch 229/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2427 - accuracy: 0.6250 - val_loss: 0.2900 - val_accuracy: 0.4231\n","Epoch 230/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2416 - accuracy: 0.6719 - val_loss: 0.2899 - val_accuracy: 0.4231\n","Epoch 231/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2308 - accuracy: 0.6250 - val_loss: 0.2938 - val_accuracy: 0.4231\n","Epoch 232/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2343 - accuracy: 0.5625 - val_loss: 0.2968 - val_accuracy: 0.4231\n","Epoch 233/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2374 - accuracy: 0.5938 - val_loss: 0.2999 - val_accuracy: 0.4231\n","Epoch 234/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2385 - accuracy: 0.5781 - val_loss: 0.3018 - val_accuracy: 0.4231\n","Epoch 235/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2503 - accuracy: 0.5156 - val_loss: 0.3026 - val_accuracy: 0.4231\n","Epoch 236/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2405 - accuracy: 0.6094 - val_loss: 0.3002 - val_accuracy: 0.4231\n","Epoch 237/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2360 - accuracy: 0.6250 - val_loss: 0.2957 - val_accuracy: 0.4231\n","Epoch 238/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2379 - accuracy: 0.5781 - val_loss: 0.2920 - val_accuracy: 0.4231\n","Epoch 239/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2403 - accuracy: 0.6406 - val_loss: 0.2900 - val_accuracy: 0.4231\n","Epoch 240/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2451 - accuracy: 0.6094 - val_loss: 0.2912 - val_accuracy: 0.4231\n","Epoch 241/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2322 - accuracy: 0.6250 - val_loss: 0.2920 - val_accuracy: 0.4231\n","Epoch 242/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2334 - accuracy: 0.5938 - val_loss: 0.2916 - val_accuracy: 0.4231\n","Epoch 243/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2331 - accuracy: 0.6250 - val_loss: 0.2926 - val_accuracy: 0.4231\n","Epoch 244/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2409 - accuracy: 0.5938 - val_loss: 0.2953 - val_accuracy: 0.4231\n","Epoch 245/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2552 - accuracy: 0.5312 - val_loss: 0.3024 - val_accuracy: 0.4231\n","1/1 [==============================] - 0s 106ms/step - loss: 0.3024 - accuracy: 0.4231\n","loss :  0.42307692766189575\n","total_loss :  2.576923131942749\n","num :  5\n","WARNING:tensorflow:Layer gru_25 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","WARNING:tensorflow:Layer gru_26 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","WARNING:tensorflow:Layer gru_27 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","WARNING:tensorflow:Layer gru_28 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","WARNING:tensorflow:Layer gru_29 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","Epoch 1/245\n","2/2 [==============================] - 12s 2s/step - loss: 0.5236 - accuracy: 0.4688 - val_loss: 0.4800 - val_accuracy: 0.4615\n","Epoch 2/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.3755 - accuracy: 0.4688 - val_loss: 0.3863 - val_accuracy: 0.4615\n","Epoch 3/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2644 - accuracy: 0.5469 - val_loss: 0.2884 - val_accuracy: 0.4615\n","Epoch 4/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.3322 - accuracy: 0.5000 - val_loss: 0.2962 - val_accuracy: 0.4615\n","Epoch 5/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.3086 - accuracy: 0.5000 - val_loss: 0.3293 - val_accuracy: 0.4615\n","Epoch 6/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2682 - accuracy: 0.5312 - val_loss: 0.3579 - val_accuracy: 0.4615\n","Epoch 7/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2880 - accuracy: 0.4219 - val_loss: 0.3678 - val_accuracy: 0.4615\n","Epoch 8/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2849 - accuracy: 0.5156 - val_loss: 0.3629 - val_accuracy: 0.4615\n","Epoch 9/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2824 - accuracy: 0.4844 - val_loss: 0.3461 - val_accuracy: 0.4615\n","Epoch 10/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2620 - accuracy: 0.5312 - val_loss: 0.3216 - val_accuracy: 0.4615\n","Epoch 11/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2585 - accuracy: 0.4844 - val_loss: 0.2967 - val_accuracy: 0.4615\n","Epoch 12/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2600 - accuracy: 0.5625 - val_loss: 0.2841 - val_accuracy: 0.4615\n","Epoch 13/245\n","2/2 [==============================] - 3s 2s/step - loss: 0.2627 - accuracy: 0.5000 - val_loss: 0.2847 - val_accuracy: 0.4615\n","Epoch 14/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2687 - accuracy: 0.5156 - val_loss: 0.2959 - val_accuracy: 0.4615\n","Epoch 15/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2571 - accuracy: 0.5469 - val_loss: 0.3078 - val_accuracy: 0.4615\n","Epoch 16/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2488 - accuracy: 0.5312 - val_loss: 0.3154 - val_accuracy: 0.4615\n","Epoch 17/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2378 - accuracy: 0.6094 - val_loss: 0.3143 - val_accuracy: 0.4615\n","Epoch 18/245\n","2/2 [==============================] - 3s 2s/step - loss: 0.2575 - accuracy: 0.4688 - val_loss: 0.3094 - val_accuracy: 0.4615\n","Epoch 19/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2637 - accuracy: 0.4531 - val_loss: 0.3035 - val_accuracy: 0.4615\n","Epoch 20/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2475 - accuracy: 0.6094 - val_loss: 0.2974 - val_accuracy: 0.4615\n","Epoch 21/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2455 - accuracy: 0.5469 - val_loss: 0.2911 - val_accuracy: 0.4615\n","Epoch 22/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2553 - accuracy: 0.5000 - val_loss: 0.2899 - val_accuracy: 0.4615\n","Epoch 23/245\n","2/2 [==============================] - 3s 2s/step - loss: 0.2530 - accuracy: 0.5312 - val_loss: 0.2945 - val_accuracy: 0.4615\n","Epoch 24/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2599 - accuracy: 0.4844 - val_loss: 0.3010 - val_accuracy: 0.4615\n","Epoch 25/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2521 - accuracy: 0.4688 - val_loss: 0.3055 - val_accuracy: 0.4615\n","Epoch 26/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2529 - accuracy: 0.5156 - val_loss: 0.3079 - val_accuracy: 0.4615\n","Epoch 27/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2452 - accuracy: 0.5000 - val_loss: 0.3064 - val_accuracy: 0.4615\n","Epoch 28/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2458 - accuracy: 0.5156 - val_loss: 0.3013 - val_accuracy: 0.4615\n","Epoch 29/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2489 - accuracy: 0.5625 - val_loss: 0.2953 - val_accuracy: 0.4615\n","Epoch 30/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2726 - accuracy: 0.4531 - val_loss: 0.2957 - val_accuracy: 0.4615\n","Epoch 31/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2529 - accuracy: 0.5312 - val_loss: 0.2968 - val_accuracy: 0.4615\n","Epoch 32/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2556 - accuracy: 0.5156 - val_loss: 0.2978 - val_accuracy: 0.4615\n","Epoch 33/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2573 - accuracy: 0.4844 - val_loss: 0.2984 - val_accuracy: 0.4615\n","Epoch 34/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2351 - accuracy: 0.6250 - val_loss: 0.2972 - val_accuracy: 0.4615\n","Epoch 35/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2569 - accuracy: 0.4844 - val_loss: 0.2956 - val_accuracy: 0.4615\n","Epoch 36/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2575 - accuracy: 0.4531 - val_loss: 0.2940 - val_accuracy: 0.4615\n","Epoch 37/245\n","2/2 [==============================] - 3s 2s/step - loss: 0.2546 - accuracy: 0.5156 - val_loss: 0.2933 - val_accuracy: 0.4615\n","Epoch 38/245\n","2/2 [==============================] - 3s 2s/step - loss: 0.2557 - accuracy: 0.4688 - val_loss: 0.2927 - val_accuracy: 0.4615\n","Epoch 39/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2484 - accuracy: 0.4844 - val_loss: 0.2914 - val_accuracy: 0.4615\n","Epoch 40/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2640 - accuracy: 0.5312 - val_loss: 0.2916 - val_accuracy: 0.4615\n","Epoch 41/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2492 - accuracy: 0.5469 - val_loss: 0.2914 - val_accuracy: 0.4615\n","Epoch 42/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2584 - accuracy: 0.4688 - val_loss: 0.2904 - val_accuracy: 0.4615\n","Epoch 43/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2617 - accuracy: 0.4688 - val_loss: 0.2892 - val_accuracy: 0.4615\n","Epoch 44/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2551 - accuracy: 0.5625 - val_loss: 0.2873 - val_accuracy: 0.4615\n","Epoch 45/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2509 - accuracy: 0.5781 - val_loss: 0.2836 - val_accuracy: 0.4615\n","Epoch 46/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2365 - accuracy: 0.6719 - val_loss: 0.2791 - val_accuracy: 0.4615\n","Epoch 47/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2448 - accuracy: 0.5625 - val_loss: 0.2779 - val_accuracy: 0.4615\n","Epoch 48/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2450 - accuracy: 0.5625 - val_loss: 0.2793 - val_accuracy: 0.4615\n","Epoch 49/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2502 - accuracy: 0.4219 - val_loss: 0.2809 - val_accuracy: 0.4615\n","Epoch 50/245\n","2/2 [==============================] - 3s 2s/step - loss: 0.2471 - accuracy: 0.5312 - val_loss: 0.2797 - val_accuracy: 0.4615\n","Epoch 51/245\n","2/2 [==============================] - 3s 2s/step - loss: 0.2574 - accuracy: 0.4688 - val_loss: 0.2771 - val_accuracy: 0.4615\n","Epoch 52/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2600 - accuracy: 0.4844 - val_loss: 0.2758 - val_accuracy: 0.4615\n","Epoch 53/245\n","2/2 [==============================] - 3s 2s/step - loss: 0.2539 - accuracy: 0.5312 - val_loss: 0.2747 - val_accuracy: 0.4615\n","Epoch 54/245\n","2/2 [==============================] - 3s 2s/step - loss: 0.2615 - accuracy: 0.4844 - val_loss: 0.2750 - val_accuracy: 0.4615\n","Epoch 55/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2642 - accuracy: 0.4531 - val_loss: 0.2760 - val_accuracy: 0.4615\n","Epoch 56/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2441 - accuracy: 0.5625 - val_loss: 0.2749 - val_accuracy: 0.4615\n","Epoch 57/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2495 - accuracy: 0.5938 - val_loss: 0.2724 - val_accuracy: 0.4615\n","Epoch 58/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2572 - accuracy: 0.4844 - val_loss: 0.2725 - val_accuracy: 0.4615\n","Epoch 59/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2595 - accuracy: 0.5312 - val_loss: 0.2728 - val_accuracy: 0.4615\n","Epoch 60/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2568 - accuracy: 0.4375 - val_loss: 0.2731 - val_accuracy: 0.4615\n","Epoch 61/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2535 - accuracy: 0.5312 - val_loss: 0.2723 - val_accuracy: 0.4615\n","Epoch 62/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2678 - accuracy: 0.4531 - val_loss: 0.2709 - val_accuracy: 0.4615\n","Epoch 63/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2494 - accuracy: 0.5312 - val_loss: 0.2686 - val_accuracy: 0.4615\n","Epoch 64/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2445 - accuracy: 0.5625 - val_loss: 0.2658 - val_accuracy: 0.4615\n","Epoch 65/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2530 - accuracy: 0.4219 - val_loss: 0.2645 - val_accuracy: 0.4615\n","Epoch 66/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2503 - accuracy: 0.5312 - val_loss: 0.2652 - val_accuracy: 0.4615\n","Epoch 67/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2460 - accuracy: 0.5938 - val_loss: 0.2658 - val_accuracy: 0.4615\n","Epoch 68/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2538 - accuracy: 0.5312 - val_loss: 0.2664 - val_accuracy: 0.4615\n","Epoch 69/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2503 - accuracy: 0.5781 - val_loss: 0.2677 - val_accuracy: 0.4615\n","Epoch 70/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2498 - accuracy: 0.5625 - val_loss: 0.2689 - val_accuracy: 0.4615\n","Epoch 71/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2467 - accuracy: 0.5625 - val_loss: 0.2689 - val_accuracy: 0.4615\n","Epoch 72/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2485 - accuracy: 0.5312 - val_loss: 0.2686 - val_accuracy: 0.4615\n","Epoch 73/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2470 - accuracy: 0.5469 - val_loss: 0.2682 - val_accuracy: 0.4615\n","Epoch 74/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2514 - accuracy: 0.4531 - val_loss: 0.2676 - val_accuracy: 0.4615\n","Epoch 75/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2568 - accuracy: 0.5000 - val_loss: 0.2676 - val_accuracy: 0.4615\n","Epoch 76/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2414 - accuracy: 0.5000 - val_loss: 0.2644 - val_accuracy: 0.4615\n","Epoch 77/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2413 - accuracy: 0.6094 - val_loss: 0.2614 - val_accuracy: 0.4615\n","Epoch 78/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2561 - accuracy: 0.4844 - val_loss: 0.2610 - val_accuracy: 0.4615\n","Epoch 79/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2534 - accuracy: 0.5156 - val_loss: 0.2623 - val_accuracy: 0.4615\n","Epoch 80/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2598 - accuracy: 0.4062 - val_loss: 0.2646 - val_accuracy: 0.4615\n","Epoch 81/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2517 - accuracy: 0.5469 - val_loss: 0.2671 - val_accuracy: 0.4615\n","Epoch 82/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2552 - accuracy: 0.4531 - val_loss: 0.2683 - val_accuracy: 0.4615\n","Epoch 83/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2548 - accuracy: 0.4844 - val_loss: 0.2684 - val_accuracy: 0.4615\n","Epoch 84/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2571 - accuracy: 0.4844 - val_loss: 0.2675 - val_accuracy: 0.4615\n","Epoch 85/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2456 - accuracy: 0.5625 - val_loss: 0.2652 - val_accuracy: 0.4615\n","Epoch 86/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2595 - accuracy: 0.4688 - val_loss: 0.2643 - val_accuracy: 0.4615\n","Epoch 87/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2504 - accuracy: 0.5156 - val_loss: 0.2646 - val_accuracy: 0.4615\n","Epoch 88/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2560 - accuracy: 0.4375 - val_loss: 0.2666 - val_accuracy: 0.4615\n","Epoch 89/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2428 - accuracy: 0.5469 - val_loss: 0.2664 - val_accuracy: 0.4615\n","Epoch 90/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2455 - accuracy: 0.6250 - val_loss: 0.2657 - val_accuracy: 0.4615\n","Epoch 91/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2483 - accuracy: 0.5625 - val_loss: 0.2642 - val_accuracy: 0.4615\n","Epoch 92/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2566 - accuracy: 0.4844 - val_loss: 0.2633 - val_accuracy: 0.4615\n","Epoch 93/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2478 - accuracy: 0.5469 - val_loss: 0.2620 - val_accuracy: 0.4615\n","Epoch 94/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2461 - accuracy: 0.5469 - val_loss: 0.2611 - val_accuracy: 0.4615\n","Epoch 95/245\n","2/2 [==============================] - 3s 2s/step - loss: 0.2576 - accuracy: 0.5312 - val_loss: 0.2613 - val_accuracy: 0.4615\n","Epoch 96/245\n","2/2 [==============================] - 3s 2s/step - loss: 0.2561 - accuracy: 0.5312 - val_loss: 0.2625 - val_accuracy: 0.4615\n","Epoch 97/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2533 - accuracy: 0.4688 - val_loss: 0.2624 - val_accuracy: 0.4615\n","Epoch 98/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2447 - accuracy: 0.5312 - val_loss: 0.2621 - val_accuracy: 0.4615\n","Epoch 99/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2423 - accuracy: 0.5938 - val_loss: 0.2608 - val_accuracy: 0.4615\n","Epoch 100/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2424 - accuracy: 0.6094 - val_loss: 0.2585 - val_accuracy: 0.4615\n","Epoch 101/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2559 - accuracy: 0.5000 - val_loss: 0.2581 - val_accuracy: 0.4615\n","Epoch 102/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2607 - accuracy: 0.5469 - val_loss: 0.2599 - val_accuracy: 0.4615\n","Epoch 103/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2525 - accuracy: 0.4375 - val_loss: 0.2618 - val_accuracy: 0.4615\n","Epoch 104/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2480 - accuracy: 0.5156 - val_loss: 0.2617 - val_accuracy: 0.4615\n","Epoch 105/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2442 - accuracy: 0.5469 - val_loss: 0.2602 - val_accuracy: 0.4615\n","Epoch 106/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2431 - accuracy: 0.5625 - val_loss: 0.2576 - val_accuracy: 0.4615\n","Epoch 107/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2528 - accuracy: 0.5469 - val_loss: 0.2558 - val_accuracy: 0.4615\n","Epoch 108/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2595 - accuracy: 0.5000 - val_loss: 0.2563 - val_accuracy: 0.4615\n","Epoch 109/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2522 - accuracy: 0.5312 - val_loss: 0.2569 - val_accuracy: 0.4615\n","Epoch 110/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2560 - accuracy: 0.5156 - val_loss: 0.2579 - val_accuracy: 0.4615\n","Epoch 111/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2597 - accuracy: 0.4375 - val_loss: 0.2579 - val_accuracy: 0.4615\n","Epoch 112/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2443 - accuracy: 0.5781 - val_loss: 0.2559 - val_accuracy: 0.4615\n","Epoch 113/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2553 - accuracy: 0.4688 - val_loss: 0.2539 - val_accuracy: 0.4615\n","Epoch 114/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2512 - accuracy: 0.4844 - val_loss: 0.2528 - val_accuracy: 0.4615\n","Epoch 115/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2512 - accuracy: 0.4844 - val_loss: 0.2528 - val_accuracy: 0.4615\n","Epoch 116/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2572 - accuracy: 0.5312 - val_loss: 0.2540 - val_accuracy: 0.4615\n","Epoch 117/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2443 - accuracy: 0.5781 - val_loss: 0.2544 - val_accuracy: 0.4615\n","Epoch 118/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2463 - accuracy: 0.5469 - val_loss: 0.2540 - val_accuracy: 0.4615\n","Epoch 119/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2478 - accuracy: 0.5938 - val_loss: 0.2530 - val_accuracy: 0.4615\n","Epoch 120/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2456 - accuracy: 0.5625 - val_loss: 0.2524 - val_accuracy: 0.4615\n","Epoch 121/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2560 - accuracy: 0.5000 - val_loss: 0.2528 - val_accuracy: 0.4615\n","Epoch 122/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2532 - accuracy: 0.4375 - val_loss: 0.2541 - val_accuracy: 0.4615\n","Epoch 123/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2549 - accuracy: 0.5156 - val_loss: 0.2554 - val_accuracy: 0.4615\n","Epoch 124/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2559 - accuracy: 0.5156 - val_loss: 0.2560 - val_accuracy: 0.4615\n","Epoch 125/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2468 - accuracy: 0.6250 - val_loss: 0.2543 - val_accuracy: 0.4615\n","Epoch 126/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2535 - accuracy: 0.4688 - val_loss: 0.2518 - val_accuracy: 0.4615\n","Epoch 127/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2387 - accuracy: 0.6250 - val_loss: 0.2494 - val_accuracy: 0.5000\n","Epoch 128/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2499 - accuracy: 0.5625 - val_loss: 0.2483 - val_accuracy: 0.6154\n","Epoch 129/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2558 - accuracy: 0.5312 - val_loss: 0.2490 - val_accuracy: 0.4615\n","Epoch 130/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2666 - accuracy: 0.5156 - val_loss: 0.2519 - val_accuracy: 0.4615\n","Epoch 131/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2471 - accuracy: 0.5156 - val_loss: 0.2543 - val_accuracy: 0.4615\n","Epoch 132/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2463 - accuracy: 0.5625 - val_loss: 0.2544 - val_accuracy: 0.4615\n","Epoch 133/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2551 - accuracy: 0.3906 - val_loss: 0.2530 - val_accuracy: 0.4615\n","Epoch 134/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2490 - accuracy: 0.5156 - val_loss: 0.2508 - val_accuracy: 0.4615\n","Epoch 135/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2533 - accuracy: 0.4688 - val_loss: 0.2491 - val_accuracy: 0.4615\n","Epoch 136/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2547 - accuracy: 0.5312 - val_loss: 0.2490 - val_accuracy: 0.4615\n","Epoch 137/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2478 - accuracy: 0.5312 - val_loss: 0.2498 - val_accuracy: 0.5000\n","Epoch 138/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2511 - accuracy: 0.5469 - val_loss: 0.2506 - val_accuracy: 0.4615\n","Epoch 139/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2484 - accuracy: 0.5625 - val_loss: 0.2515 - val_accuracy: 0.4615\n","Epoch 140/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2505 - accuracy: 0.3906 - val_loss: 0.2515 - val_accuracy: 0.4615\n","Epoch 141/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2476 - accuracy: 0.5000 - val_loss: 0.2513 - val_accuracy: 0.4615\n","Epoch 142/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2489 - accuracy: 0.5625 - val_loss: 0.2509 - val_accuracy: 0.4615\n","Epoch 143/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2540 - accuracy: 0.5156 - val_loss: 0.2507 - val_accuracy: 0.4615\n","Epoch 144/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2510 - accuracy: 0.4844 - val_loss: 0.2509 - val_accuracy: 0.4615\n","Epoch 145/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2542 - accuracy: 0.5312 - val_loss: 0.2516 - val_accuracy: 0.4615\n","Epoch 146/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2510 - accuracy: 0.5312 - val_loss: 0.2522 - val_accuracy: 0.4615\n","Epoch 147/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2528 - accuracy: 0.4688 - val_loss: 0.2532 - val_accuracy: 0.4615\n","Epoch 148/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2630 - accuracy: 0.4375 - val_loss: 0.2539 - val_accuracy: 0.4615\n","Epoch 149/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2552 - accuracy: 0.5000 - val_loss: 0.2540 - val_accuracy: 0.4615\n","Epoch 150/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2455 - accuracy: 0.5156 - val_loss: 0.2530 - val_accuracy: 0.4615\n","Epoch 151/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2547 - accuracy: 0.5781 - val_loss: 0.2523 - val_accuracy: 0.4615\n","Epoch 152/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2431 - accuracy: 0.5469 - val_loss: 0.2513 - val_accuracy: 0.4615\n","Epoch 153/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2504 - accuracy: 0.5156 - val_loss: 0.2506 - val_accuracy: 0.4615\n","Epoch 154/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2552 - accuracy: 0.4688 - val_loss: 0.2505 - val_accuracy: 0.4615\n","Epoch 155/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2505 - accuracy: 0.5625 - val_loss: 0.2510 - val_accuracy: 0.4615\n","Epoch 156/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2479 - accuracy: 0.5312 - val_loss: 0.2514 - val_accuracy: 0.4615\n","Epoch 157/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2466 - accuracy: 0.5625 - val_loss: 0.2514 - val_accuracy: 0.4615\n","Epoch 158/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2426 - accuracy: 0.6094 - val_loss: 0.2503 - val_accuracy: 0.4615\n","Epoch 159/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2489 - accuracy: 0.5312 - val_loss: 0.2494 - val_accuracy: 0.4615\n","Epoch 160/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2468 - accuracy: 0.5469 - val_loss: 0.2489 - val_accuracy: 0.5385\n","Epoch 161/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2496 - accuracy: 0.5312 - val_loss: 0.2487 - val_accuracy: 0.6154\n","Epoch 162/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2583 - accuracy: 0.5000 - val_loss: 0.2495 - val_accuracy: 0.4615\n","Epoch 163/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2508 - accuracy: 0.5469 - val_loss: 0.2506 - val_accuracy: 0.4615\n","Epoch 164/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2542 - accuracy: 0.5625 - val_loss: 0.2513 - val_accuracy: 0.4615\n","Epoch 165/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2464 - accuracy: 0.5938 - val_loss: 0.2511 - val_accuracy: 0.4615\n","Epoch 166/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2464 - accuracy: 0.5156 - val_loss: 0.2501 - val_accuracy: 0.4615\n","Epoch 167/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2477 - accuracy: 0.5000 - val_loss: 0.2490 - val_accuracy: 0.5385\n","Epoch 168/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2555 - accuracy: 0.5000 - val_loss: 0.2488 - val_accuracy: 0.6154\n","Epoch 169/245\n","2/2 [==============================] - 3s 2s/step - loss: 0.2516 - accuracy: 0.5312 - val_loss: 0.2492 - val_accuracy: 0.5000\n","Epoch 170/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2502 - accuracy: 0.5781 - val_loss: 0.2501 - val_accuracy: 0.4615\n","Epoch 171/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2492 - accuracy: 0.5312 - val_loss: 0.2507 - val_accuracy: 0.4615\n","Epoch 172/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2519 - accuracy: 0.5156 - val_loss: 0.2503 - val_accuracy: 0.5000\n","Epoch 173/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2481 - accuracy: 0.5625 - val_loss: 0.2495 - val_accuracy: 0.4231\n","Epoch 174/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2519 - accuracy: 0.4531 - val_loss: 0.2487 - val_accuracy: 0.5769\n","Epoch 175/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2481 - accuracy: 0.5156 - val_loss: 0.2485 - val_accuracy: 0.6538\n","Epoch 176/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2497 - accuracy: 0.5312 - val_loss: 0.2483 - val_accuracy: 0.6154\n","Epoch 177/245\n","2/2 [==============================] - 3s 2s/step - loss: 0.2547 - accuracy: 0.5469 - val_loss: 0.2486 - val_accuracy: 0.6154\n","Epoch 178/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2474 - accuracy: 0.4844 - val_loss: 0.2485 - val_accuracy: 0.6154\n","Epoch 179/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2574 - accuracy: 0.4844 - val_loss: 0.2485 - val_accuracy: 0.6154\n","Epoch 180/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2532 - accuracy: 0.5000 - val_loss: 0.2485 - val_accuracy: 0.6154\n","Epoch 181/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2505 - accuracy: 0.5625 - val_loss: 0.2484 - val_accuracy: 0.6538\n","Epoch 182/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2451 - accuracy: 0.5156 - val_loss: 0.2482 - val_accuracy: 0.6538\n","Epoch 183/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2531 - accuracy: 0.5312 - val_loss: 0.2483 - val_accuracy: 0.6538\n","Epoch 184/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2558 - accuracy: 0.5156 - val_loss: 0.2487 - val_accuracy: 0.5769\n","Epoch 185/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2504 - accuracy: 0.5312 - val_loss: 0.2491 - val_accuracy: 0.5000\n","Epoch 186/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2467 - accuracy: 0.6094 - val_loss: 0.2491 - val_accuracy: 0.5000\n","Epoch 187/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2476 - accuracy: 0.5312 - val_loss: 0.2487 - val_accuracy: 0.6538\n","Epoch 188/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2492 - accuracy: 0.4844 - val_loss: 0.2482 - val_accuracy: 0.5385\n","Epoch 189/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2480 - accuracy: 0.5469 - val_loss: 0.2479 - val_accuracy: 0.5385\n","Epoch 190/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2588 - accuracy: 0.5312 - val_loss: 0.2480 - val_accuracy: 0.5385\n","Epoch 191/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2465 - accuracy: 0.5000 - val_loss: 0.2482 - val_accuracy: 0.5385\n","Epoch 192/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2494 - accuracy: 0.5469 - val_loss: 0.2482 - val_accuracy: 0.5385\n","Epoch 193/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2463 - accuracy: 0.5625 - val_loss: 0.2480 - val_accuracy: 0.5385\n","Epoch 194/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2604 - accuracy: 0.5156 - val_loss: 0.2483 - val_accuracy: 0.5769\n","Epoch 195/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2503 - accuracy: 0.5625 - val_loss: 0.2484 - val_accuracy: 0.6538\n","Epoch 196/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2507 - accuracy: 0.5312 - val_loss: 0.2483 - val_accuracy: 0.5769\n","Epoch 197/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2446 - accuracy: 0.5469 - val_loss: 0.2479 - val_accuracy: 0.5385\n","Epoch 198/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2540 - accuracy: 0.5469 - val_loss: 0.2476 - val_accuracy: 0.5385\n","Epoch 199/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2463 - accuracy: 0.5312 - val_loss: 0.2476 - val_accuracy: 0.5385\n","Epoch 200/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2511 - accuracy: 0.5469 - val_loss: 0.2478 - val_accuracy: 0.5385\n","Epoch 201/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2618 - accuracy: 0.5000 - val_loss: 0.2483 - val_accuracy: 0.5385\n","Epoch 202/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2465 - accuracy: 0.5312 - val_loss: 0.2486 - val_accuracy: 0.6538\n","Epoch 203/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2501 - accuracy: 0.5312 - val_loss: 0.2485 - val_accuracy: 0.6538\n","Epoch 204/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2490 - accuracy: 0.5625 - val_loss: 0.2482 - val_accuracy: 0.5385\n","Epoch 205/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2474 - accuracy: 0.5312 - val_loss: 0.2476 - val_accuracy: 0.5385\n","Epoch 206/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2444 - accuracy: 0.5625 - val_loss: 0.2473 - val_accuracy: 0.5385\n","Epoch 207/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2490 - accuracy: 0.5000 - val_loss: 0.2473 - val_accuracy: 0.5385\n","Epoch 208/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2541 - accuracy: 0.5312 - val_loss: 0.2474 - val_accuracy: 0.5385\n","Epoch 209/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2478 - accuracy: 0.5000 - val_loss: 0.2477 - val_accuracy: 0.5385\n","Epoch 210/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2475 - accuracy: 0.5312 - val_loss: 0.2482 - val_accuracy: 0.5769\n","Epoch 211/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2526 - accuracy: 0.4844 - val_loss: 0.2486 - val_accuracy: 0.6538\n","Epoch 212/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2453 - accuracy: 0.5312 - val_loss: 0.2485 - val_accuracy: 0.6538\n","Epoch 213/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2540 - accuracy: 0.5156 - val_loss: 0.2481 - val_accuracy: 0.5385\n","Epoch 214/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2490 - accuracy: 0.5469 - val_loss: 0.2479 - val_accuracy: 0.5385\n","Epoch 215/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2514 - accuracy: 0.5156 - val_loss: 0.2478 - val_accuracy: 0.5385\n","Epoch 216/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2492 - accuracy: 0.5625 - val_loss: 0.2482 - val_accuracy: 0.5769\n","Epoch 217/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2553 - accuracy: 0.5000 - val_loss: 0.2486 - val_accuracy: 0.5769\n","Epoch 218/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2467 - accuracy: 0.5938 - val_loss: 0.2489 - val_accuracy: 0.5385\n","Epoch 219/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2544 - accuracy: 0.5625 - val_loss: 0.2488 - val_accuracy: 0.5769\n","Epoch 220/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2422 - accuracy: 0.5781 - val_loss: 0.2485 - val_accuracy: 0.6538\n","Epoch 221/245\n","2/2 [==============================] - 3s 2s/step - loss: 0.2532 - accuracy: 0.5469 - val_loss: 0.2482 - val_accuracy: 0.5385\n","Epoch 222/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2469 - accuracy: 0.5156 - val_loss: 0.2479 - val_accuracy: 0.5385\n","Epoch 223/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2427 - accuracy: 0.5312 - val_loss: 0.2476 - val_accuracy: 0.5385\n","Epoch 224/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2531 - accuracy: 0.5312 - val_loss: 0.2477 - val_accuracy: 0.5385\n","Epoch 225/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2559 - accuracy: 0.4844 - val_loss: 0.2481 - val_accuracy: 0.5385\n","Epoch 226/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2507 - accuracy: 0.5781 - val_loss: 0.2485 - val_accuracy: 0.6538\n","Epoch 227/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2473 - accuracy: 0.5469 - val_loss: 0.2484 - val_accuracy: 0.6154\n","Epoch 228/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2486 - accuracy: 0.5000 - val_loss: 0.2480 - val_accuracy: 0.5385\n","Epoch 229/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2458 - accuracy: 0.5469 - val_loss: 0.2478 - val_accuracy: 0.5385\n","Epoch 230/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2495 - accuracy: 0.5469 - val_loss: 0.2477 - val_accuracy: 0.5385\n","Epoch 231/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2575 - accuracy: 0.5312 - val_loss: 0.2477 - val_accuracy: 0.5385\n","Epoch 232/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2513 - accuracy: 0.5156 - val_loss: 0.2479 - val_accuracy: 0.5385\n","Epoch 233/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2483 - accuracy: 0.5469 - val_loss: 0.2479 - val_accuracy: 0.5385\n","Epoch 234/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2506 - accuracy: 0.5312 - val_loss: 0.2478 - val_accuracy: 0.5385\n","Epoch 235/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2485 - accuracy: 0.5469 - val_loss: 0.2477 - val_accuracy: 0.5385\n","Epoch 236/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2504 - accuracy: 0.5469 - val_loss: 0.2474 - val_accuracy: 0.5385\n","Epoch 237/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2490 - accuracy: 0.5156 - val_loss: 0.2472 - val_accuracy: 0.5385\n","Epoch 238/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2484 - accuracy: 0.5625 - val_loss: 0.2470 - val_accuracy: 0.5385\n","Epoch 239/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2513 - accuracy: 0.5000 - val_loss: 0.2471 - val_accuracy: 0.5385\n","Epoch 240/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2478 - accuracy: 0.5156 - val_loss: 0.2472 - val_accuracy: 0.5385\n","Epoch 241/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2474 - accuracy: 0.5469 - val_loss: 0.2475 - val_accuracy: 0.5385\n","Epoch 242/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2544 - accuracy: 0.5312 - val_loss: 0.2478 - val_accuracy: 0.5769\n","Epoch 243/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2515 - accuracy: 0.5781 - val_loss: 0.2480 - val_accuracy: 0.6154\n","Epoch 244/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2445 - accuracy: 0.5781 - val_loss: 0.2478 - val_accuracy: 0.5769\n","Epoch 245/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2479 - accuracy: 0.5312 - val_loss: 0.2474 - val_accuracy: 0.5385\n","1/1 [==============================] - 0s 109ms/step - loss: 0.2474 - accuracy: 0.5385\n","loss :  0.5384615659713745\n","total_loss :  3.1153846979141235\n","num :  6\n","WARNING:tensorflow:Layer gru_30 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","WARNING:tensorflow:Layer gru_31 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","WARNING:tensorflow:Layer gru_32 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","WARNING:tensorflow:Layer gru_33 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","WARNING:tensorflow:Layer gru_34 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","Epoch 1/245\n","2/2 [==============================] - 13s 3s/step - loss: 0.4926 - accuracy: 0.4844 - val_loss: 0.5177 - val_accuracy: 0.4231\n","Epoch 2/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.3770 - accuracy: 0.4844 - val_loss: 0.4435 - val_accuracy: 0.4231\n","Epoch 3/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2754 - accuracy: 0.4844 - val_loss: 0.3423 - val_accuracy: 0.4231\n","Epoch 4/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2976 - accuracy: 0.5156 - val_loss: 0.3329 - val_accuracy: 0.4231\n","Epoch 5/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2773 - accuracy: 0.5469 - val_loss: 0.3696 - val_accuracy: 0.4231\n","Epoch 6/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2398 - accuracy: 0.6094 - val_loss: 0.3992 - val_accuracy: 0.4231\n","Epoch 7/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2569 - accuracy: 0.5312 - val_loss: 0.4133 - val_accuracy: 0.4231\n","Epoch 8/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2745 - accuracy: 0.4844 - val_loss: 0.4126 - val_accuracy: 0.4231\n","Epoch 9/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2685 - accuracy: 0.5156 - val_loss: 0.4014 - val_accuracy: 0.4231\n","Epoch 10/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2581 - accuracy: 0.5625 - val_loss: 0.3834 - val_accuracy: 0.4231\n","Epoch 11/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2428 - accuracy: 0.5000 - val_loss: 0.3637 - val_accuracy: 0.4231\n","Epoch 12/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2707 - accuracy: 0.5000 - val_loss: 0.3525 - val_accuracy: 0.4231\n","Epoch 13/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2672 - accuracy: 0.5625 - val_loss: 0.3546 - val_accuracy: 0.4231\n","Epoch 14/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2575 - accuracy: 0.5312 - val_loss: 0.3640 - val_accuracy: 0.4231\n","Epoch 15/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2375 - accuracy: 0.6094 - val_loss: 0.3731 - val_accuracy: 0.4231\n","Epoch 16/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2556 - accuracy: 0.5156 - val_loss: 0.3791 - val_accuracy: 0.4231\n","Epoch 17/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2443 - accuracy: 0.6094 - val_loss: 0.3787 - val_accuracy: 0.4231\n","Epoch 18/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2547 - accuracy: 0.5312 - val_loss: 0.3735 - val_accuracy: 0.4231\n","Epoch 19/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2656 - accuracy: 0.4688 - val_loss: 0.3681 - val_accuracy: 0.4231\n","Epoch 20/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2417 - accuracy: 0.5469 - val_loss: 0.3633 - val_accuracy: 0.4231\n","Epoch 21/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2523 - accuracy: 0.5781 - val_loss: 0.3609 - val_accuracy: 0.4231\n","Epoch 22/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2485 - accuracy: 0.4531 - val_loss: 0.3607 - val_accuracy: 0.4231\n","Epoch 23/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2539 - accuracy: 0.6094 - val_loss: 0.3621 - val_accuracy: 0.4231\n","Epoch 24/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2606 - accuracy: 0.5469 - val_loss: 0.3628 - val_accuracy: 0.4231\n","Epoch 25/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2567 - accuracy: 0.5469 - val_loss: 0.3639 - val_accuracy: 0.4231\n","Epoch 26/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2436 - accuracy: 0.5469 - val_loss: 0.3628 - val_accuracy: 0.4231\n","Epoch 27/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2499 - accuracy: 0.5312 - val_loss: 0.3588 - val_accuracy: 0.4231\n","Epoch 28/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2551 - accuracy: 0.5312 - val_loss: 0.3544 - val_accuracy: 0.4231\n","Epoch 29/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2395 - accuracy: 0.5625 - val_loss: 0.3490 - val_accuracy: 0.4231\n","Epoch 30/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2584 - accuracy: 0.3750 - val_loss: 0.3491 - val_accuracy: 0.4231\n","Epoch 31/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2572 - accuracy: 0.5156 - val_loss: 0.3541 - val_accuracy: 0.4231\n","Epoch 32/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2511 - accuracy: 0.5781 - val_loss: 0.3577 - val_accuracy: 0.4231\n","Epoch 33/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2430 - accuracy: 0.5625 - val_loss: 0.3601 - val_accuracy: 0.4231\n","Epoch 34/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2543 - accuracy: 0.4844 - val_loss: 0.3583 - val_accuracy: 0.4231\n","Epoch 35/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2507 - accuracy: 0.5000 - val_loss: 0.3519 - val_accuracy: 0.4231\n","Epoch 36/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2511 - accuracy: 0.5469 - val_loss: 0.3478 - val_accuracy: 0.4231\n","Epoch 37/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2429 - accuracy: 0.5938 - val_loss: 0.3468 - val_accuracy: 0.4231\n","Epoch 38/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2528 - accuracy: 0.5469 - val_loss: 0.3488 - val_accuracy: 0.4231\n","Epoch 39/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2455 - accuracy: 0.6406 - val_loss: 0.3481 - val_accuracy: 0.4231\n","Epoch 40/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2427 - accuracy: 0.5781 - val_loss: 0.3470 - val_accuracy: 0.4231\n","Epoch 41/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2532 - accuracy: 0.5000 - val_loss: 0.3454 - val_accuracy: 0.4231\n","Epoch 42/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2535 - accuracy: 0.5000 - val_loss: 0.3446 - val_accuracy: 0.4231\n","Epoch 43/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2372 - accuracy: 0.6562 - val_loss: 0.3458 - val_accuracy: 0.4231\n","Epoch 44/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2560 - accuracy: 0.4531 - val_loss: 0.3435 - val_accuracy: 0.4231\n","Epoch 45/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2418 - accuracy: 0.5312 - val_loss: 0.3415 - val_accuracy: 0.4231\n","Epoch 46/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2426 - accuracy: 0.5000 - val_loss: 0.3399 - val_accuracy: 0.4231\n","Epoch 47/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2437 - accuracy: 0.6094 - val_loss: 0.3370 - val_accuracy: 0.4231\n","Epoch 48/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2332 - accuracy: 0.5312 - val_loss: 0.3392 - val_accuracy: 0.4231\n","Epoch 49/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2488 - accuracy: 0.5000 - val_loss: 0.3488 - val_accuracy: 0.4231\n","Epoch 50/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2425 - accuracy: 0.5625 - val_loss: 0.3527 - val_accuracy: 0.4231\n","Epoch 51/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2419 - accuracy: 0.6094 - val_loss: 0.3483 - val_accuracy: 0.4231\n","Epoch 52/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2474 - accuracy: 0.5469 - val_loss: 0.3432 - val_accuracy: 0.4231\n","Epoch 53/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2425 - accuracy: 0.5938 - val_loss: 0.3445 - val_accuracy: 0.4231\n","Epoch 54/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2549 - accuracy: 0.5156 - val_loss: 0.3494 - val_accuracy: 0.4231\n","Epoch 55/245\n","2/2 [==============================] - 3s 2s/step - loss: 0.2555 - accuracy: 0.4844 - val_loss: 0.3545 - val_accuracy: 0.4231\n","Epoch 56/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2418 - accuracy: 0.5781 - val_loss: 0.3576 - val_accuracy: 0.4231\n","Epoch 57/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2586 - accuracy: 0.5000 - val_loss: 0.3528 - val_accuracy: 0.4231\n","Epoch 58/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2536 - accuracy: 0.5156 - val_loss: 0.3451 - val_accuracy: 0.4231\n","Epoch 59/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2412 - accuracy: 0.5938 - val_loss: 0.3383 - val_accuracy: 0.4231\n","Epoch 60/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2397 - accuracy: 0.6094 - val_loss: 0.3320 - val_accuracy: 0.4231\n","Epoch 61/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2511 - accuracy: 0.5000 - val_loss: 0.3280 - val_accuracy: 0.4231\n","Epoch 62/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2657 - accuracy: 0.4531 - val_loss: 0.3339 - val_accuracy: 0.4231\n","Epoch 63/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2571 - accuracy: 0.5625 - val_loss: 0.3404 - val_accuracy: 0.4231\n","Epoch 64/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2469 - accuracy: 0.6094 - val_loss: 0.3400 - val_accuracy: 0.4231\n","Epoch 65/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2429 - accuracy: 0.5938 - val_loss: 0.3321 - val_accuracy: 0.4231\n","Epoch 66/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2473 - accuracy: 0.5625 - val_loss: 0.3207 - val_accuracy: 0.4231\n","Epoch 67/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2479 - accuracy: 0.4531 - val_loss: 0.3157 - val_accuracy: 0.4231\n","Epoch 68/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2390 - accuracy: 0.5625 - val_loss: 0.3170 - val_accuracy: 0.4231\n","Epoch 69/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2357 - accuracy: 0.6719 - val_loss: 0.3224 - val_accuracy: 0.4231\n","Epoch 70/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2427 - accuracy: 0.5156 - val_loss: 0.3294 - val_accuracy: 0.4231\n","Epoch 71/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2358 - accuracy: 0.6094 - val_loss: 0.3343 - val_accuracy: 0.4231\n","Epoch 72/245\n","2/2 [==============================] - 3s 2s/step - loss: 0.2590 - accuracy: 0.5625 - val_loss: 0.3386 - val_accuracy: 0.4231\n","Epoch 73/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2381 - accuracy: 0.5938 - val_loss: 0.3385 - val_accuracy: 0.4231\n","Epoch 74/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2437 - accuracy: 0.6094 - val_loss: 0.3333 - val_accuracy: 0.4231\n","Epoch 75/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2435 - accuracy: 0.5312 - val_loss: 0.3298 - val_accuracy: 0.4231\n","Epoch 76/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2455 - accuracy: 0.5781 - val_loss: 0.3291 - val_accuracy: 0.4231\n","Epoch 77/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2450 - accuracy: 0.5938 - val_loss: 0.3313 - val_accuracy: 0.4231\n","Epoch 78/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2507 - accuracy: 0.5625 - val_loss: 0.3398 - val_accuracy: 0.4231\n","Epoch 79/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2443 - accuracy: 0.5781 - val_loss: 0.3467 - val_accuracy: 0.4231\n","Epoch 80/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2448 - accuracy: 0.5469 - val_loss: 0.3454 - val_accuracy: 0.4231\n","Epoch 81/245\n","2/2 [==============================] - 3s 2s/step - loss: 0.2443 - accuracy: 0.5625 - val_loss: 0.3343 - val_accuracy: 0.4231\n","Epoch 82/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2561 - accuracy: 0.5312 - val_loss: 0.3239 - val_accuracy: 0.4231\n","Epoch 83/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2572 - accuracy: 0.5000 - val_loss: 0.3296 - val_accuracy: 0.4231\n","Epoch 84/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2522 - accuracy: 0.5312 - val_loss: 0.3417 - val_accuracy: 0.4231\n","Epoch 85/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2493 - accuracy: 0.5625 - val_loss: 0.3481 - val_accuracy: 0.4231\n","Epoch 86/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2520 - accuracy: 0.5156 - val_loss: 0.3422 - val_accuracy: 0.4231\n","Epoch 87/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2480 - accuracy: 0.5156 - val_loss: 0.3314 - val_accuracy: 0.4231\n","Epoch 88/245\n","2/2 [==============================] - 3s 2s/step - loss: 0.2466 - accuracy: 0.5625 - val_loss: 0.3237 - val_accuracy: 0.4231\n","Epoch 89/245\n","2/2 [==============================] - 3s 2s/step - loss: 0.2508 - accuracy: 0.5000 - val_loss: 0.3235 - val_accuracy: 0.4231\n","Epoch 90/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2570 - accuracy: 0.5469 - val_loss: 0.3296 - val_accuracy: 0.4231\n","Epoch 91/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2435 - accuracy: 0.5938 - val_loss: 0.3333 - val_accuracy: 0.4231\n","Epoch 92/245\n","2/2 [==============================] - 3s 2s/step - loss: 0.2413 - accuracy: 0.5312 - val_loss: 0.3320 - val_accuracy: 0.4231\n","Epoch 93/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2374 - accuracy: 0.5938 - val_loss: 0.3271 - val_accuracy: 0.4231\n","Epoch 94/245\n","2/2 [==============================] - 3s 2s/step - loss: 0.2392 - accuracy: 0.5625 - val_loss: 0.3225 - val_accuracy: 0.4231\n","Epoch 95/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2336 - accuracy: 0.5781 - val_loss: 0.3208 - val_accuracy: 0.4231\n","Epoch 96/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2451 - accuracy: 0.5781 - val_loss: 0.3221 - val_accuracy: 0.4231\n","Epoch 97/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2424 - accuracy: 0.5312 - val_loss: 0.3254 - val_accuracy: 0.4231\n","Epoch 98/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2440 - accuracy: 0.5938 - val_loss: 0.3297 - val_accuracy: 0.4231\n","Epoch 99/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2328 - accuracy: 0.7188 - val_loss: 0.3321 - val_accuracy: 0.4231\n","Epoch 100/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2453 - accuracy: 0.5938 - val_loss: 0.3352 - val_accuracy: 0.4231\n","Epoch 101/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2503 - accuracy: 0.5312 - val_loss: 0.3381 - val_accuracy: 0.4231\n","Epoch 102/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2403 - accuracy: 0.5625 - val_loss: 0.3386 - val_accuracy: 0.4231\n","Epoch 103/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2479 - accuracy: 0.5312 - val_loss: 0.3378 - val_accuracy: 0.4231\n","Epoch 104/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2615 - accuracy: 0.5469 - val_loss: 0.3389 - val_accuracy: 0.4231\n","Epoch 105/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2292 - accuracy: 0.6250 - val_loss: 0.3411 - val_accuracy: 0.4231\n","Epoch 106/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2462 - accuracy: 0.5781 - val_loss: 0.3422 - val_accuracy: 0.4231\n","Epoch 107/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2332 - accuracy: 0.6250 - val_loss: 0.3379 - val_accuracy: 0.4231\n","Epoch 108/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2410 - accuracy: 0.5938 - val_loss: 0.3366 - val_accuracy: 0.4231\n","Epoch 109/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2486 - accuracy: 0.5312 - val_loss: 0.3412 - val_accuracy: 0.4231\n","Epoch 110/245\n","2/2 [==============================] - 3s 2s/step - loss: 0.2409 - accuracy: 0.5469 - val_loss: 0.3449 - val_accuracy: 0.4231\n","Epoch 111/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2420 - accuracy: 0.6250 - val_loss: 0.3468 - val_accuracy: 0.4231\n","Epoch 112/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2377 - accuracy: 0.6562 - val_loss: 0.3449 - val_accuracy: 0.4231\n","Epoch 113/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2384 - accuracy: 0.6094 - val_loss: 0.3386 - val_accuracy: 0.4231\n","Epoch 114/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2359 - accuracy: 0.6094 - val_loss: 0.3308 - val_accuracy: 0.4231\n","Epoch 115/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2482 - accuracy: 0.5938 - val_loss: 0.3315 - val_accuracy: 0.4231\n","Epoch 116/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2388 - accuracy: 0.5781 - val_loss: 0.3361 - val_accuracy: 0.4231\n","Epoch 117/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2427 - accuracy: 0.5469 - val_loss: 0.3330 - val_accuracy: 0.4231\n","Epoch 118/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2409 - accuracy: 0.6562 - val_loss: 0.3243 - val_accuracy: 0.4231\n","Epoch 119/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2299 - accuracy: 0.7031 - val_loss: 0.3209 - val_accuracy: 0.4231\n","Epoch 120/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2428 - accuracy: 0.5625 - val_loss: 0.3259 - val_accuracy: 0.4231\n","Epoch 121/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2350 - accuracy: 0.6562 - val_loss: 0.3292 - val_accuracy: 0.4231\n","Epoch 122/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2444 - accuracy: 0.5312 - val_loss: 0.3343 - val_accuracy: 0.4231\n","Epoch 123/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2242 - accuracy: 0.6094 - val_loss: 0.3369 - val_accuracy: 0.4231\n","Epoch 124/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2506 - accuracy: 0.6094 - val_loss: 0.3410 - val_accuracy: 0.4231\n","Epoch 125/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2467 - accuracy: 0.5938 - val_loss: 0.3468 - val_accuracy: 0.4231\n","Epoch 126/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2349 - accuracy: 0.6562 - val_loss: 0.3511 - val_accuracy: 0.4231\n","Epoch 127/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2403 - accuracy: 0.5312 - val_loss: 0.3524 - val_accuracy: 0.4231\n","Epoch 128/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2416 - accuracy: 0.5469 - val_loss: 0.3482 - val_accuracy: 0.4231\n","Epoch 129/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2590 - accuracy: 0.5312 - val_loss: 0.3422 - val_accuracy: 0.4231\n","Epoch 130/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2445 - accuracy: 0.5781 - val_loss: 0.3414 - val_accuracy: 0.4231\n","Epoch 131/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2449 - accuracy: 0.6250 - val_loss: 0.3464 - val_accuracy: 0.4231\n","Epoch 132/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2334 - accuracy: 0.6250 - val_loss: 0.3445 - val_accuracy: 0.4231\n","Epoch 133/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2342 - accuracy: 0.7031 - val_loss: 0.3368 - val_accuracy: 0.4231\n","Epoch 134/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2371 - accuracy: 0.5781 - val_loss: 0.3300 - val_accuracy: 0.4231\n","Epoch 135/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2424 - accuracy: 0.5938 - val_loss: 0.3331 - val_accuracy: 0.4231\n","Epoch 136/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2296 - accuracy: 0.5469 - val_loss: 0.3403 - val_accuracy: 0.4231\n","Epoch 137/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2306 - accuracy: 0.6562 - val_loss: 0.3433 - val_accuracy: 0.4231\n","Epoch 138/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2272 - accuracy: 0.5781 - val_loss: 0.3421 - val_accuracy: 0.4231\n","Epoch 139/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2322 - accuracy: 0.6250 - val_loss: 0.3382 - val_accuracy: 0.4231\n","Epoch 140/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2323 - accuracy: 0.6250 - val_loss: 0.3448 - val_accuracy: 0.4231\n","Epoch 141/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2282 - accuracy: 0.6406 - val_loss: 0.3544 - val_accuracy: 0.4231\n","Epoch 142/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2321 - accuracy: 0.5938 - val_loss: 0.3647 - val_accuracy: 0.4231\n","Epoch 143/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2315 - accuracy: 0.6250 - val_loss: 0.3737 - val_accuracy: 0.4231\n","Epoch 144/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2499 - accuracy: 0.5938 - val_loss: 0.3809 - val_accuracy: 0.4231\n","Epoch 145/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2479 - accuracy: 0.5781 - val_loss: 0.3816 - val_accuracy: 0.4231\n","Epoch 146/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2426 - accuracy: 0.6094 - val_loss: 0.3809 - val_accuracy: 0.4231\n","Epoch 147/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2325 - accuracy: 0.6406 - val_loss: 0.3769 - val_accuracy: 0.4231\n","Epoch 148/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2456 - accuracy: 0.5781 - val_loss: 0.3763 - val_accuracy: 0.4231\n","Epoch 149/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2367 - accuracy: 0.5469 - val_loss: 0.3785 - val_accuracy: 0.4231\n","Epoch 150/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2369 - accuracy: 0.6250 - val_loss: 0.3758 - val_accuracy: 0.4231\n","Epoch 151/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2257 - accuracy: 0.6406 - val_loss: 0.3703 - val_accuracy: 0.4231\n","Epoch 152/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2485 - accuracy: 0.5312 - val_loss: 0.3691 - val_accuracy: 0.4231\n","Epoch 153/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2356 - accuracy: 0.5781 - val_loss: 0.3705 - val_accuracy: 0.4231\n","Epoch 154/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2351 - accuracy: 0.6250 - val_loss: 0.3710 - val_accuracy: 0.4231\n","Epoch 155/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2509 - accuracy: 0.6250 - val_loss: 0.3732 - val_accuracy: 0.4231\n","Epoch 156/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2438 - accuracy: 0.5312 - val_loss: 0.3675 - val_accuracy: 0.4231\n","Epoch 157/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2178 - accuracy: 0.6250 - val_loss: 0.3614 - val_accuracy: 0.4231\n","Epoch 158/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2352 - accuracy: 0.6094 - val_loss: 0.3615 - val_accuracy: 0.4231\n","Epoch 159/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2311 - accuracy: 0.6406 - val_loss: 0.3667 - val_accuracy: 0.4231\n","Epoch 160/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2424 - accuracy: 0.5781 - val_loss: 0.3724 - val_accuracy: 0.4231\n","Epoch 161/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2280 - accuracy: 0.6562 - val_loss: 0.3713 - val_accuracy: 0.4231\n","Epoch 162/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2118 - accuracy: 0.7031 - val_loss: 0.3612 - val_accuracy: 0.4231\n","Epoch 163/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2374 - accuracy: 0.5625 - val_loss: 0.3623 - val_accuracy: 0.4231\n","Epoch 164/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2411 - accuracy: 0.6406 - val_loss: 0.3736 - val_accuracy: 0.4231\n","Epoch 165/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2407 - accuracy: 0.5625 - val_loss: 0.3767 - val_accuracy: 0.4231\n","Epoch 166/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2285 - accuracy: 0.6562 - val_loss: 0.3720 - val_accuracy: 0.4231\n","Epoch 167/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2297 - accuracy: 0.6250 - val_loss: 0.3633 - val_accuracy: 0.4231\n","Epoch 168/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2410 - accuracy: 0.6406 - val_loss: 0.3637 - val_accuracy: 0.4231\n","Epoch 169/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2431 - accuracy: 0.6094 - val_loss: 0.3691 - val_accuracy: 0.4231\n","Epoch 170/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2374 - accuracy: 0.5938 - val_loss: 0.3795 - val_accuracy: 0.4231\n","Epoch 171/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2244 - accuracy: 0.6562 - val_loss: 0.3826 - val_accuracy: 0.4231\n","Epoch 172/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2430 - accuracy: 0.5938 - val_loss: 0.3766 - val_accuracy: 0.4231\n","Epoch 173/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2336 - accuracy: 0.6875 - val_loss: 0.3693 - val_accuracy: 0.4231\n","Epoch 174/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2522 - accuracy: 0.6250 - val_loss: 0.3768 - val_accuracy: 0.4231\n","Epoch 175/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2183 - accuracy: 0.6562 - val_loss: 0.3825 - val_accuracy: 0.4231\n","Epoch 176/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2341 - accuracy: 0.5938 - val_loss: 0.3861 - val_accuracy: 0.4231\n","Epoch 177/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2375 - accuracy: 0.6250 - val_loss: 0.3845 - val_accuracy: 0.4231\n","Epoch 178/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2370 - accuracy: 0.6094 - val_loss: 0.3801 - val_accuracy: 0.4231\n","Epoch 179/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2361 - accuracy: 0.6250 - val_loss: 0.3749 - val_accuracy: 0.4231\n","Epoch 180/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2414 - accuracy: 0.5625 - val_loss: 0.3796 - val_accuracy: 0.4231\n","Epoch 181/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2373 - accuracy: 0.5625 - val_loss: 0.3804 - val_accuracy: 0.4231\n","Epoch 182/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2297 - accuracy: 0.5938 - val_loss: 0.3818 - val_accuracy: 0.4231\n","Epoch 183/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2298 - accuracy: 0.5938 - val_loss: 0.3774 - val_accuracy: 0.4231\n","Epoch 184/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2335 - accuracy: 0.6250 - val_loss: 0.3716 - val_accuracy: 0.4231\n","Epoch 185/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2330 - accuracy: 0.6406 - val_loss: 0.3717 - val_accuracy: 0.4231\n","Epoch 186/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2304 - accuracy: 0.6562 - val_loss: 0.3851 - val_accuracy: 0.4231\n","Epoch 187/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2243 - accuracy: 0.6250 - val_loss: 0.3977 - val_accuracy: 0.4231\n","Epoch 188/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2365 - accuracy: 0.6562 - val_loss: 0.3992 - val_accuracy: 0.4231\n","Epoch 189/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2429 - accuracy: 0.6250 - val_loss: 0.3912 - val_accuracy: 0.4231\n","Epoch 190/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2532 - accuracy: 0.5312 - val_loss: 0.3888 - val_accuracy: 0.4231\n","Epoch 191/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2315 - accuracy: 0.6719 - val_loss: 0.3979 - val_accuracy: 0.4231\n","Epoch 192/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2335 - accuracy: 0.6406 - val_loss: 0.3970 - val_accuracy: 0.4231\n","Epoch 193/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2439 - accuracy: 0.6094 - val_loss: 0.3869 - val_accuracy: 0.4231\n","Epoch 194/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2297 - accuracy: 0.5781 - val_loss: 0.3752 - val_accuracy: 0.4231\n","Epoch 195/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2343 - accuracy: 0.6875 - val_loss: 0.3650 - val_accuracy: 0.4231\n","Epoch 196/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2291 - accuracy: 0.6875 - val_loss: 0.3627 - val_accuracy: 0.4231\n","Epoch 197/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2178 - accuracy: 0.6250 - val_loss: 0.3793 - val_accuracy: 0.4231\n","Epoch 198/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2410 - accuracy: 0.5469 - val_loss: 0.3872 - val_accuracy: 0.4231\n","Epoch 199/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2289 - accuracy: 0.6875 - val_loss: 0.3847 - val_accuracy: 0.4231\n","Epoch 200/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2206 - accuracy: 0.6562 - val_loss: 0.3806 - val_accuracy: 0.4231\n","Epoch 201/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2330 - accuracy: 0.6094 - val_loss: 0.3863 - val_accuracy: 0.4231\n","Epoch 202/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2299 - accuracy: 0.6562 - val_loss: 0.4045 - val_accuracy: 0.4231\n","Epoch 203/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2411 - accuracy: 0.6094 - val_loss: 0.4137 - val_accuracy: 0.4231\n","Epoch 204/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2314 - accuracy: 0.6250 - val_loss: 0.4137 - val_accuracy: 0.4231\n","Epoch 205/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2258 - accuracy: 0.6094 - val_loss: 0.4013 - val_accuracy: 0.4231\n","Epoch 206/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2521 - accuracy: 0.6406 - val_loss: 0.3978 - val_accuracy: 0.4231\n","Epoch 207/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2378 - accuracy: 0.6250 - val_loss: 0.3970 - val_accuracy: 0.4231\n","Epoch 208/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2290 - accuracy: 0.6250 - val_loss: 0.3873 - val_accuracy: 0.4231\n","Epoch 209/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2134 - accuracy: 0.6250 - val_loss: 0.3846 - val_accuracy: 0.4231\n","Epoch 210/245\n","2/2 [==============================] - 3s 2s/step - loss: 0.2058 - accuracy: 0.6719 - val_loss: 0.3927 - val_accuracy: 0.4231\n","Epoch 211/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2266 - accuracy: 0.5938 - val_loss: 0.3908 - val_accuracy: 0.4231\n","Epoch 212/245\n","2/2 [==============================] - 3s 2s/step - loss: 0.2376 - accuracy: 0.6562 - val_loss: 0.3729 - val_accuracy: 0.4231\n","Epoch 213/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2298 - accuracy: 0.5938 - val_loss: 0.3591 - val_accuracy: 0.4231\n","Epoch 214/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2178 - accuracy: 0.6406 - val_loss: 0.3687 - val_accuracy: 0.4231\n","Epoch 215/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2439 - accuracy: 0.6094 - val_loss: 0.3854 - val_accuracy: 0.4231\n","Epoch 216/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2411 - accuracy: 0.6094 - val_loss: 0.3923 - val_accuracy: 0.4231\n","Epoch 217/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2171 - accuracy: 0.6875 - val_loss: 0.3820 - val_accuracy: 0.4231\n","Epoch 218/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2278 - accuracy: 0.6250 - val_loss: 0.3812 - val_accuracy: 0.4231\n","Epoch 219/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2451 - accuracy: 0.5781 - val_loss: 0.4088 - val_accuracy: 0.4231\n","Epoch 220/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2274 - accuracy: 0.5938 - val_loss: 0.4257 - val_accuracy: 0.4231\n","Epoch 221/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2656 - accuracy: 0.5000 - val_loss: 0.4155 - val_accuracy: 0.4231\n","Epoch 222/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2491 - accuracy: 0.5781 - val_loss: 0.3816 - val_accuracy: 0.4231\n","Epoch 223/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2374 - accuracy: 0.5781 - val_loss: 0.3542 - val_accuracy: 0.4231\n","Epoch 224/245\n","2/2 [==============================] - 3s 2s/step - loss: 0.2304 - accuracy: 0.6562 - val_loss: 0.3556 - val_accuracy: 0.4231\n","Epoch 225/245\n","2/2 [==============================] - 3s 2s/step - loss: 0.2246 - accuracy: 0.6406 - val_loss: 0.3741 - val_accuracy: 0.4231\n","Epoch 226/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2376 - accuracy: 0.5938 - val_loss: 0.3835 - val_accuracy: 0.4231\n","Epoch 227/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2305 - accuracy: 0.5938 - val_loss: 0.3673 - val_accuracy: 0.4231\n","Epoch 228/245\n","2/2 [==============================] - 3s 2s/step - loss: 0.2311 - accuracy: 0.6562 - val_loss: 0.3520 - val_accuracy: 0.4231\n","Epoch 229/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2160 - accuracy: 0.6719 - val_loss: 0.3563 - val_accuracy: 0.4231\n","Epoch 230/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2274 - accuracy: 0.6250 - val_loss: 0.3756 - val_accuracy: 0.4231\n","Epoch 231/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2173 - accuracy: 0.6406 - val_loss: 0.3794 - val_accuracy: 0.4231\n","Epoch 232/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2367 - accuracy: 0.6406 - val_loss: 0.3818 - val_accuracy: 0.4231\n","Epoch 233/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2384 - accuracy: 0.6250 - val_loss: 0.3826 - val_accuracy: 0.4231\n","Epoch 234/245\n","2/2 [==============================] - 3s 2s/step - loss: 0.2292 - accuracy: 0.6250 - val_loss: 0.3777 - val_accuracy: 0.4231\n","Epoch 235/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2442 - accuracy: 0.5781 - val_loss: 0.3734 - val_accuracy: 0.4231\n","Epoch 236/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2268 - accuracy: 0.6250 - val_loss: 0.3722 - val_accuracy: 0.4231\n","Epoch 237/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2257 - accuracy: 0.6562 - val_loss: 0.3708 - val_accuracy: 0.4231\n","Epoch 238/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2154 - accuracy: 0.7188 - val_loss: 0.3741 - val_accuracy: 0.4231\n","Epoch 239/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2274 - accuracy: 0.6562 - val_loss: 0.3780 - val_accuracy: 0.4231\n","Epoch 240/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2203 - accuracy: 0.6094 - val_loss: 0.3784 - val_accuracy: 0.4231\n","Epoch 241/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2348 - accuracy: 0.6250 - val_loss: 0.3684 - val_accuracy: 0.4231\n","Epoch 242/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2228 - accuracy: 0.6719 - val_loss: 0.3651 - val_accuracy: 0.4231\n","Epoch 243/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2399 - accuracy: 0.6406 - val_loss: 0.3728 - val_accuracy: 0.4231\n","Epoch 244/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2316 - accuracy: 0.6250 - val_loss: 0.3859 - val_accuracy: 0.4231\n","Epoch 245/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2401 - accuracy: 0.5938 - val_loss: 0.3906 - val_accuracy: 0.4231\n","1/1 [==============================] - 0s 104ms/step - loss: 0.3906 - accuracy: 0.4231\n","loss :  0.42307692766189575\n","total_loss :  3.5384616255760193\n","num :  7\n","WARNING:tensorflow:Layer gru_35 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","WARNING:tensorflow:Layer gru_36 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","WARNING:tensorflow:Layer gru_37 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","WARNING:tensorflow:Layer gru_38 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","WARNING:tensorflow:Layer gru_39 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","Epoch 1/245\n","2/2 [==============================] - 13s 2s/step - loss: 0.5053 - accuracy: 0.4375 - val_loss: 0.2900 - val_accuracy: 0.6538\n","Epoch 2/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.3228 - accuracy: 0.4531 - val_loss: 0.2351 - val_accuracy: 0.6538\n","Epoch 3/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2815 - accuracy: 0.5781 - val_loss: 0.2303 - val_accuracy: 0.6538\n","Epoch 4/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2757 - accuracy: 0.5625 - val_loss: 0.2451 - val_accuracy: 0.6538\n","Epoch 5/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2483 - accuracy: 0.5156 - val_loss: 0.2587 - val_accuracy: 0.6538\n","Epoch 6/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2653 - accuracy: 0.4688 - val_loss: 0.2627 - val_accuracy: 0.6538\n","Epoch 7/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2865 - accuracy: 0.4531 - val_loss: 0.2587 - val_accuracy: 0.6538\n","Epoch 8/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2636 - accuracy: 0.5000 - val_loss: 0.2501 - val_accuracy: 0.6538\n","Epoch 9/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2583 - accuracy: 0.5312 - val_loss: 0.2401 - val_accuracy: 0.6538\n","Epoch 10/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2498 - accuracy: 0.5000 - val_loss: 0.2343 - val_accuracy: 0.6538\n","Epoch 11/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2616 - accuracy: 0.5312 - val_loss: 0.2332 - val_accuracy: 0.6538\n","Epoch 12/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2456 - accuracy: 0.5781 - val_loss: 0.2358 - val_accuracy: 0.6538\n","Epoch 13/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2666 - accuracy: 0.5000 - val_loss: 0.2394 - val_accuracy: 0.6538\n","Epoch 14/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2599 - accuracy: 0.4375 - val_loss: 0.2428 - val_accuracy: 0.6538\n","Epoch 15/245\n","2/2 [==============================] - 3s 2s/step - loss: 0.2585 - accuracy: 0.5469 - val_loss: 0.2433 - val_accuracy: 0.6538\n","Epoch 16/245\n","2/2 [==============================] - 3s 2s/step - loss: 0.2484 - accuracy: 0.5312 - val_loss: 0.2406 - val_accuracy: 0.6538\n","Epoch 17/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2678 - accuracy: 0.4688 - val_loss: 0.2367 - val_accuracy: 0.6538\n","Epoch 18/245\n","2/2 [==============================] - 2s 1s/step - loss: 0.2253 - accuracy: 0.6406 - val_loss: 0.2331 - val_accuracy: 0.6538\n","Epoch 19/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2455 - accuracy: 0.5781 - val_loss: 0.2317 - val_accuracy: 0.6538\n","Epoch 20/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2320 - accuracy: 0.5938 - val_loss: 0.2329 - val_accuracy: 0.6538\n","Epoch 21/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2295 - accuracy: 0.7031 - val_loss: 0.2353 - val_accuracy: 0.6538\n","Epoch 22/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2494 - accuracy: 0.6250 - val_loss: 0.2378 - val_accuracy: 0.6538\n","Epoch 23/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2468 - accuracy: 0.5625 - val_loss: 0.2389 - val_accuracy: 0.6538\n","Epoch 24/245\n","2/2 [==============================] - 3s 2s/step - loss: 0.2666 - accuracy: 0.5625 - val_loss: 0.2386 - val_accuracy: 0.6538\n","Epoch 25/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2423 - accuracy: 0.5781 - val_loss: 0.2384 - val_accuracy: 0.6538\n","Epoch 26/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2241 - accuracy: 0.6719 - val_loss: 0.2373 - val_accuracy: 0.6538\n","Epoch 27/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2503 - accuracy: 0.5000 - val_loss: 0.2360 - val_accuracy: 0.6538\n","Epoch 28/245\n","2/2 [==============================] - 3s 2s/step - loss: 0.2674 - accuracy: 0.5312 - val_loss: 0.2363 - val_accuracy: 0.6538\n","Epoch 29/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2387 - accuracy: 0.5781 - val_loss: 0.2376 - val_accuracy: 0.6538\n","Epoch 30/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2552 - accuracy: 0.4844 - val_loss: 0.2387 - val_accuracy: 0.6538\n","Epoch 31/245\n","2/2 [==============================] - 3s 2s/step - loss: 0.2670 - accuracy: 0.3906 - val_loss: 0.2385 - val_accuracy: 0.6538\n","Epoch 32/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2495 - accuracy: 0.5469 - val_loss: 0.2377 - val_accuracy: 0.6538\n","Epoch 33/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2521 - accuracy: 0.5469 - val_loss: 0.2368 - val_accuracy: 0.6538\n","Epoch 34/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2449 - accuracy: 0.5781 - val_loss: 0.2355 - val_accuracy: 0.6538\n","Epoch 35/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2455 - accuracy: 0.4844 - val_loss: 0.2351 - val_accuracy: 0.6538\n","Epoch 36/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2563 - accuracy: 0.5156 - val_loss: 0.2362 - val_accuracy: 0.6538\n","Epoch 37/245\n","2/2 [==============================] - 3s 2s/step - loss: 0.2412 - accuracy: 0.5000 - val_loss: 0.2373 - val_accuracy: 0.6538\n","Epoch 38/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2489 - accuracy: 0.5000 - val_loss: 0.2376 - val_accuracy: 0.6538\n","Epoch 39/245\n","2/2 [==============================] - 3s 2s/step - loss: 0.2428 - accuracy: 0.5156 - val_loss: 0.2370 - val_accuracy: 0.6538\n","Epoch 40/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2364 - accuracy: 0.6406 - val_loss: 0.2361 - val_accuracy: 0.6538\n","Epoch 41/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2588 - accuracy: 0.5000 - val_loss: 0.2357 - val_accuracy: 0.6538\n","Epoch 42/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2622 - accuracy: 0.5781 - val_loss: 0.2371 - val_accuracy: 0.6538\n","Epoch 43/245\n","2/2 [==============================] - 3s 2s/step - loss: 0.2551 - accuracy: 0.4844 - val_loss: 0.2373 - val_accuracy: 0.6538\n","Epoch 44/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2602 - accuracy: 0.4844 - val_loss: 0.2366 - val_accuracy: 0.6538\n","Epoch 45/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2589 - accuracy: 0.4844 - val_loss: 0.2351 - val_accuracy: 0.6538\n","Epoch 46/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2440 - accuracy: 0.5781 - val_loss: 0.2338 - val_accuracy: 0.6538\n","Epoch 47/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2402 - accuracy: 0.5156 - val_loss: 0.2325 - val_accuracy: 0.6538\n","Epoch 48/245\n","2/2 [==============================] - 3s 2s/step - loss: 0.2446 - accuracy: 0.5781 - val_loss: 0.2319 - val_accuracy: 0.6538\n","Epoch 49/245\n","2/2 [==============================] - 3s 2s/step - loss: 0.2483 - accuracy: 0.5625 - val_loss: 0.2319 - val_accuracy: 0.6538\n","Epoch 50/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2415 - accuracy: 0.5156 - val_loss: 0.2318 - val_accuracy: 0.6538\n","Epoch 51/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2454 - accuracy: 0.5625 - val_loss: 0.2319 - val_accuracy: 0.6538\n","Epoch 52/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2460 - accuracy: 0.5156 - val_loss: 0.2323 - val_accuracy: 0.6538\n","Epoch 53/245\n","2/2 [==============================] - 3s 2s/step - loss: 0.2521 - accuracy: 0.5469 - val_loss: 0.2323 - val_accuracy: 0.6538\n","Epoch 54/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2519 - accuracy: 0.5625 - val_loss: 0.2318 - val_accuracy: 0.6538\n","Epoch 55/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2582 - accuracy: 0.4375 - val_loss: 0.2315 - val_accuracy: 0.6538\n","Epoch 56/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2365 - accuracy: 0.5469 - val_loss: 0.2311 - val_accuracy: 0.6538\n","Epoch 57/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2402 - accuracy: 0.5938 - val_loss: 0.2303 - val_accuracy: 0.6538\n","Epoch 58/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2442 - accuracy: 0.5312 - val_loss: 0.2297 - val_accuracy: 0.6538\n","Epoch 59/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2523 - accuracy: 0.5625 - val_loss: 0.2299 - val_accuracy: 0.6538\n","Epoch 60/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2440 - accuracy: 0.5625 - val_loss: 0.2307 - val_accuracy: 0.6538\n","Epoch 61/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2352 - accuracy: 0.6250 - val_loss: 0.2315 - val_accuracy: 0.6538\n","Epoch 62/245\n","2/2 [==============================] - 3s 2s/step - loss: 0.2510 - accuracy: 0.5000 - val_loss: 0.2320 - val_accuracy: 0.6538\n","Epoch 63/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2437 - accuracy: 0.6406 - val_loss: 0.2316 - val_accuracy: 0.6538\n","Epoch 64/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2530 - accuracy: 0.4844 - val_loss: 0.2309 - val_accuracy: 0.6538\n","Epoch 65/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2445 - accuracy: 0.5469 - val_loss: 0.2303 - val_accuracy: 0.6538\n","Epoch 66/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2331 - accuracy: 0.5781 - val_loss: 0.2297 - val_accuracy: 0.6538\n","Epoch 67/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2361 - accuracy: 0.6250 - val_loss: 0.2297 - val_accuracy: 0.6538\n","Epoch 68/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2405 - accuracy: 0.5312 - val_loss: 0.2299 - val_accuracy: 0.6538\n","Epoch 69/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2522 - accuracy: 0.5938 - val_loss: 0.2303 - val_accuracy: 0.6538\n","Epoch 70/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2394 - accuracy: 0.5469 - val_loss: 0.2304 - val_accuracy: 0.6538\n","Epoch 71/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2401 - accuracy: 0.5312 - val_loss: 0.2304 - val_accuracy: 0.6538\n","Epoch 72/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2357 - accuracy: 0.6094 - val_loss: 0.2299 - val_accuracy: 0.6538\n","Epoch 73/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2499 - accuracy: 0.6250 - val_loss: 0.2300 - val_accuracy: 0.6538\n","Epoch 74/245\n","2/2 [==============================] - 3s 2s/step - loss: 0.2637 - accuracy: 0.5469 - val_loss: 0.2310 - val_accuracy: 0.6538\n","Epoch 75/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2487 - accuracy: 0.5625 - val_loss: 0.2314 - val_accuracy: 0.6538\n","Epoch 76/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2461 - accuracy: 0.5312 - val_loss: 0.2310 - val_accuracy: 0.6538\n","Epoch 77/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2485 - accuracy: 0.6094 - val_loss: 0.2300 - val_accuracy: 0.6538\n","Epoch 78/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2533 - accuracy: 0.4844 - val_loss: 0.2293 - val_accuracy: 0.6538\n","Epoch 79/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2459 - accuracy: 0.5312 - val_loss: 0.2291 - val_accuracy: 0.6538\n","Epoch 80/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2536 - accuracy: 0.5469 - val_loss: 0.2292 - val_accuracy: 0.6538\n","Epoch 81/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2423 - accuracy: 0.4844 - val_loss: 0.2294 - val_accuracy: 0.6538\n","Epoch 82/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2528 - accuracy: 0.5156 - val_loss: 0.2293 - val_accuracy: 0.6538\n","Epoch 83/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2454 - accuracy: 0.6406 - val_loss: 0.2289 - val_accuracy: 0.6538\n","Epoch 84/245\n","2/2 [==============================] - 3s 2s/step - loss: 0.2402 - accuracy: 0.5938 - val_loss: 0.2289 - val_accuracy: 0.6538\n","Epoch 85/245\n","2/2 [==============================] - 3s 2s/step - loss: 0.2443 - accuracy: 0.6094 - val_loss: 0.2289 - val_accuracy: 0.6538\n","Epoch 86/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2423 - accuracy: 0.5625 - val_loss: 0.2288 - val_accuracy: 0.6538\n","Epoch 87/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2424 - accuracy: 0.5000 - val_loss: 0.2288 - val_accuracy: 0.6538\n","Epoch 88/245\n","2/2 [==============================] - 3s 2s/step - loss: 0.2534 - accuracy: 0.5469 - val_loss: 0.2287 - val_accuracy: 0.6538\n","Epoch 89/245\n","2/2 [==============================] - 3s 2s/step - loss: 0.2584 - accuracy: 0.5000 - val_loss: 0.2286 - val_accuracy: 0.6538\n","Epoch 90/245\n","2/2 [==============================] - 3s 2s/step - loss: 0.2414 - accuracy: 0.6094 - val_loss: 0.2286 - val_accuracy: 0.6538\n","Epoch 91/245\n","2/2 [==============================] - 3s 2s/step - loss: 0.2318 - accuracy: 0.5938 - val_loss: 0.2288 - val_accuracy: 0.6538\n","Epoch 92/245\n","2/2 [==============================] - 3s 2s/step - loss: 0.2448 - accuracy: 0.6094 - val_loss: 0.2291 - val_accuracy: 0.6538\n","Epoch 93/245\n","2/2 [==============================] - 3s 2s/step - loss: 0.2415 - accuracy: 0.5312 - val_loss: 0.2292 - val_accuracy: 0.6538\n","Epoch 94/245\n","2/2 [==============================] - 3s 2s/step - loss: 0.2381 - accuracy: 0.5625 - val_loss: 0.2290 - val_accuracy: 0.6538\n","Epoch 95/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2443 - accuracy: 0.5469 - val_loss: 0.2290 - val_accuracy: 0.6538\n","Epoch 96/245\n","2/2 [==============================] - 3s 2s/step - loss: 0.2476 - accuracy: 0.5469 - val_loss: 0.2292 - val_accuracy: 0.6538\n","Epoch 97/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2487 - accuracy: 0.5625 - val_loss: 0.2292 - val_accuracy: 0.6538\n","Epoch 98/245\n","2/2 [==============================] - 3s 2s/step - loss: 0.2470 - accuracy: 0.6406 - val_loss: 0.2291 - val_accuracy: 0.6538\n","Epoch 99/245\n","2/2 [==============================] - 3s 1s/step - loss: 0.2559 - accuracy: 0.5156 - val_loss: 0.2290 - val_accuracy: 0.6538\n","Epoch 100/245\n","2/2 [==============================] - 3s 2s/step - loss: 0.2481 - accuracy: 0.5625 - val_loss: 0.2289 - val_accuracy: 0.6538\n","Epoch 101/245\n","2/2 [==============================] - ETA: 0s - loss: 0.2389 - accuracy: 0.5625"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"m3AO5wo3p4yy","executionInfo":{"status":"ok","timestamp":1630760996108,"user_tz":-540,"elapsed":9782,"user":{"displayName":"고기맛고구마","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj-JBJH0nKac_tUeR-K9pB3y_KCNQkUdNxaqUui=s64","userId":"16568438449136061581"}},"outputId":"022e4f4e-e49d-4a48-b0ba-ddd9cc71c307"},"source":["!pip install wandb"],"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting wandb\n","  Downloading wandb-0.12.1-py2.py3-none-any.whl (1.7 MB)\n","\u001b[K     |████████████████████████████████| 1.7 MB 5.4 MB/s \n","\u001b[?25hCollecting GitPython>=1.0.0\n","  Downloading GitPython-3.1.18-py3-none-any.whl (170 kB)\n","\u001b[K     |████████████████████████████████| 170 kB 49.0 MB/s \n","\u001b[?25hRequirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.3)\n","Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.8.2)\n","Collecting shortuuid>=0.5.0\n","  Downloading shortuuid-1.0.1-py3-none-any.whl (7.5 kB)\n","Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (5.4.8)\n","Requirement already satisfied: six>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.15.0)\n","Collecting configparser>=3.8.1\n","  Downloading configparser-5.0.2-py3-none-any.whl (19 kB)\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from wandb) (3.13)\n","Requirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.17.3)\n","Collecting sentry-sdk>=1.0.0\n","  Downloading sentry_sdk-1.3.1-py2.py3-none-any.whl (133 kB)\n","\u001b[K     |████████████████████████████████| 133 kB 50.2 MB/s \n","\u001b[?25hCollecting pathtools\n","  Downloading pathtools-0.1.2.tar.gz (11 kB)\n","Requirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (7.1.2)\n","Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.23.0)\n","Collecting subprocess32>=3.5.3\n","  Downloading subprocess32-3.5.4.tar.gz (97 kB)\n","\u001b[K     |████████████████████████████████| 97 kB 6.4 MB/s \n","\u001b[?25hCollecting docker-pycreds>=0.4.0\n","  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n","Collecting gitdb<5,>=4.0.1\n","  Downloading gitdb-4.0.7-py3-none-any.whl (63 kB)\n","\u001b[K     |████████████████████████████████| 63 kB 1.9 MB/s \n","\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.0 in /usr/local/lib/python3.7/dist-packages (from GitPython>=1.0.0->wandb) (3.7.4.3)\n","Collecting smmap<5,>=3.0.1\n","  Downloading smmap-4.0.0-py2.py3-none-any.whl (24 kB)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2021.5.30)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (1.24.3)\n","Building wheels for collected packages: subprocess32, pathtools\n","  Building wheel for subprocess32 (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for subprocess32: filename=subprocess32-3.5.4-py3-none-any.whl size=6502 sha256=0c4c2178e115901f91a5a3ac8b94cc6bfd1394cd5f4ad602f494747c32cea7b6\n","  Stored in directory: /root/.cache/pip/wheels/50/ca/fa/8fca8d246e64f19488d07567547ddec8eb084e8c0d7a59226a\n","  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8807 sha256=9fb667088a9cf2c2a4cc66d2c92cecf28c2ad814c765a64593d5ccdbc8121a5b\n","  Stored in directory: /root/.cache/pip/wheels/3e/31/09/fa59cef12cdcfecc627b3d24273699f390e71828921b2cbba2\n","Successfully built subprocess32 pathtools\n","Installing collected packages: smmap, gitdb, subprocess32, shortuuid, sentry-sdk, pathtools, GitPython, docker-pycreds, configparser, wandb\n","Successfully installed GitPython-3.1.18 configparser-5.0.2 docker-pycreds-0.4.0 gitdb-4.0.7 pathtools-0.1.2 sentry-sdk-1.3.1 shortuuid-1.0.1 smmap-4.0.0 subprocess32-3.5.4 wandb-0.12.1\n"]}]}]}